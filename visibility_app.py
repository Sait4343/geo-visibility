import time
from datetime import datetime, timedelta, date, time as dt_time # –î–æ–¥–∞–Ω–æ dt_time
import plotly.express as px 
import pandas as pd
import plotly.graph_objects as go
import requests
import streamlit as st
import extra_streamlit_components as stx
from streamlit_option_menu import option_menu
from supabase import create_client, Client
import numpy as np # –ü–æ—Ç—Ä—ñ–±–Ω–æ –¥–ª—è –∞–¥–º—ñ–Ω–∫–∏
import json


# =========================
# 1. CONFIGURATION
# =========================

st.set_page_config(
    page_title="AI Visibility by Virshi",
    page_icon="üëÅÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded",
)

# üî¥ –ü–†–û–î–ê–ö–®–ù N8N –í–ï–ë–•–£–ö–ò
N8N_GEN_URL = "https://virshi.app.n8n.cloud/webhook/webhook/generate-prompts"
N8N_ANALYZE_URL = "https://virshi.app.n8n.cloud/webhook/webhook/run-analysis_prod"
N8N_RECO_URL = "https://virshi.app.n8n.cloud/webhook/recommendations"  
N8N_CHAT_WEBHOOK = "https://virshi.app.n8n.cloud/webhook/webhook/chat-bot" 


# Custom CSS
st.markdown(
    """
<style>
    /* 1. –ó–ê–ì–ê–õ–¨–ù–Ü –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø */
    .stApp { background-color: #F4F6F9; }
    
    /* –ü—Ä–∏—Ö–æ–≤—É–≤–∞–Ω–Ω—è —è–∫—ñ—Ä–Ω–∏—Ö –ø–æ—Å–∏–ª–∞–Ω—å (–ª–∞–Ω—Ü—é–∂–∫—ñ–≤) –±—ñ–ª—è –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤ */
    [data-testid="stMarkdownContainer"] h1 > a,
    [data-testid="stMarkdownContainer"] h2 > a,
    [data-testid="stMarkdownContainer"] h3 > a,
    [data-testid="stMarkdownContainer"] h4 > a,
    [data-testid="stMarkdownContainer"] h5 > a,
    [data-testid="stMarkdownContainer"] h6 > a {
        display: none !important;
    }
    a.anchor-link { display: none !important; }

    /* 2. –°–ê–ô–î–ë–ê–† */
    section[data-testid="stSidebar"] { 
        background-color: #FFFFFF; 
        border-right: 1px solid #E0E0E0; 
    }
    .sidebar-logo-container { display: flex; justify-content: center; margin-bottom: 10px; }
    .sidebar-logo-container img { width: 140px; }
    .sidebar-name { font-size: 14px; font-weight: 600; color: #333; margin-top: 5px;}
    .sidebar-label { font-size: 11px; color: #999; text-transform: uppercase; letter-spacing: 0.5px; margin-top: 15px;}

    /* 3. –ö–û–ù–¢–ï–ô–ù–ï–†–ò –Ü –§–û–†–ú–ò */
    .css-1r6slb0, .css-12oz5g7, div[data-testid="stForm"] {
        background-color: white; padding: 20px; border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05); border: 1px solid #EAEAEA;
    }

    /* 4. –ú–ï–¢–†–ò–ö–ò */
    div[data-testid="stMetric"] {
        background-color: #ffffff; border: 1px solid #e0e0e0; padding: 15px;
        border-radius: 10px; text-align: center; box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    .metric-card-small {
        background-color: #F0F2F6;
        border-radius: 6px;
        padding: 10px;
        text-align: center;
    }
    .metric-value {
        font-size: 18px; font-weight: bold; color: #8041F6;
    }
    .metric-label {
        font-size: 12px; color: #666;
    }

    /* 5. –ö–ù–û–ü–ö–ò */
    .stButton>button { 
        background-color: #8041F6; color: white; border-radius: 8px; border: none; font-weight: 600; 
        transition: background-color 0.3s;
    }
    .stButton>button:hover { background-color: #6a35cc; }
    
    .upgrade-btn {
        display: block; width: 100%; background-color: #FFC107; color: #000000;
        text-align: center; padding: 8px; border-radius: 8px;
        text-decoration: none; font-weight: bold; margin-top: 10px; border: 1px solid #e0a800;
    }

    /* 6. –ë–ï–ô–î–ñ–Ü –¢–ê –°–¢–ê–¢–£–°–ò */
    .badge-trial { background-color: #FFECB3; color: #856404; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.7em; }
    .badge-active { background-color: #D4EDDA; color: #155724; padding: 2px 6px; border-radius: 4px; font-weight: bold; font-size: 0.7em; }

    /* 7. –í–Ü–î–ü–û–í–Ü–î–¨ –®–Ü */
    .ai-response-box {
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        padding: 20px;
        font-family: 'Source Sans Pro', sans-serif;
        line-height: 1.6;
        color: #31333F;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
        max-height: 600px;
        overflow-y: auto;
    }
</style>
""",
    unsafe_allow_html=True,
)

# =========================
# 2. DB CONNECTION & STATE
# =========================

cookie_manager = stx.CookieManager()

try:
    SUPABASE_URL: str = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY: str = st.secrets["SUPABASE_KEY"]

    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    DB_CONNECTED = True
except Exception as e:
    st.error(f"CRITICAL ERROR: Database Connection Failed. {e}")
    st.stop()

# Session State
if "user" not in st.session_state:
    st.session_state["user"] = None
if "user_details" not in st.session_state:
    st.session_state["user_details"] = {}
if "role" not in st.session_state:
    st.session_state["role"] = "user"
if "current_project" not in st.session_state:
    st.session_state["current_project"] = None
if "generated_prompts" not in st.session_state:
    st.session_state["generated_prompts"] = []
if "onboarding_step" not in st.session_state:
    st.session_state["onboarding_step"] = 2  # —Å—Ç–∞—Ä—Ç—É—î–º–æ –æ–¥—Ä–∞–∑—É –∑ –∫—Ä–æ–∫—É –ø—Ä–æ –±—Ä–µ–Ω–¥
if "focus_keyword_id" not in st.session_state:
    st.session_state["focus_keyword_id"] = None

# =========================
# 3. HELPERS
# =========================


def get_donut_chart(value, color="#00C896"):
    value = float(value) if value else 0.0
    remaining = max(0, 100 - value)
    fig = go.Figure(
        data=[
            go.Pie(
                values=[value, remaining],
                hole=0.75,
                marker_colors=[color, "#F0F2F6"],
                textinfo="none",
                hoverinfo="label+percent",
            )
        ]
    )
    fig.update_layout(
        showlegend=False,
        margin=dict(t=0, b=0, l=0, r=0),
        height=80,
        width=80,
        annotations=[
            dict(
                text=f"{int(value)}%",
                x=0.5,
                y=0.5,
                font_size=14,
                showarrow=False,
                font_weight="bold",
                font_color="#333",
            )
        ],
    )
    return fig


METRIC_TOOLTIPS = {
    "sov": "–ß–∞—Å—Ç–∫–∞ –≤–∏–¥–∏–º–æ—Å—Ç—ñ –≤–∞—à–æ–≥–æ –±—Ä–µ–Ω–¥—É —É –≤—ñ–¥–ø–æ–≤—ñ–¥—è—Ö –®–Ü –ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º–∏.",
    "official": "–ß–∞—Å—Ç–∫–∞ –ø–æ—Å–∏–ª–∞–Ω—å –Ω–∞ –≤–∞—à—ñ –æ—Ñ—ñ—Ü—ñ–π–Ω—ñ —Ä–µ—Å—É—Ä—Å–∏.",
    "sentiment": "–¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å: –ü–æ–∑–∏—Ç–∏–≤–Ω–∞, –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞ –∞–±–æ –ù–µ–≥–∞—Ç–∏–≤–Ω–∞.",
    "position": "–°–µ—Ä–µ–¥–Ω—è –ø–æ–∑–∏—Ü—ñ—è –≤–∞—à–æ–≥–æ –±—Ä–µ–Ω–¥—É —É —Å–ø–∏—Å–∫–∞—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π.",
    "presence": "–í—ñ–¥—Å–æ—Ç–æ–∫ –∑–∞–ø–∏—Ç—ñ–≤, –¥–µ –±—Ä–µ–Ω–¥ –±—É–≤ –∑–≥–∞–¥–∞–Ω–∏–π.",
    "domain": "–í—ñ–¥—Å–æ—Ç–æ–∫ –∑–∞–ø–∏—Ç—ñ–≤ –∑ –∫–ª—ñ–∫–∞–±–µ–ª—å–Ω–∏–º –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º –Ω–∞ –≤–∞—à –¥–æ–º–µ–Ω.",
}


def n8n_generate_prompts(brand: str, domain: str, industry: str, products: str):
    """
    –í–∏–∫–ª–∏–∫–∞—î n8n –≤–µ–±—Ö—É–∫ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –ø—Ä–æ–º–ø—Ç—ñ–≤.
    –û–ù–û–í–õ–ï–ù–û: –î–æ–¥–∞–Ω–æ header –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó (virshi-auth), —â–æ–± –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ –ø–æ–º–∏–ª–∫—É 403.
    """
    try:
        payload = {
            "brand": brand,
            "domain": domain,
            "industry": industry,
            "products": products,
        }

        # üî• –í–ê–ñ–õ–ò–í–û: –î–æ–¥–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó
        headers = {
            "virshi-auth": "hi@virshi.ai2025"
        }

        # –ü–µ—Ä–µ–¥–∞—î–º–æ headers —É –∑–∞–ø–∏—Ç
        response = requests.post(N8N_GEN_URL, json=payload, headers=headers, timeout=20)

        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list):
                return data
            return data.get("prompts", [])
        else:
            st.error(f"N8N Error: {response.status_code} - {response.text}")
            return []
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑'—î–¥–Ω–∞–Ω–Ω—è –∑ N8N: {e}")
        return []


def n8n_trigger_analysis(project_id, keywords, brand_name, models=None):
    """
    –í—ñ–¥–ø—Ä–∞–≤–ª—è—î –∑–∞–ø–∏—Ç –Ω–∞ n8n –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.
    –í–ï–†–°–Ü–Ø: RESTORED ORIGINAL PAYLOAD + TRIAL LIMIT.
    1. –§–æ—Ä–º–∞—Ç –¥–∞–Ω–∏—Ö –ø–æ–≤–µ—Ä–Ω—É—Ç–æ –¥–æ —Ä–æ–±–æ—á–æ–≥–æ —Å—Ç–∞–Ω—É (–±–µ–∑ brand_name_lower, –±–µ–∑ —á–∏—Å—Ç–∫–∏ URL).
    2. –ü—Ä–∞—Ü—é—î –±–ª–æ–∫—É–≤–∞–Ω–Ω—è –ø–æ–≤—Ç–æ—Ä–Ω–∏—Ö –∑–∞–ø—É—Å–∫—ñ–≤ –¥–ª—è Trial.
    """
    import requests
    import streamlit as st
    
    # --- 1. –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø –î–û –ë–î ---
    if 'supabase' in st.session_state:
        supabase = st.session_state['supabase']
    elif 'supabase' in globals():
        supabase = globals()['supabase']
    else:
        st.error("üö® –ü–æ–º–∏–ª–∫–∞: –ù–µ–º–∞—î –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î.")
        return False

    MODEL_MAPPING = {
        "Perplexity": "perplexity",
        "OpenAI GPT": "gpt-4o",
        "Google Gemini": "gemini-1.5-pro"
    }

    # 2. –û–¢–†–ò–ú–ê–ù–ù–Ø –°–¢–ê–¢–£–°–£
    current_proj = st.session_state.get("current_project")
    
    status = "trial"
    if current_proj and current_proj.get("id") == project_id:
        status = current_proj.get("status", "trial")
    
    if status == "blocked":
        st.error("‚õî –ü—Ä–æ–µ–∫—Ç –∑–∞–±–ª–æ–∫–æ–≤–∞–Ω–æ (BLOCKED). –ó–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–æ—Ä–∞.")
        return False

    if not models:
        models = ["Perplexity"]

    # ==========================================
    # üî• –õ–û–ì–Ü–ö–ê –¢–†–Ü–ê–õ–£ (–ó–ê–•–ò–°–¢)
    # ==========================================
    if status == "trial":
        is_only_gemini = True
        for m in models:
            if "Gemini" not in m and "gemini" not in m:
                is_only_gemini = False
                break
        
        if not is_only_gemini:
            st.error("‚õî –£ —Å—Ç–∞—Ç—É—Å—ñ TRIAL —Ä—É—á–Ω–∏–π –∑–∞–ø—É—Å–∫ –æ–±–º–µ–∂–µ–Ω–æ. –î–æ—Å—Ç—É–ø–Ω–æ –ª–∏—à–µ —á–µ—Ä–µ–∑ Google Gemini.")
            return False

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω–∏–π –∑–∞–ø—É—Å–∫ (—á–∏ —î –∑–∞–ø–∏—Å–∏ –≤ scan_results)
        try:
            existing = supabase.table("scan_results")\
                .select("id", count="exact")\
                .eq("project_id", project_id)\
                .limit(1)\
                .execute()
            
            # –Ø–∫—â–æ count > 0 -> –≤–∂–µ —Å–∫–∞–Ω—É–≤–∞–ª–∏ -> –ë–ª–æ–∫—É—î–º–æ
            if existing.data or (existing.count and existing.count > 0):
                st.error("‚õî –ê–Ω–∞–ª—ñ–∑ –Ω–µ–º–æ–∂–ª–∏–≤–∏–π —É —Å—Ç–∞—Ç—É—Å—ñ TRIAL (–ª—ñ–º—ñ—Ç –≤–∏—á–µ—Ä–ø–∞–Ω–æ). –ë—É–¥—å –ª–∞—Å–∫–∞, –∑–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –≤ —Ç–µ—Ö–ø—ñ–¥—Ç—Ä–∏–º–∫—É –Ω–∞ –ø–æ—à—Ç—É hi@virshi.ai, —â–æ–± –æ—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–∞—Ç—É—Å ACTIVE.")
                return False
        except Exception as e:
            # –ù–µ –±–ª–æ–∫—É—î–º–æ –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ –∑–∞–ø–∏—Ç—É, —â–æ–± –Ω–µ –ª–∞–º–∞—Ç–∏ –ª–æ–≥—ñ–∫—É, –∞–ª–µ –≤–∏–≤–æ–¥–∏–º–æ –≤ –∫–æ–Ω—Å–æ–ª—å
            print(f"Trial check error: {e}")

    # ==========================================
    # üöÄ –í–Ü–î–ü–†–ê–í–ö–ê (–†–û–ë–û–ß–ò–ô –í–ê–†–Ü–ê–ù–¢)
    # ==========================================
    try:
        user = st.session_state.get("user")
        user_email = user.email if user else "no-reply@virshi.ai"
        
        if isinstance(keywords, str):
            keywords = [keywords]

        success_count = 0

        # 3. –û–¢–†–ò–ú–£–Ñ–ú–û –û–§–Ü–¶–Ü–ô–ù–Ü –î–ñ–ï–†–ï–õ–ê (–ë–µ–∑ –∑–º—ñ–Ω, —è–∫ —É —Ä–æ–±–æ—á–æ–º—É –≤–∞—Ä—ñ–∞–Ω—Ç—ñ)
        official_assets = []
        try:
            assets_resp = supabase.table("official_assets")\
                .select("domain_or_url")\
                .eq("project_id", project_id)\
                .execute()
            # –ë–µ—Ä–µ–º–æ —è–∫ —î, –±–µ–∑ .lower() —ñ –±–µ–∑ replace(), –±–æ n8n –æ—á—ñ–∫—É—î –æ—Ä–∏–≥—ñ–Ω–∞–ª
            official_assets = [item["domain_or_url"] for item in assets_resp.data] if assets_resp.data else []
        except Exception as e:
            print(f"Error fetching assets: {e}")
            official_assets = []

        headers = {"virshi-auth": "hi@virshi.ai2025"}

        # 4. –¶–ò–ö–õ –í–Ü–î–ü–†–ê–í–ö–ò
        for ui_model_name in models:
            tech_model_id = MODEL_MAPPING.get(ui_model_name, ui_model_name)

            # –§–æ—Ä–º—É—î–º–æ JSON —Ç–æ—á–Ω—ñ—Å—ñ–Ω—å–∫–æ —è–∫ —É –≤–∞—à–æ–º—É –ø—Ä–∏–∫–ª–∞–¥—ñ "working JSON"
            payload = {
                "project_id": project_id,
                "keywords": keywords, 
                "brand_name": brand_name,
                # "brand_name_lower" –ü–†–ò–ë–†–ê–ù–û - —Ü–µ –ª–∞–º–∞–ª–æ n8n
                "user_email": user_email,
                "provider": tech_model_id,
                "models": [tech_model_id],
                "official_assets": official_assets 
            }
            
            try:
                # –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—è, —â–æ –∑–º—ñ–Ω–Ω–∞ N8N_ANALYZE_URL –¥–æ—Å—Ç—É–ø–Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ
                response = requests.post(
                    N8N_ANALYZE_URL, 
                    json=payload, 
                    headers=headers, 
                    timeout=20
                )
                
                if response.status_code == 200:
                    success_count += 1
                else:
                    st.error(f"–ü–æ–º–∏–ª–∫–∞ n8n ({ui_model_name}): {response.text}")
                    
            except Exception as inner_e:
                st.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç–∏ {ui_model_name}: {inner_e}")

        return success_count > 0
            
    except Exception as e:
        st.error(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –∑–∞–ø—É—Å–∫—É: {e}")
        return False


def trigger_ai_recommendation(user, project, category, context_text):
    """
    –í—ñ–¥–ø—Ä–∞–≤–ª—è—î –∑–∞–ø–∏—Ç –Ω–∞ AI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó HTML-–∑–≤—ñ—Ç—É.
    """
    import requests
    from datetime import datetime
    
    headers = {
        "virshi-auth": "hi@virshi.ai2025"
    }
    
    # –§–æ—Ä–º—É—î–º–æ –ø–æ–≤–Ω–∏–π payload
    payload = {
        "timestamp": datetime.now().isoformat(),
        # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        "user_id": user.id if user else "unknown",
        "user_email": user.email if user else "unknown",
        
        # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø—Ä–æ–µ–∫—Ç
        "project_id": project.get("id"),
        "brand_name": project.get("brand_name"),
        "domain": project.get("domain"),
        
        # –î–µ—Ç–∞–ª—ñ –∑–∞–ø–∏—Ç—É
        "category": category, 
        "request_context": context_text,
        "request_type": "html_report"
    }
    
    try:
        response = requests.post(N8N_RECO_URL, json=payload, headers=headers, timeout=120)
        
        if response.status_code == 200:
            # –°–ø—Ä–æ–±—É—î–º–æ —Ä–æ–∑–ø–∞—Ä—Å–∏—Ç–∏ JSON, —è–∫—â–æ n8n –ø–æ–≤–µ—Ä—Ç–∞—î –æ–±'—î–∫—Ç
            try:
                data = response.json()
                # –®—É–∫–∞—î–º–æ HTML —É —Ä—ñ–∑–Ω–∏—Ö –ø–æ–ª—è—Ö
                return data.get("html") or data.get("output") or data.get("report") or str(data)
            except:
                # –Ø–∫—â–æ –ø–æ–≤–µ—Ä–Ω—É–≤—Å—è –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç/html
                return response.text
        else:
            return f"<p style='color:red; font-weight:bold;'>Error from AI Provider: {response.status_code}</p>"
            
    except Exception as e:
        return f"<p style='color:red; font-weight:bold;'>Connection Error: {e}</p>"


# =========================
# 4. AUTH & USER LOGIC
# =========================


def load_user_project(user_id: str) -> bool:
    try:
        res = supabase.table("projects").select("*").eq("user_id", user_id).execute()
        if res.data and len(res.data) > 0:
            st.session_state["current_project"] = res.data[0]
            return True
    except Exception:
        pass
    return False


def get_user_role_and_details(user_id: str):
    try:
        data = supabase.table("profiles").select("*").eq("id", user_id).execute()
        if data.data:
            p = data.data[0]
            return p.get("role", "user"), {
                "first_name": p.get("first_name"),
                "last_name": p.get("last_name"),
            }
    except Exception:
        pass
    return "user", {}


def check_session():
    if st.session_state["user"] is None:
        time.sleep(0.1)
        token = cookie_manager.get("virshi_auth_token")

        if token:
            try:
                res = supabase.auth.get_user(token)
                if getattr(res, "user", None):
                    st.session_state["user"] = res.user
                    role, details = get_user_role_and_details(res.user.id)
                    st.session_state["role"] = role
                    st.session_state["user_details"] = details
                    load_user_project(res.user.id)
                else:
                    cookie_manager.delete("virshi_auth_token")
            except Exception:
                cookie_manager.delete("virshi_auth_token")


def login_user(email: str, password: str):
    try:
        res = supabase.auth.sign_in_with_password(
            {"email": email, "password": password}
        )
        if not res.user:
            st.error("–ù–µ –≤–¥–∞–ª–æ—Å—è —É–≤—ñ–π—Ç–∏. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ email —Ç–∞ –ø–∞—Ä–æ–ª—å.")
            return

        st.session_state["user"] = res.user
        cookie_manager.set(
            "virshi_auth_token",
            res.session.access_token,
            expires_at=datetime.now() + timedelta(days=7),
        )

        role, details = get_user_role_and_details(res.user.id)
        st.session_state["role"] = role
        st.session_state["user_details"] = details

        if load_user_project(res.user.id):
            st.success("–í—Ö—ñ–¥ —É—Å–ø—ñ—à–Ω–∏–π!")

        st.rerun()
    except Exception:
        st.error(
            "–ü–æ–º–∏–ª–∫–∞ –≤—Ö–æ–¥—É: –Ω–µ–≤—ñ—Ä–Ω–∏–π –ª–æ–≥—ñ–Ω, –ø–∞—Ä–æ–ª—å –∞–±–æ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–Ω—è email."
        )


def register_user(email: str, password: str, first: str, last: str) -> bool:
    """
    –†–µ—î—Å—Ç—Ä–∞—Ü—ñ—è –Ω–æ–≤–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ + –∑–∞–ø–∏—Å first_name / last_name –≤ —Ç–∞–±–ª–∏—Ü—é profiles.
    """
    try:
        res = supabase.auth.sign_up(
            {
                "email": email,
                "password": password,
                "options": {"data": {"first_name": first, "last_name": last}},
            }
        )

        if res.user:
            # —è–≤–Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—Ä–æ—Ñ—ñ–ª—é
            try:
                supabase.table("profiles").insert(
                    {
                        "id": res.user.id,
                        "email": email,
                        "first_name": first,
                        "last_name": last,
                        "role": "user",
                    }
                ).execute()
            except Exception:
                pass

            if res.session:
                st.success("–†–µ—î—Å—Ç—Ä–∞—Ü—ñ—è —É—Å–ø—ñ—à–Ω–∞! –í–∏–∫–æ–Ω—É—î–º–æ –≤—Ö—ñ–¥...")
                st.session_state["user"] = res.user
                cookie_manager.set(
                    "virshi_auth_token",
                    res.session.access_token,
                    expires_at=datetime.now() + timedelta(days=7),
                )
                role, details = get_user_role_and_details(res.user.id)
                st.session_state["role"] = role
                st.session_state["user_details"] = details
                load_user_project(res.user.id)
                st.rerun()
            else:
                st.success(
                    "–†–µ—î—Å—Ç—Ä–∞—Ü—ñ—è —É—Å–ø—ñ—à–Ω–∞! –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ø–æ—à—Ç—É, –ø—ñ–¥—Ç–≤–µ—Ä–¥—ñ—Ç—å email "
                    "—Ç–∞ —É–≤—ñ–π–¥—ñ—Ç—å –Ω–∞ –≤–∫–ª–∞–¥—Ü—ñ ¬´–í—Ö—ñ–¥¬ª."
                )
            return True

        st.error("–ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Auth.")
    except Exception as e:
        if "already registered" in str(e):
            st.warning("–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á –≤–∂–µ —ñ—Å–Ω—É—î. –°–ø—Ä–æ–±—É–π—Ç–µ —É–≤—ñ–π—Ç–∏.")
        else:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó: {e}")
    return False


def logout():
    """
    –ù–∞–¥—ñ–π–Ω–∏–π –≤–∏—Ö—ñ–¥ —ñ–∑ —Å–∏—Å—Ç–µ–º–∏.
    """
    # 1. –í–∏–¥–∞–ª—è—î–º–æ –∫—É–∫—É (Token)
    try:
        cookie_manager.delete("virshi_auth_token")
    except Exception:
        pass

    # 2. –í–∏—Ö–æ–¥–∏–º–æ –∑ Supabase (–Ω–∞ —Å—Ç–æ—Ä–æ–Ω—ñ —Å–µ—Ä–≤–µ—Ä–∞)
    try:
        supabase.auth.sign_out()
    except Exception:
        pass

    # 3. üî• –ü–û–í–ù–ï –æ—á–∏—â–µ–Ω–Ω—è Session State
    # –¶–µ –≤–∏–¥–∞–ª—è—î –≤—Å—ñ –∑–º—ñ–Ω–Ω—ñ: user, current_project, –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä—ñ–≤ —Ç–æ—â–æ.
    st.session_state.clear()

    # 4. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ –∫—Ä–∏—Ç–∏—á–Ω—ñ –∑–º—ñ–Ω–Ω—ñ, —â–æ–± –Ω–µ –±—É–ª–æ –ø–æ–º–∏–ª–æ–∫ –¥–æ –ø–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
    st.session_state["user"] = None
    
    # 5. –ü–∞—É–∑–∞, —â–æ–± –±—Ä–∞—É–∑–µ—Ä –≤—Å—Ç–∏–≥ —Ñ—ñ–∑–∏—á–Ω–æ –≤–∏–¥–∞–ª–∏—Ç–∏ –∫—É–∫—É
    time.sleep(1)

    # 6. –ü–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏
    st.rerun()


def login_page():
    c_l, c_center, c_r = st.columns([1, 1.5, 1])
    with c_center:
        st.markdown(
            '<div style="text-align: center;"><img src="https://raw.githubusercontent.com/virshi-ai/image/refs/heads/main/logo-removebg-preview.png" width="180"></div>',
            unsafe_allow_html=True,
        )
        st.markdown("<br>", unsafe_allow_html=True)

        t1, t2 = st.tabs(["üîë –í—Ö—ñ–¥", "üìù –†–µ—î—Å—Ç—Ä–∞—Ü—ñ—è"])

        # –í–•–Ü–î
        with t1:
            with st.form("login"):
                email = st.text_input("–ï–º–µ–π–ª")
                password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password")
                if st.form_submit_button("–£–≤—ñ–π—Ç–∏", use_container_width=True):
                    if email and password:
                        login_user(email, password)
                    else:
                        st.warning("–í–≤–µ–¥—ñ—Ç—å –µ–º–µ–π–ª —Ç–∞ –ø–∞—Ä–æ–ª—å.")

        # –†–ï–Ñ–°–¢–†–ê–¶–Ü–Ø
        with t2:
            with st.form("reg"):
                ne = st.text_input("–ï–º–µ–π–ª")
                np = st.text_input("–ü–∞—Ä–æ–ª—å", type="password")
                c1, c2 = st.columns(2)
                fn = c1.text_input("–Ü–º'—è")
                ln = c2.text_input("–ü—Ä—ñ–∑–≤–∏—â–µ")
                if st.form_submit_button("–ó–∞—Ä–µ—î—Å—Ç—Ä—É–≤–∞—Ç–∏—Å—è", use_container_width=True):
                    if ne and np and fn:
                        register_user(ne, np, fn, ln)
                    else:
                        st.warning("–í—Å—ñ –ø–æ–ª—è –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ.")


# =========================
# 5. ONBOARDING
# =========================


def onboarding_wizard():
    """
    –ú–∞–π—Å—Ç–µ—Ä —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—Ä–æ–µ–∫—Ç—É.
    –í–ï–†–°–Ü–Ø: REGION SELECT + TIMEOUT FIX.
    1. –†–µ–≥—ñ–æ–Ω: –í–∏–ø–∞–¥–∞—é—á–∏–π —Å–ø–∏—Å–æ–∫ (Ukraine, USA, Europe, Global).
    2. –ë–∞–∑–∞ –¥–∞–Ω–∏—Ö: –†–µ–≥—ñ–æ–Ω –∑–∞–ø–∏—Å—É—î—Ç—å—Å—è –¥–∏–Ω–∞–º—ñ—á–Ω–æ.
    """
    import requests
    import time
    
    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Å—ñ—ó
    if "onboarding_stage" not in st.session_state:
        st.session_state["onboarding_stage"] = 2
        st.session_state["generated_prompts"] = []
    
    # CSS –¥–ª—è –∑–µ–ª–µ–Ω–∏—Ö –Ω–æ–º–µ—Ä—ñ–≤
    st.markdown("""
    <style>
        .green-number-small {
            background-color: #00C896;
            color: white;
            width: 24px;
            height: 24px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 12px;
            margin-top: 8px;
        }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown("## üöÄ –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ü—Ä–æ–µ–∫—Ç—É")
    step = st.session_state.get("onboarding_step", 2) 

    with st.container(border=True):
        # ========================================================
        # –ö–†–û–ö 1: –í–í–Ü–î –î–ê–ù–ò–•
        # ========================================================
        if step == 2:
            st.subheader("–ö—Ä–æ–∫ 1: –í–≤–µ–¥—ñ—Ç—å –¥–∞–Ω—ñ –ø—Ä–æ –≤–∞—à –±—Ä–µ–Ω–¥")
            c1, c2 = st.columns(2)
            with c1:
                brand = st.text_input("–ù–∞–∑–≤–∞ –±—Ä–µ–Ω–¥—É", placeholder="Monobank", value=st.session_state.get("temp_brand", ""))
                industry = st.text_input("–ì–∞–ª—É–∑—å –±—Ä–µ–Ω–¥—É / –Ω—ñ—à–∞", placeholder="–§—ñ–Ω—Ç–µ—Ö", value=st.session_state.get("temp_industry", ""))
            with c2:
                domain = st.text_input("–î–æ–º–µ–Ω (–æ—Ñ—ñ—Ü—ñ–π–Ω–∏–π —Å–∞–π—Ç)", placeholder="monobank.ua", value=st.session_state.get("temp_domain", ""))
                
                # üî• UPDATE: –í–∏–ø–∞–¥–∞—é—á–∏–π —Å–ø–∏—Å–æ–∫ –∑–∞–º—ñ—Å—Ç—å —Ñ—ñ–∫—Å–æ–≤–∞–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É
                region_options = ["Ukraine", "USA", "Europe", "Global"]
                # –Ø–∫—â–æ —Ä–∞–Ω—ñ—à–µ –≤–∂–µ –æ–±–∏—Ä–∞–ª–∏, –±–µ—Ä–µ–º–æ –∑–±–µ—Ä–µ–∂–µ–Ω–µ, —ñ–Ω–∞–∫—à–µ –¥–µ—Ñ–æ–ª—Ç Ukraine (0 —ñ–Ω–¥–µ–∫—Å)
                saved_region = st.session_state.get("temp_region", "Ukraine")
                try:
                    idx = region_options.index(saved_region)
                except:
                    idx = 0
                
                region = st.selectbox("–†–µ–≥—ñ–æ–Ω", options=region_options, index=idx)

            products = st.text_area("–ü—Ä–æ–¥—É–∫—Ç–∏ / –ü–æ—Å–ª—É–≥–∏", value=st.session_state.get("temp_products", ""))

            if st.button("–ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∑–∞–ø–∏—Ç–∏"):
                if brand and domain and industry and products:
                    st.session_state["temp_brand"] = brand
                    st.session_state["temp_domain"] = domain
                    st.session_state["temp_industry"] = industry
                    st.session_state["temp_products"] = products
                    # üî• UPDATE: –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ–±—Ä–∞–Ω–∏–π —Ä–µ–≥—ñ–æ–Ω
                    st.session_state["temp_region"] = region

                    with st.spinner("–ì–µ–Ω–µ—Ä—É—î–º–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ –∑–∞–ø–∏—Ç–∏..."):
                        # –í–∏–∫–ª–∏–∫ –æ–Ω–æ–≤–ª–µ–Ω–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó –∑ —Ç–∞–π–º–∞—É—Ç–æ–º 60—Å
                        prompts = n8n_generate_prompts(brand, domain, industry, products)
                        if prompts:
                            st.session_state["generated_prompts"] = prompts
                            st.session_state["onboarding_step"] = 3
                            st.rerun()
                        # –Ø–∫—â–æ –ø–æ–º–∏–ª–∫–∞ —Ç–∞–π–º–∞—É—Ç—É, –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤–∏–≤–µ–¥–µ —Å–∞–º–∞ —Ñ—É–Ω–∫—Ü—ñ—è n8n_generate_prompts
                else:
                    st.warning("‚ö†Ô∏è –ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–ø–æ–≤–Ω—ñ—Ç—å –≤—Å—ñ –ø–æ–ª—è.")

        # ========================================================
        # –ö–†–û–ö 2: –ü–ï–†–ï–í–Ü–†–ö–ê –¢–ê –ó–ê–ü–£–°–ö
        # ========================================================
        elif step == 3:
            st.subheader("–ö—Ä–æ–∫ 2: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –∑–∞–ø—É—Å–∫")
            
            prompts_list = st.session_state.get("generated_prompts", [])
            
            if not prompts_list:
                st.warning("–°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Ç—ñ–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π.")
                if st.button("–ù–∞–∑–∞–¥"):
                    st.session_state["onboarding_step"] = 2
                    st.rerun()
                return

            st.markdown("–ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —Ç–∞ –≤—ñ–¥—Ä–µ–¥–∞–≥—É–π—Ç–µ –∑–∞–ø–∏—Ç–∏ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º:")
            st.write("") 

            selected_indices = []

            # --- –¶–ò–ö–õ –í–ò–í–û–î–£ –ö–ê–†–¢–û–ö –ó –†–ï–î–ê–ì–£–í–ê–ù–ù–Ø–ú ---
            for i, kw in enumerate(prompts_list):
                edit_key = f"edit_mode_row_{i}"
                if edit_key not in st.session_state:
                    st.session_state[edit_key] = False

                with st.container(border=True):
                    c_chk, c_num, c_text, c_btn = st.columns([0.5, 0.5, 8, 1])
                    
                    # 1. –ß–µ–∫–±–æ–∫—Å
                    with c_chk:
                        st.write("") 
                        if st.checkbox("", value=True, key=f"chk_final_{i}"):
                            selected_indices.append(i)
                    
                    # 2. –ù–æ–º–µ—Ä
                    with c_num:
                        st.markdown(f"<div class='green-number-small'>{i+1}</div>", unsafe_allow_html=True)

                    # 3. –¢–µ–∫—Å—Ç / –ü–æ–ª–µ
                    with c_text:
                        if st.session_state[edit_key]:
                            new_val = st.text_input("", value=kw, key=f"input_kw_{i}", label_visibility="collapsed")
                        else:
                            st.markdown(f"<div style='padding-top: 8px; font-size: 15px;'>{kw}</div>", unsafe_allow_html=True)

                    # 4. –ö–Ω–æ–ø–∫–∞
                    with c_btn:
                        st.write("") 
                        if st.session_state[edit_key]:
                            if st.button("üíæ", key=f"save_kw_{i}", help="–ó–±–µ—Ä–µ–≥—Ç–∏"):
                                st.session_state["generated_prompts"][i] = new_val
                                st.session_state[edit_key] = False
                                st.rerun()
                        else:
                            if st.button("‚úèÔ∏è", key=f"edit_kw_{i}", help="–†–µ–¥–∞–≥—É–≤–∞—Ç–∏"):
                                st.session_state[edit_key] = True
                                st.rerun()

            final_kws_to_send = [st.session_state["generated_prompts"][idx] for idx in selected_indices]
            
            st.divider()
            c_info, c_launch = st.columns([2, 1])
            with c_info:
                st.markdown(f"**–ì–æ—Ç–æ–≤–æ –¥–æ –∑–∞–ø—É—Å–∫—É:** {len(final_kws_to_send)} –∑–∞–ø–∏—Ç—ñ–≤")
            
            with c_launch:
                if st.button("üöÄ –ó–±–µ—Ä–µ–≥—Ç–∏ —Ç–∞ –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –∞–Ω–∞–ª—ñ–∑", type="primary", use_container_width=True):
                    if final_kws_to_send:
                        try:
                            # 1. –ó–ë–ò–†–ê–Ñ–ú–û –î–ê–ù–Ü
                            user_id = st.session_state["user"].id
                            brand_name = st.session_state.get("temp_brand")
                            domain_name = st.session_state.get("temp_domain")
                            # üî• UPDATE: –ë–µ—Ä–µ–º–æ —Ä–µ–≥—ñ–æ–Ω –∑—ñ —Å—Ç–µ–π—Ç—É
                            region_val = st.session_state.get("temp_region", "Ukraine")
                            
                            # 2. –°–¢–í–û–†–Æ–Ñ–ú–û –ü–†–û–ï–ö–¢
                            res = supabase.table("projects").insert({
                                "user_id": user_id, 
                                "brand_name": brand_name,
                                "domain": domain_name,
                                "region": region_val,  # <--- –ó–∞–ø–∏—Å—É—î–º–æ –æ–±—Ä–∞–Ω–∏–π —Ä–µ–≥—ñ–æ–Ω
                                "status": "trial"
                            }).execute()

                            if res.data:
                                proj_data = res.data[0]
                                proj_id = proj_data["id"]
                                
                                st.session_state["current_project"] = proj_data

                                # 3. –ó–ê–ü–ò–°–£–Ñ–ú–û WHITELIST
                                clean_d = domain_name.replace("https://", "").replace("http://", "").strip().rstrip("/")
                                try:
                                    supabase.table("official_assets").insert({
                                        "project_id": proj_id, 
                                        "domain_or_url": clean_d,
                                        "type": "website"
                                    }).execute()
                                except Exception:
                                    pass 

                                # 4. –ó–ê–ü–ò–°–£–Ñ–ú–û KEYWORDS
                                kws_data = [{"project_id": proj_id, "keyword_text": kw, "is_active": True} for kw in final_kws_to_send]
                                supabase.table("keywords").insert(kws_data).execute()
                                
                                # 5. –í–Ü–î–ü–†–ê–í–ö–ê –ù–ê N8N
                                my_bar = st.progress(0, text="–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è AI-–∞–Ω–∞–ª—ñ—Ç–∏–∫–∞...")
                                total_kws = len(final_kws_to_send)

                                for i, single_kw in enumerate(final_kws_to_send):
                                    progress_pct = (i + 1) / total_kws
                                    my_bar.progress(progress_pct, text=f"–ê–Ω–∞–ª—ñ–∑ –∑–∞–ø–∏—Ç—É: {single_kw}...")
                                    
                                    n8n_trigger_analysis(
                                        project_id=proj_id, 
                                        keywords=[single_kw],     
                                        brand_name=brand_name,
                                        models=["Google Gemini"]  
                                    )
                                    time.sleep(0.5) 

                                my_bar.progress(1.0, text="‚úÖ –ü—Ä–æ–µ–∫—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
                                time.sleep(1)

                                # –§—ñ–Ω–∞–ª
                                st.session_state["onboarding_step"] = 2 
                                st.success("–£—Å–ø—ñ—Ö!")
                                st.rerun()

                        except Exception as e:
                            st.error(f"–ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø—Ä–æ–µ–∫—Ç—É: {e}")
                    else:
                        st.warning("–û–±–µ—Ä—ñ—Ç—å —Ö–æ—á–∞ –± –æ–¥–∏–Ω –∑–∞–ø–∏—Ç.")
                    
# =========================
# 6. DASHBOARD
# =========================

def show_competitors_page():
    """
    –°—Ç–æ—Ä—ñ–Ω–∫–∞ –≥–ª–∏–±–æ–∫–æ–≥–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É.
    –û–Ω–æ–≤–ª–µ–Ω–æ: 
    - –í–∫–ª–∞–¥–∫–∞ '–ß–∞—Å—Ç–æ—Ç–∞ –∑–≥–∞–¥–∫–∏': st.area_chart + —Ç–∞–±–ª–∏—Ü—è –∑–ª—ñ–≤–∞ –≤ —Å—Ç–∏–ª—ñ –∑–∞–≥–∞–ª—å–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥—É.
    """
    import pandas as pd
    import plotly.express as px
    import streamlit as st
    
    # --- 0. –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø ---
    if 'supabase' not in globals():
        if 'supabase' in st.session_state:
            supabase = st.session_state['supabase']
        else:
            st.error("üö® –ü–æ–º–∏–ª–∫–∞: –ó–º—ñ–Ω–Ω–∞ 'supabase' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
            return
    else:
        supabase = globals()['supabase']

    proj = st.session_state.get("current_project")
    if not proj:
        st.info("–°–ø–æ—á–∞—Ç–∫—É —Å—Ç–≤–æ—Ä—ñ—Ç—å –ø—Ä–æ–µ–∫—Ç.")
        return

    MODEL_MAPPING = {
        "Perplexity": "perplexity",
        "OpenAI GPT": "gpt-4o",
        "Google Gemini": "gemini-1.5-pro"
    }

    st.title("üë• –ê–Ω–∞–ª—ñ–∑ –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤")

    # --- 1. –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –î–ê–ù–ò–• ---
    try:
        # A. –°–∫–∞–Ω—É–≤–∞–Ω–Ω—è
        scans_resp = supabase.table("scan_results")\
            .select("id, provider, keyword_id, created_at")\
            .eq("project_id", proj["id"])\
            .execute()
        
        if not scans_resp.data:
            st.info("–î–∞–Ω–∏—Ö –Ω–µ–º–∞—î. –ó–∞–ø—É—Å—Ç—ñ—Ç—å —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è.")
            return
            
        df_scans = pd.DataFrame(scans_resp.data)
        
        # B. –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
        kw_resp = supabase.table("keywords").select("id, keyword_text").eq("project_id", proj["id"]).execute()
        kw_map = {k['id']: k['keyword_text'] for k in kw_resp.data}
        df_scans['keyword_text'] = df_scans['keyword_id'].map(kw_map)

        # C. –ó–≥–∞–¥–∫–∏ –±—Ä–µ–Ω–¥—ñ–≤
        scan_ids = df_scans['id'].tolist()
        mentions_resp = supabase.table("brand_mentions")\
            .select("*")\
            .in_("scan_result_id", scan_ids)\
            .execute()
        
        if not mentions_resp.data:
            st.info("–ë—Ä–µ–Ω–¥—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
            return

        df_mentions = pd.DataFrame(mentions_resp.data)

        # D. Master Data
        df_full = pd.merge(df_mentions, df_scans, left_on='scan_result_id', right_on='id', how='left')

    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö: {e}")
        return

    # --- 2. –§–Ü–õ–¨–¢–†–ò ---
    with st.container(border=True):
        c1, c2 = st.columns(2)
        with c1:
            all_models = list(MODEL_MAPPING.keys())
            sel_models = st.multiselect("ü§ñ –§—ñ–ª—å—Ç—Ä –ø–æ LLM:", all_models, default=all_models)
            sel_tech_models = [MODEL_MAPPING[m] for m in sel_models]

        with c2:
            all_kws = df_full['keyword_text'].dropna().unique().tolist()
            sel_kws = st.multiselect("üîé –§—ñ–ª—å—Ç—Ä –ø–æ –ó–∞–ø–∏—Ç–∞—Ö:", all_kws, default=all_kws)

    # –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä—ñ–≤
    if sel_tech_models:
        mask_model = df_full['provider'].apply(lambda x: any(t in str(x) for t in sel_tech_models))
    else:
        mask_model = df_full['provider'].apply(lambda x: False)

    if sel_kws:
        mask_kw = df_full['keyword_text'].isin(sel_kws)
    else:
        mask_kw = df_full['keyword_text'].apply(lambda x: False)

    df_filtered = df_full[mask_model & mask_kw]

    if df_filtered.empty:
        st.warning("–ó–∞ –æ–±—Ä–∞–Ω–∏–º–∏ —Ñ—ñ–ª—å—Ç—Ä–∞–º–∏ –¥–∞–Ω–∏—Ö –Ω–µ–º–∞—î.")
        return

    # --- 3. –ê–ì–†–ï–ì–ê–¶–Ü–Ø ---
    
    # –•–µ–ª–ø–µ—Ä: –¢–µ–∫—Å—Ç -> –ß–∏—Å–ª–æ
    def sentiment_to_score(s):
        if s == '–ü–æ–∑–∏—Ç–∏–≤–Ω–∏–π': return 100
        if s == '–ù–µ–≥–∞—Ç–∏–≤–Ω–∏–π': return 0
        return 50 # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π
    
    df_filtered['sent_score_num'] = df_filtered['sentiment_score'].apply(sentiment_to_score)

    stats = df_filtered.groupby('brand_name').agg(
        Mentions=('id_x', 'count'),
        Avg_Rank=('rank_position', 'mean'),
        Avg_Sentiment_Num=('sent_score_num', 'mean'),
        Is_My_Brand=('is_my_brand', 'max')
    ).reset_index()

    # –•–µ–ª–ø–µ—Ä: –ß–∏—Å–ª–æ -> –¢–µ–∫—Å—Ç
    def get_sentiment_text(score):
        if score >= 60: return "–ü–æ–∑–∏—Ç–∏–≤–Ω–∞"
        if score <= 40: return "–ù–µ–≥–∞—Ç–∏–≤–Ω–∞"
        return "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞"

    stats['Reputation_Text'] = stats['Avg_Sentiment_Num'].apply(get_sentiment_text)
    stats['Show'] = True 

    # --- 4. –í–Ü–î–û–ë–†–ê–ñ–ï–ù–ù–Ø (–í–ö–õ–ê–î–ö–ò) ---
    st.write("") 
    
    tab_list, tab_freq, tab_sent, tab_rank = st.tabs([
        "üìã –î–µ—Ç–∞–ª—å–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥", 
        "üìä –ß–∞—Å—Ç–æ—Ç–∞ –∑–≥–∞–¥–∫–∏", 
        "‚≠ê –¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å", 
        "üèÜ –°–µ—Ä–µ–¥–Ω—è –ø–æ–∑–∏—Ü—ñ—è"
    ])

    # === TAB 1: –î–ï–¢–ê–õ–¨–ù–ò–ô –†–ï–ô–¢–ò–ù–ì ===
    with tab_list:
        st.markdown("##### üìã –ó–≤–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü—è")
        
        display_df = stats.copy().sort_values('Mentions', ascending=False)
        display_df['–°–µ—Ä. –ü–æ–∑–∏—Ü—ñ—è'] = display_df['Avg_Rank'].apply(lambda x: f"#{x:.1f}")
        display_df['Is_My_Brand'] = display_df['Is_My_Brand'].apply(lambda x: True if x else False)

        st.dataframe(
            display_df[['brand_name', 'Mentions', 'Reputation_Text', '–°–µ—Ä. –ü–æ–∑–∏—Ü—ñ—è', 'Is_My_Brand']],
            use_container_width=True,
            column_config={
                "brand_name": "–ë—Ä–µ–Ω–¥",
                "Mentions": st.column_config.ProgressColumn("–ó–≥–∞–¥–æ–∫", format="%d", min_value=0, max_value=int(stats['Mentions'].max())),
                "Reputation_Text": st.column_config.TextColumn("–†–µ–ø—É—Ç–∞—Ü—ñ—è"),
                "Is_My_Brand": st.column_config.CheckboxColumn("–¶—ñ–ª—å–æ–≤–∏–π –±—Ä–µ–Ω–¥", disabled=True)
            },
            hide_index=True
        )

    # === TAB 2: –ß–ê–°–¢–û–¢–ê –ó–ì–ê–î–ö–ò (AREA CHART) ===
    with tab_freq:
        st.markdown("##### üìä –ß–∞—Å—Ç–æ—Ç–∞ –∑–≥–∞–¥–∫–∏ (Area Chart)")
        
        col_table, col_chart = st.columns([1.8, 2.2])

        with col_table:
            # –¢–∞–±–ª–∏—Ü—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å (—ñ–¥–µ–Ω—Ç–∏—á–Ω–∞ –ø–æ —Å—Ç–∏–ª—é –¥–æ Tab 1)
            df_freq_editor = stats[['Show', 'brand_name', 'Mentions', 'Is_My_Brand']].copy()
            df_freq_editor = df_freq_editor.sort_values('Mentions', ascending=False)

            edited_freq_df = st.data_editor(
                df_freq_editor,
                column_config={
                    "Show": st.column_config.CheckboxColumn("Show", width="small"),
                    "brand_name": st.column_config.TextColumn("–ë—Ä–µ–Ω–¥", disabled=True),
                    "Mentions": st.column_config.ProgressColumn(
                        "–ó–≥–∞–¥–æ–∫", 
                        format="%d", 
                        min_value=0, 
                        max_value=int(stats['Mentions'].max())
                    ),
                    "Is_My_Brand": st.column_config.CheckboxColumn("–¶—ñ–ª—å–æ–≤–∏–π", disabled=True, width="small")
                },
                hide_index=True,
                use_container_width=True,
                key="editor_freq"
            )

        with col_chart:
            # –î–∞–Ω—ñ –¥–ª—è –≥—Ä–∞—Ñ—ñ–∫–∞
            chart_data = edited_freq_df[edited_freq_df['Show'] == True]
            
            if not chart_data.empty:
                # –ì–æ—Ç—É—î–º–æ –¥–∞–Ω—ñ –¥–ª—è Area Chart (–Ü–Ω–¥–µ–∫—Å - –ë—Ä–µ–Ω–¥, –ó–Ω–∞—á–µ–Ω–Ω—è - –ó–≥–∞–¥–∫–∏)
                # st.area_chart –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î —ñ–Ω–¥–µ–∫—Å —è–∫ –≤—ñ—Å—å X
                chart_view = chart_data.set_index('brand_name')[['Mentions']]
                
                st.markdown("**–î–∏–Ω–∞–º—ñ–∫–∞ –∑–≥–∞–¥–æ–∫:**")
                st.area_chart(chart_view, color="#00C896")
            else:
                st.info("–û–±–µ—Ä—ñ—Ç—å —Ö–æ—á–∞ –± –æ–¥–∏–Ω –±—Ä–µ–Ω–¥ —É —Ç–∞–±–ª–∏—Ü—ñ –∑–ª—ñ–≤–∞.")

    # === TAB 3: –¢–û–ù–ê–õ–¨–ù–Ü–°–¢–¨ (STACKED BAR) ===
    with tab_sent:
        st.markdown("##### ‚≠ê –ê–Ω–∞–ª—ñ–∑ –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ")
        st.caption("–°–ø—ñ–≤–≤—ñ–¥–Ω–æ—à–µ–Ω–Ω—è: –ü–æ–∑–∏—Ç–∏–≤–Ω—ñ vs –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ñ vs –ù–µ–≥–∞—Ç–∏–≤–Ω—ñ.")

        # –ê–≥—Ä–µ–≥–∞—Ü—ñ—è –¥–ª—è Stacked Bar
        sent_distribution = df_filtered.groupby(['brand_name', 'sentiment_score']).size().reset_index(name='count')
        total_per_brand = sent_distribution.groupby('brand_name')['count'].transform('sum')
        sent_distribution['percentage'] = (sent_distribution['count'] / total_per_brand * 100).round(1)

        # –ö–µ—Ä—É–≤–∞–Ω–Ω—è
        col_list, col_chart = st.columns([1.5, 2.5])
        
        with col_list:
            df_sent_editor = stats[['Show', 'brand_name', 'Reputation_Text']].sort_values('brand_name')
            edited_sent_df = st.data_editor(
                df_sent_editor,
                column_config={
                    "Show": st.column_config.CheckboxColumn("Show", width="small"),
                    "brand_name": "–ë—Ä–µ–Ω–¥",
                    "Reputation_Text": "–†–µ–ø—É—Ç–∞—Ü—ñ—è"
                },
                hide_index=True,
                use_container_width=True,
                key="editor_sent"
            )

        with col_chart:
            selected_brands = edited_sent_df[edited_sent_df['Show'] == True]['brand_name'].tolist()
            chart_data_sent = sent_distribution[sent_distribution['brand_name'].isin(selected_brands)]

            if not chart_data_sent.empty:
                color_map_sent = {
                    "–ü–æ–∑–∏—Ç–∏–≤–Ω–∏–π": "#00C896",   
                    "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π": "#E0E0E0",  
                    "–ù–µ–≥–∞—Ç–∏–≤–Ω–∏–π": "#FF4B4B"    
                }
                
                fig_stack = px.bar(
                    chart_data_sent,
                    y="brand_name",
                    x="percentage",
                    color="sentiment_score",
                    orientation='h',
                    text="percentage",
                    color_discrete_map=color_map_sent,
                    category_orders={"sentiment_score": ["–ù–µ–≥–∞—Ç–∏–≤–Ω–∏–π", "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π", "–ü–æ–∑–∏—Ç–∏–≤–Ω–∏–π"]},
                    height=500
                )
                
                fig_stack.update_traces(texttemplate='%{text}%', textposition='inside')
                fig_stack.update_layout(
                    barmode='stack',
                    xaxis_title="–ß–∞—Å—Ç–∫–∞ (%)",
                    yaxis_title="",
                    legend_title="–¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å",
                    plot_bgcolor='rgba(0,0,0,0)',
                    margin=dict(l=0, r=0, t=30, b=0)
                )
                st.plotly_chart(fig_stack, use_container_width=True)
            else:
                st.info("–û–±–µ—Ä—ñ—Ç—å –±—Ä–µ–Ω–¥ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.")

    # === TAB 4: –°–ï–†–ï–î–ù–Ø –ü–û–ó–ò–¶–Ü–Ø (DONUT INVERSE) ===
    with tab_rank:
        st.markdown("##### üèÜ –°–µ—Ä–µ–¥–Ω—è –ø–æ–∑–∏—Ü—ñ—è (–ß–∏–º –º–µ–Ω—à–µ —á–∏—Å–ª–æ - —Ç–∏–º –∫—Ä–∞—â–µ)")
        
        col_rank_table, col_rank_chart = st.columns([1.5, 2])

        with col_rank_table:
            df_rank_editor = stats[['Show', 'brand_name', 'Avg_Rank', 'Is_My_Brand']].sort_values('Avg_Rank', ascending=True)

            edited_rank_df = st.data_editor(
                df_rank_editor,
                column_config={
                    "Show": st.column_config.CheckboxColumn("Show", width="small"),
                    "brand_name": st.column_config.TextColumn("–ë—Ä–µ–Ω–¥", disabled=True),
                    "Avg_Rank": st.column_config.NumberColumn("–†–∞–Ω–≥", format="%.1f"),
                    "Is_My_Brand": None
                },
                hide_index=True,
                use_container_width=True,
                key="editor_rank"
            )

        with col_rank_chart:
            chart_data_rank = edited_rank_df[edited_rank_df['Show'] == True].copy()
            if not chart_data_rank.empty:
                # –õ–æ–≥—ñ–∫–∞ —ñ–Ω–≤–µ—Ä—Å—ñ—ó (–¥–ª—è –≤—ñ–∑—É–∞–ª—å–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É)
                max_rank_val = chart_data_rank['Avg_Rank'].max()
                base_val = max_rank_val + 2 
                chart_data_rank['Inverse_Score'] = base_val - chart_data_rank['Avg_Rank']

                fig_rank = px.pie(
                    chart_data_rank,
                    names='brand_name',
                    values='Inverse_Score', # –†–æ–∑–º—ñ—Ä —Å–µ–∫—Ç–æ—Ä–∞
                    hole=0.6,
                    color='Is_My_Brand',
                    color_discrete_map={True: '#00C896', False: '#FFCE56', 1: '#00C896', 0: '#FFCE56'},
                    hover_data=['brand_name']
                )
                # –£ –ø—ñ–¥–ø–∏—Å–∞—Ö –ø–æ–∫–∞–∑—É—î–º–æ –†–ï–ê–õ–¨–ù–ò–ô —Ä–∞–Ω–≥!
                fig_rank.update_traces(
                    customdata=chart_data_rank[['Avg_Rank']],
                    textinfo='label',
                    hovertemplate = "<b>%{label}</b><br>–°–µ—Ä–µ–¥–Ω—î –º—ñ—Å—Ü–µ: %{customdata[0]:.1f}"
                )
                
                leader = chart_data_rank.iloc[0]
                fig_rank.update_layout(
                    showlegend=False, 
                    margin=dict(t=20, b=20, l=20, r=20), 
                    height=350,
                    annotations=[dict(text=f"–õ—ñ–¥–µ—Ä:<br>{leader['brand_name']}<br>#{leader['Avg_Rank']:.1f}", x=0.5, y=0.5, font_size=14, showarrow=False)]
                )
                st.plotly_chart(fig_rank, use_container_width=True)
            else:
                st.info("–û–±–µ—Ä—ñ—Ç—å –±—Ä–µ–Ω–¥.")

def show_recommendations_page():
    """
    –°—Ç–æ—Ä—ñ–Ω–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π.
    –í–ï–†–°–Ü–Ø: RENAMED FILES & BUTTONS.
    File prefix: "Recommendations_"
    Button label: "–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó"
    """
    import streamlit as st
    import pandas as pd
    import streamlit.components.v1 as components
    from datetime import datetime, timedelta

    # --- 1. –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø ---
    if 'supabase' in st.session_state:
        supabase = st.session_state['supabase']
    elif 'supabase' in globals():
        supabase = globals()['supabase']
    else:
        st.error("üö® DB Error: –ù–µ–º–∞—î –∑'—î–¥–Ω–∞–Ω–Ω—è –∑ –±–∞–∑–æ—é –¥–∞–Ω–∏—Ö.")
        return

    proj = st.session_state.get("current_project")
    user = st.session_state.get("user")
    
    if not proj:
        st.info("–°–ø–æ—á–∞—Ç–∫—É –æ–±–µ—Ä—ñ—Ç—å –ø—Ä–æ–µ–∫—Ç.")
        return

    st.title(f"üí° –¶–µ–Ω—Ç—Ä —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π: {proj.get('brand_name')}")

    # --- 2. –ö–ê–¢–ï–ì–û–†–Ü–á ---
    CATEGORIES = {
        "Digital": {
            "title": "Digital & Technical GEO",
            "desc": "–¢–µ—Ö–Ω—ñ—á–Ω–∞ –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è –µ–∫–æ—Å–∏—Å—Ç–µ–º–∏ –±—Ä–µ–Ω–¥—É –¥–ª—è –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ AI.",
            "value": "LLM (ChatGPT, Gemini) ‚Äî —Ü–µ –ø—Ä–æ–≥—Ä–∞–º–∏. –Ø–∫—â–æ —Å–∞–π—Ç —Ç–µ—Ö–Ω—ñ—á–Ω–æ —Å–∫–ª–∞–¥–Ω–∏–π –¥–ª—è –Ω–∏—Ö, –≤–æ–Ω–∏ –π–æ–≥–æ —ñ–≥–Ω–æ—Ä—É—é—Ç—å. –ú–∏ –∞–Ω–∞–ª—ñ–∑—É—î–º–æ –∫–æ–¥, —Ä–æ–∑–º—ñ—Ç–∫—É Schema.org —Ç–∞ –¥–æ—Å—Ç—É–ø–Ω—ñ—Å—Ç—å –¥–ª—è –±–æ—Ç—ñ–≤.",
            "prompt_context": "Analyze technical SEO, Schema markup, site structure, and data accessibility for LLM crawling. Focus on Technical GEO factors."
        },
        "Content": {
            "title": "Content Strategy",
            "desc": "–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–Ω—Ç–µ–Ω—Ç—É, —è–∫–∏–π AI –∑–∞—Ö–æ—á–µ —Ü–∏—Ç—É–≤–∞—Ç–∏.",
            "value": "AI –ª—é–±–∏—Ç—å —Ñ–∞–∫—Ç–∏ —ñ —Å—Ç—Ä—É–∫—Ç—É—Ä—É. –ú–∏ –¥–∞–º–æ –ø–ª–∞–Ω: —è–∫—ñ —Å—Ç–∞—Ç—Ç—ñ –ø–∏—Å–∞—Ç–∏ —ñ —è–∫ —ó—Ö –æ—Ñ–æ—Ä–º–ª—é–≤–∞—Ç–∏, —â–æ–± —Å—Ç–∞—Ç–∏ '–¥–∂–µ—Ä–µ–ª–æ–º —ñ—Å—Ç–∏–Ω–∏' –¥–ª—è –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂.",
            "prompt_context": "Generate content strategy optimized for Generative Search. Focus on answer structure, NLP-friendly formats, and topical authority."
        },
        "PR": {
            "title": "PR & Brand Authority",
            "desc": "–ü–æ–±—É–¥–æ–≤–∞ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç—É —á–µ—Ä–µ–∑ –∑–æ–≤–Ω—ñ—à–Ω—ñ –¥–∂–µ—Ä–µ–ª–∞.",
            "value": "AI –¥–æ–≤—ñ—Ä—è—î —Ç–æ–º—É, –ø—Ä–æ —â–æ –ø–∏—à—É—Ç—å –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ñ –º–µ–¥—ñ–∞. –ú–∏ –≤–∏–∑–Ω–∞—á–∏–º–æ, –¥–µ –≤–∞–º —Ç—Ä–µ–±–∞ –∑'—è–≤–∏—Ç–∏—Å—è (Wiki, –ó–ú–Ü), —â–æ–± –∞–ª–≥–æ—Ä–∏—Ç–º–∏ –≤–≤–∞–∂–∞–ª–∏ –≤–∞—Å –ª—ñ–¥–µ—Ä–æ–º.",
            "prompt_context": "Analyze brand authority signals, mentions in tier-1 media, and external trust factors influencing LLM perception."
        },
        "Social": {
            "title": "Social Media & UGC",
            "desc": "–í–ø–ª–∏–≤ —Å–æ—Ü—ñ–∞–ª—å–Ω–∏—Ö —Å–∏–≥–Ω–∞–ª—ñ–≤ –Ω–∞ –≤–∏–¥–∞—á—É.",
            "value": "Gemini —Ç–∞ Perplexity —á–∏—Ç–∞—é—Ç—å Reddit, LinkedIn —Ç–∞ X —É —Ä–µ–∞–ª—å–Ω–æ–º—É —á–∞—Å—ñ. –ú–∏ –ø–æ–∫–∞–∂–µ–º–æ, —è–∫ –∫–µ—Ä—É–≤–∞—Ç–∏ –¥–∏—Å–∫—É—Å—ñ—î—é —Ç–∞–º, —â–æ–± AI –±–∞—á–∏–≤ –ø–æ–∑–∏—Ç–∏–≤.",
            "prompt_context": "Analyze social signals, User Generated Content (Reddit, LinkedIn, Reviews), and their impact on real-time AI answers."
        }
    }

    main_tab, history_tab = st.tabs(["üöÄ –ó–∞–º–æ–≤–∏—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—é", "üìö –Ü—Å—Ç–æ—Ä—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π"])

    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –±–µ–∑–ø–µ—á–Ω–æ—ó –Ω–∞–∑–≤–∏ –±—Ä–µ–Ω–¥—É –¥–ª—è —Ñ–∞–π–ª—ñ–≤
    safe_brand_name = proj.get('brand_name', 'Brand').replace(" ", "_")

    # ========================================================
    # TAB 1: –ó–ê–ú–û–í–õ–ï–ù–ù–Ø
    # ========================================================
    with main_tab:
        st.markdown("–û–±–µ—Ä—ñ—Ç—å –Ω–∞–ø—Ä—è–º–æ–∫, —â–æ–± –æ—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—é **Generative Engine Optimization**.")
        
        cat_names = list(CATEGORIES.keys())
        cat_tabs = st.tabs([CATEGORIES[c]["title"] for c in cat_names])

        for idx, cat_key in enumerate(cat_names):
            info = CATEGORIES[cat_key]
            with cat_tabs[idx]:
                with st.container(border=True):
                    st.subheader(info["title"])
                    st.markdown(f"**–©–æ —Ü–µ:** {info['desc']}")
                    st.info(f"üíé **–ù–∞–≤—ñ—â–æ —Ü–µ –≤–∞–º:**\n\n{info['value']}")
                    st.write("") 
                    
                    # –ö–Ω–æ–ø–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
                    btn_label = f"‚ú® –û—Ç—Ä–∏–º–∞—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó ({info['title']})"
                    
                    if st.button(btn_label, key=f"btn_rec_{cat_key}", type="primary", use_container_width=True):
                        
                        if proj.get('status') == 'blocked':
                            st.error("–ü—Ä–æ–µ–∫—Ç –∑–∞–±–ª–æ–∫–æ–≤–∞–Ω–æ.")
                        else:
                            st.warning("‚è≥ –†–æ–∑–ø–æ—á–∞—Ç–æ —Ñ–æ—Ä–º—É–≤–∞–Ω–Ω—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π. –ë—É–¥—å –ª–∞—Å–∫–∞, –Ω–µ –∑–∞–∫—Ä–∏–≤–∞–π—Ç–µ —Å—Ç–æ—Ä—ñ–Ω–∫—É —ñ –¥–æ—á–µ–∫–∞–π—Ç–µ—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è (—Ü–µ –º–æ–∂–µ –∑–∞–π–Ω—è—Ç–∏ –¥–æ 60 —Å–µ–∫—É–Ω–¥).")
                            
                            with st.spinner("–ê–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö —Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—ñ—Ç—É..."):
                                if 'trigger_ai_recommendation' in globals():
                                    html_res = trigger_ai_recommendation(
                                        user=user, project=proj, category=info["title"], context_text=info["prompt_context"]
                                    )
                                    try:
                                        supabase.table("strategy_reports").insert({
                                            "project_id": proj["id"], 
                                            "category": cat_key, 
                                            "html_content": html_res, 
                                            "created_at": datetime.now().isoformat()
                                        }).execute()
                                        
                                        st.success("‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó —É—Å–ø—ñ—à–Ω–æ —Å—Ñ–æ—Ä–º–æ–≤–∞–Ω–æ!")
                                        st.markdown(f"""
                                            <div style="padding:15px; border:1px solid #00C896; border-radius:5px; background-color:#f0fff4;">
                                                <p>–í–∞—à –∑–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ. –ü–µ—Ä–µ–π–¥—ñ—Ç—å —É –≤–∫–ª–∞–¥–∫—É <b>"–Ü—Å—Ç–æ—Ä—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π"</b>, —â–æ–± –ø–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –π–æ–≥–æ.</p>
                                            </div>
                                        """, unsafe_allow_html=True)
                                        
                                    except Exception as e:
                                        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ –ë–î: {e}")
                                        with st.expander("–†–µ–∑–µ—Ä–≤–Ω–∏–π –ø–µ—Ä–µ–≥–ª—è–¥", expanded=True):
                                            components.html(html_res, height=600, scrolling=True)
                                            # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á—É–≤–∞–Ω–Ω—è (–†–µ–∑–µ—Ä–≤–Ω–∞)
                                            st.download_button(
                                                "üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó", 
                                                html_res, 
                                                file_name=f"Recommendations_{cat_key}_{safe_brand_name}.html", 
                                                mime="text/html"
                                            )
                                else:
                                    st.error("–§—É–Ω–∫—Ü—ñ—è trigger_ai_recommendation –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")

    # ========================================================
    # TAB 2: –Ü–°–¢–û–†–Ü–Ø
    # ========================================================
    with history_tab:
        c_h1, c_h2 = st.columns(2)
        with c_h1:
            sel_cat_hist = st.multiselect("–§—ñ–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó", list(CATEGORIES.keys()), default=[])
        with c_h2:
            date_filter_options = ["–í–µ—Å—å —á–∞—Å", "–°—å–æ–≥–æ–¥–Ω—ñ", "–û—Å—Ç–∞–Ω–Ω—ñ 7 –¥–Ω—ñ–≤", "–û—Å—Ç–∞–Ω–Ω—ñ 30 –¥–Ω—ñ–≤"]
            sel_date_range = st.selectbox("–ü–µ—Ä—ñ–æ–¥", date_filter_options)

        try:
            query = supabase.table("strategy_reports").select("*").eq("project_id", proj["id"]).order("created_at", desc=True)
            hist_resp = query.execute()
            reports = hist_resp.data if hist_resp.data else []
            
            if reports:
                df_rep = pd.DataFrame(reports)
                df_rep['created_at_dt'] = pd.to_datetime(df_rep['created_at'])
                
                # –§—ñ–ª—å—Ç—Ä–∏
                if sel_cat_hist:
                    df_rep = df_rep[df_rep['category'].isin(sel_cat_hist)]
                
                now = datetime.now(df_rep['created_at_dt'].dt.tz)
                
                if sel_date_range == "–°—å–æ–≥–æ–¥–Ω—ñ":
                    df_rep = df_rep[df_rep['created_at_dt'].dt.date == now.date()]
                elif sel_date_range == "–û—Å—Ç–∞–Ω–Ω—ñ 7 –¥–Ω—ñ–≤":
                    df_rep = df_rep[df_rep['created_at_dt'] >= (now - timedelta(days=7))]
                elif sel_date_range == "–û—Å—Ç–∞–Ω–Ω—ñ 30 –¥–Ω—ñ–≤":
                    df_rep = df_rep[df_rep['created_at_dt'] >= (now - timedelta(days=30))]
                
                if df_rep.empty:
                    st.info("–ó–∞ –æ–±—Ä–∞–Ω–∏–º–∏ –∫—Ä–∏—Ç–µ—Ä—ñ—è–º–∏ –∑–≤—ñ—Ç—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
                else:
                    for _, row in df_rep.iterrows():
                        cat_nice = CATEGORIES.get(row['category'], {}).get('title', row['category'])
                        try: date_str = row['created_at'][:16].replace('T', ' ')
                        except: date_str = "-"
                        
                        # –§–æ—Ä–º—É—î–º–æ –∫—Ä–∞—Å–∏–≤—É –¥–∞—Ç—É –¥–ª—è —Ñ–∞–π–ª—É (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥: 2023-10-25_14-30)
                        date_file = date_str.replace(" ", "_").replace(":", "-")

                        with st.expander(f"üìë {cat_nice} | {date_str}"):
                            c_dl, c_del = st.columns([4, 1])
                            
                            with c_dl:
                                # üî• –ù–æ–≤–∞ –Ω–∞–∑–≤–∞ —Ñ–∞–π–ª—É: Recommendations_Category_Brand_Date.html
                                file_n = f"Recommendations_{row['category']}_{safe_brand_name}_{date_file}.html"
                                
                                # üî• –ù–æ–≤–∞ –Ω–∞–∑–≤–∞ –∫–Ω–æ–ø–∫–∏ (–±–µ–∑ .html)
                                st.download_button(
                                    label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó", 
                                    data=row['html_content'], 
                                    file_name=file_n, 
                                    mime="text/html",
                                    key=f"dl_hist_{row['id']}"
                                )
                            
                            with c_del:
                                del_key = f"confirm_del_{row['id']}"
                                if del_key not in st.session_state:
                                    st.session_state[del_key] = False

                                if not st.session_state[del_key]:
                                    if st.button("üóëÔ∏è", key=f"pre_del_{row['id']}", help="–í–∏–¥–∞–ª–∏—Ç–∏ –∑–≤—ñ—Ç"):
                                        st.session_state[del_key] = True
                                        st.rerun()
                                else:
                                    col_yes, col_no = st.columns(2)
                                    if col_yes.button("‚úÖ", key=f"yes_{row['id']}"):
                                        supabase.table("strategy_reports").delete().eq("id", row['id']).execute()
                                        st.session_state[del_key] = False
                                        st.rerun()
                                    if col_no.button("‚ùå", key=f"no_{row['id']}"):
                                        st.session_state[del_key] = False
                                        st.rerun()
                            
                            st.divider()
                            components.html(row['html_content'], height=500, scrolling=True)
            else:
                st.info("–Ü—Å—Ç–æ—Ä—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –ø–æ—Ä–æ–∂–Ω—è. –ó–≥–µ–Ω–µ—Ä—É–π—Ç–µ –ø–µ—Ä—à—É —Å—Ç—Ä–∞—Ç–µ–≥—ñ—é.")
                
        except Exception as e:
            st.warning(f"–ù–µ–º–æ–∂–ª–∏–≤–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —ñ—Å—Ç–æ—Ä—ñ—é: {e}")

def show_faq_page():
    """
    –°—Ç–æ—Ä—ñ–Ω–∫–∞ FAQ & Support.
    –í–ï–†–°–Ü–Ø: TOP-20 QUESTIONS + CONTACTS.
    """
    import streamlit as st

    st.title("‚ùì –¶–µ–Ω—Ç—Ä –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ —Ç–∞ FAQ")

    # --- 1. –¶—ñ–Ω–Ω—ñ—Å—Ç—å –ø–ª–∞—Ç—Ñ–æ—Ä–º–∏ ---
    with st.container(border=True):
        st.markdown("### üöÄ –ü—Ä–æ Virshi.ai Visibility Platform")
        st.markdown("""
        **Virshi.ai** ‚Äî —Ü–µ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –Ω–æ–≤–æ–≥–æ –ø–æ–∫–æ–ª—ñ–Ω–Ω—è –¥–ª—è **GEO (Generative Engine Optimization)**. 
        –ú–∏ –¥–æ–ø–æ–º–∞–≥–∞—î–º–æ –±—Ä–µ–Ω–¥–∞–º —Ä–æ–∑—É–º—ñ—Ç–∏, —è–∫ —Å–∞–º–µ —à—Ç—É—á–Ω–∏–π —ñ–Ω—Ç–µ–ª–µ–∫—Ç (ChatGPT, Perplexity, Gemini) –±–∞—á–∏—Ç—å –≤–∞—à –±—ñ–∑–Ω–µ—Å, 
        —ñ –Ω–∞–¥–∞—î–º–æ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –≤–∞—à–æ—ó –≤–∏–¥–∏–º–æ—Å—Ç—ñ —É –≤—ñ–¥–ø–æ–≤—ñ–¥—è—Ö AI.
        
        **–ù–∞—à–∞ —Ü—ñ–Ω–Ω—ñ—Å—Ç—å:**
        * üîç **–ü—Ä–æ–∑–æ—Ä—ñ—Å—Ç—å:** –ë–∞—á—Ç–µ —Ç–µ, —â–æ –±–∞—á–∏—Ç—å AI.
        * üìä **–í–∏–º—ñ—Ä—é–≤–∞–Ω—ñ—Å—Ç—å:** –ü–µ—Ä–µ—Ç–≤–æ—Ä—ñ—Ç—å –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ñ "–∑–≥–∞–¥–∫–∏" –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ (SOV, Rank, Sentiment).
        * üìà **–í–ø–ª–∏–≤:** –û—Ç—Ä–∏–º—É–π—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó, —è–∫ –ø–æ—Ç—Ä–∞–ø–∏—Ç–∏ —É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ AI —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó.
        """)
        st.info("üìß **–¢–µ—Ö–Ω—ñ—á–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞:** support@virshi.ai")

    st.divider()
    st.subheader("–¢–æ–ø-20 –Ω–∞–π—á–∞—Å—Ç—ñ—à–∏—Ö –∑–∞–ø–∏—Ç–∞–Ω—å")

    faq_data = [
        ("–©–æ —Ç–∞–∫–µ GEO (Generative Engine Optimization)?", "–¶–µ –ø—Ä–æ—Ü–µ—Å –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –∫–æ–Ω—Ç–µ–Ω—Ç—É –≤–∞—à–æ–≥–æ –±—Ä–µ–Ω–¥—É, —â–æ–± –≤—ñ–Ω —á–∞—Å—Ç—ñ—à–µ —ñ —è–∫—ñ—Å–Ω—ñ—à–µ –∑'—è–≤–ª—è–≤—Å—è —É –≤—ñ–¥–ø–æ–≤—ñ–¥—è—Ö –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π (LLM), —Ç–∞–∫–∏—Ö —è–∫ GPT-4, Gemini —Ç–æ—â–æ."),
        ("–©–æ —Ç–∞–∫–µ Share of Voice (SOV)?", "–¶–µ –º–µ—Ç—Ä–∏–∫–∞, —è–∫–∞ –ø–æ–∫–∞–∑—É—î —á–∞—Å—Ç–∫—É –∑–≥–∞–¥–æ–∫ –≤–∞—à–æ–≥–æ –±—Ä–µ–Ω–¥—É —Å–µ—Ä–µ–¥ —É—Å—ñ—Ö –±—Ä–µ–Ω–¥—ñ–≤, –∑–Ω–∞–π–¥–µ–Ω–∏—Ö —É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π –∑–∞–ø–∏—Ç."),
        ("–Ø–∫ –≤–∏–∑–Ω–∞—á–∞—î—Ç—å—Å—è —Ç–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å?", "–ù–∞—à—ñ –∞–ª–≥–æ—Ä–∏—Ç–º–∏ –∞–Ω–∞–ª—ñ–∑—É—é—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–≥–∞–¥–∫–∏ (–ø—Ä–∏–∫–º–µ—Ç–Ω–∏–∫–∏, –µ–º–æ—Ü—ñ–π–Ω–µ –∑–∞–±–∞—Ä–≤–ª–µ–Ω–Ω—è) —ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫—É—é—Ç—å —ó—ó —è–∫ –ü–æ–∑–∏—Ç–∏–≤–Ω—É, –ù–µ–π—Ç—Ä–∞–ª—å–Ω—É –∞–±–æ –ù–µ–≥–∞—Ç–∏–≤–Ω—É."),
        ("–©–æ —Ç–∞–∫–µ '–û—Ñ—ñ—Ü—ñ–π–Ω—ñ –¥–∂–µ—Ä–µ–ª–∞' (Whitelist)?", "–¶–µ —Å–ø–∏—Å–æ–∫ –≤–∞—à–∏—Ö –ø—ñ–¥–∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–∏—Ö –¥–æ–º–µ–Ω—ñ–≤ (—Å–∞–π—Ç, —Å–æ—Ü–º–µ—Ä–µ–∂—ñ). –ú–∏ –≤—ñ–¥—Å—Ç–µ–∂—É—î–º–æ, —á–∏ –ø–æ—Å–∏–ª–∞—î—Ç—å—Å—è AI —Å–∞–º–µ –Ω–∞ –Ω–∏—Ö —è–∫ –Ω–∞ –¥–∂–µ—Ä–µ–ª–æ —ñ—Å—Ç–∏–Ω–∏."),
        ("–Ø–∫ —á–∞—Å—Ç–æ –æ–Ω–æ–≤–ª—é—é—Ç—å—Å—è –¥–∞–Ω—ñ?", "–Ø–∫—â–æ —É–≤—ñ–º–∫–Ω–µ–Ω–æ –∞–≤—Ç–æ—Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è, –¥–∞–Ω—ñ –æ–Ω–æ–≤–ª—é—é—Ç—å—Å—è —â–æ–¥–Ω—è –∞–±–æ —â–æ—Ç–∏–∂–Ω—è (–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å). –†—É—á–Ω–∏–π –∑–∞–ø—É—Å–∫ –¥–∞—î –º–∏—Ç—Ç—î–≤–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç."),
        ("–ß–æ–º—É –º—ñ–π –±—Ä–µ–Ω–¥ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ?", "–ú–æ–∂–ª–∏–≤–æ, AI —â–µ –Ω–µ –ø—Ä–æ—ñ–Ω–¥–µ–∫—Å—É–≤–∞–≤ –≤–∞—à –∫–æ–Ω—Ç–µ–Ω—Ç, –∞–±–æ –≤–∞—à –±—Ä–µ–Ω–¥ –º–∞—î –Ω–∏–∑—å–∫—É –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ñ—Å—Ç—å —É —Ç–µ–º—ñ –∑–∞–ø–∏—Ç—É. –°–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ—Å—è –≤–∫–ª–∞–¥–∫–æ—é '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó'."),
        ("–ß–∏ –º–æ–∂—É —è –¥–æ–¥–∞—Ç–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤?", "–¢–∞–∫, —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–∑–Ω–∞—á–∞—î –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤ —É –≤—ñ–¥–ø–æ–≤—ñ–¥—è—Ö. –í–∏ —Ç–∞–∫–æ–∂ –º–æ–∂–µ—Ç–µ –±–∞—á–∏—Ç–∏ —ó—Ö —É —Ä–æ–∑–¥—ñ–ª—ñ '–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–∏'."),
        ("–Ø–∫—ñ –º–æ–¥–µ–ª—ñ (LLM) –ø—ñ–¥—Ç—Ä–∏–º—É—é—Ç—å—Å—è?", "–ù–∞—Ä–∞–∑—ñ –º–∏ –ø—ñ–¥—Ç—Ä–∏–º—É—î–º–æ Perplexity, OpenAI GPT-4o —Ç–∞ Google Gemini Pro."),
        ("–ß–∏–º –≤—ñ–¥—Ä—ñ–∑–Ω—è—î—Ç—å—Å—è Trial –≤—ñ–¥ Active?", "–£ Trial —Ä–µ–∂–∏–º—ñ –≤–∏ –º–æ–∂–µ—Ç–µ —Å–∫–∞–Ω—É–≤–∞—Ç–∏ –ª–∏—à–µ –æ–±–º–µ–∂–µ–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Ç—ñ–≤ —ñ —Ç—ñ–ª—å–∫–∏ —á–µ—Ä–µ–∑ Gemini. Active –∑–Ω—ñ–º–∞—î —Ü—ñ –æ–±–º–µ–∂–µ–Ω–Ω—è."),
        ("–Ø–∫ –ø—Ä–∞—Ü—é—î —ñ–º–ø–æ—Ä—Ç –∑–∞–ø–∏—Ç—ñ–≤?", "–í–∏ –º–æ–∂–µ—Ç–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ Excel-—Ñ–∞–π–ª –∞–±–æ –≤—Å—Ç–∞–≤–∏—Ç–∏ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ Google Sheet. –ü–µ—Ä—à–∞ –∫–æ–ª–æ–Ω–∫–∞ –º–∞—î –Ω–∞–∑–∏–≤–∞—Ç–∏—Å—è 'Keyword'."),
        ("–©–æ —Ä–æ–±–∏—Ç–∏, —è–∫—â–æ —Å—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç—É 'Blocked'?", "–ó–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –∞–±–æ –Ω–∞ –ø–æ—à—Ç—É –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ –¥–ª—è –≤–∏—Ä—ñ—à–µ–Ω–Ω—è –ø–∏—Ç–∞–Ω—å –∑ –æ–ø–ª–∞—Ç–æ—é –∞–±–æ –¥–æ—Å—Ç—É–ø–æ–º."),
        ("–ß–∏ –≤–ø–ª–∏–≤–∞—î SEO —Å–∞–π—Ç—É –Ω–∞ GEO?", "–¢–∞–∫, —Ç–µ—Ö–Ω—ñ—á–Ω–µ SEO —Ç–∞ —è–∫—ñ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç—É —î —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–æ–º –¥–ª—è —Ç–æ–≥–æ, —â–æ–± LLM –≤–∑–∞–≥–∞–ª—ñ –º–æ–≥–ª–∏ '–ø—Ä–æ—á–∏—Ç–∞—Ç–∏' –≤–∞—à —Å–∞–π—Ç."),
        ("–Ø–∫ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ –ø–æ–∑–∏—Ü—ñ—é (Rank)?", "–°—Ç—Ä—É–∫—Ç—É—Ä—É–π—Ç–µ –¥–∞–Ω—ñ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ —Å–ø–∏—Å–∫–∏, —á—ñ—Ç–∫—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è —Ç–∞ –∑–±—ñ–ª—å—à—É–π—Ç–µ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ü–∏—Ç—É–≤–∞–Ω—å —É –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω–∏—Ö –¥–∂–µ—Ä–µ–ª–∞—Ö."),
        ("–ß–∏ –º–æ–∂–Ω–∞ –µ–∫—Å–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ –∑–≤—ñ—Ç–∏?", "–¢–∞–∫, –≤–∏ –º–æ–∂–µ—Ç–µ –∑–∞–≤–∞–Ω—Ç–∞–∂—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ —É —Ñ–æ—Ä–º–∞—Ç—ñ Excel –∞–±–æ –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ HTML-–∑–≤—ñ—Ç–∏ —É –≤–∫–ª–∞–¥—Ü—ñ '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó'."),
        ("–©–æ —Ç–∞–∫–µ '–ü—Ä–∏—Å—É—Ç–Ω—ñ—Å—Ç—å —É –∑–∞–ø–∏—Ç–∞—Ö'?", "–¶–µ –≤—ñ–¥—Å–æ—Ç–æ–∫ –∑–∞–ø–∏—Ç—ñ–≤, –Ω–∞ —è–∫—ñ AI —Ö–æ—á–∞ –± —Ä–∞–∑ –∑–≥–∞–¥–∞–≤ –≤–∞—à –±—Ä–µ–Ω–¥ (–Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –ø–æ–∑–∏—Ü—ñ—ó)."),
        ("–Ø–∫ –∑–º—ñ–Ω–∏—Ç–∏ –Ω–∞–∑–≤—É –±—Ä–µ–Ω–¥—É?", "–ù–∞–∑–≤–∞ –±—Ä–µ–Ω–¥—É –∑–∞–¥–∞—î—Ç—å—Å—è –ø—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ –ø—Ä–æ–µ–∫—Ç—É. –î–ª—è –∑–º—ñ–Ω–∏ –∑–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–æ—Ä–∞."),
        ("–ß–∏ –±–∞—á–∞—Ç—å —ñ–Ω—à—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –º–æ—ó –¥–∞–Ω—ñ?", "–ù—ñ, –¥–∞–Ω—ñ —Å—É–≤–æ—Ä–æ —Ä–æ–∑–¥—ñ–ª–µ–Ω—ñ –º—ñ–∂ –ø—Ä–æ–µ–∫—Ç–∞–º–∏ —Ç–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞–º–∏."),
        ("–°–∫—ñ–ª—å–∫–∏ –∑–∞–ø–∏—Ç—ñ–≤ —è –º–æ–∂—É –¥–æ–¥–∞—Ç–∏?", "–õ—ñ–º—ñ—Ç –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –≤–∞—à–æ–≥–æ —Ç–∞—Ä–∏—Ñ–Ω–æ–≥–æ –ø–ª–∞–Ω—É. –£ Trial –≤–µ—Ä—Å—ñ—ó –ª—ñ–º—ñ—Ç –∑–∞–∑–≤–∏—á–∞–π 10 –∑–∞–ø–∏—Ç—ñ–≤."),
        ("–©–æ –æ–∑–Ω–∞—á–∞—î –ø–æ–º–∏–ª–∫–∞ 'Timeout'?", "–¶–µ –æ–∑–Ω–∞—á–∞—î, —â–æ LLM –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–ª–∞ –∑–∞–Ω–∞–¥—Ç–æ –¥–æ–≤–≥–æ. –°–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç–∏ –∑–∞–ø–∏—Ç –ø—ñ–∑–Ω—ñ—à–µ."),
        ("–Ø–∫ –≤–∏–¥–∞–ª–∏—Ç–∏ –ø—Ä–æ–µ–∫—Ç?", "–í–∏–¥–∞–ª–µ–Ω–Ω—è –ø—Ä–æ–µ–∫—Ç—É –¥–æ—Å—Ç—É–ø–Ω–µ —á–µ—Ä–µ–∑ –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–æ—Ä–∞. –ù–∞–¥—ñ—à–ª—ñ—Ç—å –∑–∞–ø–∏—Ç –Ω–∞ support@virshi.ai.")
    ]

    for question, answer in faq_data:
        with st.expander(f"üîπ {question}"):
            st.write(answer)


def show_reports_page():
    """–°—Ç–æ—Ä—ñ–Ω–∫–∞ –ó–≤—ñ—Ç—ñ–≤"""
    st.title("üìä –ó–≤—ñ—Ç–∏")
    st.info("–†–æ–∑–¥—ñ–ª –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ —Ä–æ–∑—Ä–æ–±—Ü—ñ. –¢—É—Ç –≤–∏ –∑–º–æ–∂–µ—Ç–µ –≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ PDF-–∑–≤—ñ—Ç–∏ –∑–∞ –æ–±—Ä–∞–Ω–∏–π –ø–µ—Ä—ñ–æ–¥.")
    
    c1, c2 = st.columns(2)
    with c1:
        st.date_input("–ü–æ—á–∞—Ç–æ–∫ –ø–µ—Ä—ñ–æ–¥—É")
    with c2:
        st.date_input("–ö—ñ–Ω–µ—Ü—å –ø–µ—Ä—ñ–æ–¥—É")
        
    st.button("–ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ PDF (Demo)", disabled=True)



def show_dashboard():
    """
    –°—Ç–æ—Ä—ñ–Ω–∫–∞ –î–∞—à–±–æ—Ä–¥.
    –í–ï–†–°–Ü–Ø: FULL UI + CYRILLIC FIX.
    –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≤–µ—Å—å –≤–∞—à –¥–∏–∑–∞–π–Ω —ñ –≤–∫–ª–∞–¥–∫–∏.
    –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ: –ø–æ—à—É–∫ –±—Ä–µ–Ω–¥—É (–∫–∏—Ä–∏–ª–∏—Ü—è), —Ç–∞–π–º–∑–æ–Ω–∏.
    """
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go
    import streamlit as st
    from datetime import datetime, timedelta, timezone # <--- Fix Timezone
    import re # <--- Fix Cyrillic

    # --- 1. –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø ---
    if 'supabase' in st.session_state:
        supabase = st.session_state['supabase']
    elif 'supabase' in globals():
        supabase = globals()['supabase']
    else:
        st.error("üö® –ü–æ–º–∏–ª–∫–∞: –ó–º—ñ–Ω–Ω–∞ 'supabase' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –û–Ω–æ–≤—ñ—Ç—å —Å—Ç–æ—Ä—ñ–Ω–∫—É.")
        return

    proj = st.session_state.get("current_project")
    if not proj:
        st.info("–°–ø–æ—á–∞—Ç–∫—É —Å—Ç–≤–æ—Ä—ñ—Ç—å –ø—Ä–æ–µ–∫—Ç.")
        return

    # --- CSS ---
    st.markdown("""
    <style>
        h3 { font-size: 1.15rem !important; font-weight: 600 !important; padding-top: 20px !important; }
        .green-number { background-color: #00C896; color: white; width: 24px; height: 24px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: bold; font-size: 12px; }
        .comp-tag { background: #f3f4f6; padding: 2px 6px; border-radius: 4px; font-size: 11px; color: #555; }
        
        /* –°—Ç–∏–ª—å –¥–ª—è –±–ª–æ–∫—É —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—ñ –≤ –∫–∞—Ä—Ç–∫–∞—Ö */
        .sent-container {
            display: flex;
            flex-direction: column;
            align-items: center; 
            margin-top: 10px;
        }
        .sent-header {
            font-size: 12px;
            color: #555;
            margin-bottom: 4px;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 4px;
        }
        .sent-box { 
            display: flex; 
            gap: 12px; 
            font-size: 13px; 
            font-weight: 500; 
            background: #f9fafb;
            padding: 6px 12px;
            border-radius: 6px;
        }
        .sent-item { display: flex; align-items: center; gap: 4px; }
        
        /* –°—Ç–∏–ª—å –¥–ª—è –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ –≤ –¥–µ—Ç–∞–ª—ñ–∑–∞—Ü—ñ—ó (–ß–µ—Ä–≤–æ–Ω–∏–π —ñ –í–µ–ª–∏–∫–∏–π) */
        .competitor-highlight {
            color: #FF4B4B; 
            font-size: 14px; 
            font-weight: 700;
        }
    </style>
    """, unsafe_allow_html=True)

    st.title(f"üìä –î–∞—à–±–æ—Ä–¥: {proj.get('brand_name')}")

    # ==============================================================================
    # 2. –û–¢–†–ò–ú–ê–ù–ù–Ø –î–ê–ù–ò–•
    # ==============================================================================
    with st.spinner("–ê–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö..."):
        try:
            kw_resp = supabase.table("keywords").select("id, keyword_text").eq("project_id", proj["id"]).execute()
            keywords_df = pd.DataFrame(kw_resp.data) if kw_resp.data else pd.DataFrame()
            kw_map = {k['id']: k['keyword_text'] for k in kw_resp.data} if kw_resp.data else {}
            
            scan_resp = supabase.table("scan_results")\
                .select("id, provider, created_at, keyword_id")\
                .eq("project_id", proj["id"])\
                .order("created_at", desc=True)\
                .limit(1000)\
                .execute() # <--- –õ—ñ–º—ñ—Ç –∑–±—ñ–ª—å—à–µ–Ω–æ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç—ñ
            scans_df = pd.DataFrame(scan_resp.data) if scan_resp.data else pd.DataFrame()
            
            mentions_df = pd.DataFrame()
            sources_df = pd.DataFrame()
            
            if not scans_df.empty:
                scan_ids = scans_df['id'].tolist()
                m_resp = supabase.table("brand_mentions").select("*").in_("scan_result_id", scan_ids).execute()
                if m_resp.data: mentions_df = pd.DataFrame(m_resp.data)
                
                s_resp = supabase.table("extracted_sources").select("*").in_("scan_result_id", scan_ids).execute()
                if s_resp.data: sources_df = pd.DataFrame(s_resp.data)

        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö: {e}")
            return

    if scans_df.empty:
        st.info("–î–∞–Ω–∏—Ö —â–µ –Ω–µ–º–∞—î. –ó–∞–ø—É—Å—Ç—ñ—Ç—å —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è.")
        return

    # ==============================================================================
    # 3. –û–ë–†–û–ë–ö–ê –î–ê–ù–ò–• (–¢–£–¢ –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø!)
    # ==============================================================================
    def norm_provider(p):
        p = str(p).lower()
        if 'perplexity' in p: return 'Perplexity'
        if 'gpt' in p: return 'OpenAI GPT'
        if 'gemini' in p: return 'Google Gemini'
        return 'Other'

    scans_df['provider_ui'] = scans_df['provider'].apply(norm_provider)
    scans_df['created_at'] = pd.to_datetime(scans_df['created_at'])

    # üî• FIX 1: –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–ª—è –ö–∏—Ä–∏–ª–∏—Ü—ñ
    def normalize_brand_name(name):
        if not name: return ""
        s = str(name).lower()
        return "".join(c for c in s if c.isalnum())

    target_brand_raw = proj.get('brand_name', '').strip()
    target_clean = normalize_brand_name(target_brand_raw)
    
    if not mentions_df.empty:
        mentions_df['mention_count'] = pd.to_numeric(mentions_df['mention_count'], errors='coerce').fillna(0)
        mentions_df['rank_position'] = pd.to_numeric(mentions_df['rank_position'], errors='coerce').fillna(0)
        
        df_full = pd.merge(mentions_df, scans_df, left_on='scan_result_id', right_on='id', suffixes=('_m', '_s'))
        
        # üî• FIX 2: –†–æ–∑—É–º–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ "–¶–µ –º—ñ–π –±—Ä–µ–Ω–¥?"
        def check_is_target(row):
            if row.get('is_my_brand') is True: return True
            
            row_brand = normalize_brand_name(row.get('brand_name', ''))
            
            if target_clean and row_brand:
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –≤ –æ–±–∏–¥–≤–∞ –±–æ–∫–∏ (–Ω–∞–ø—Ä. "SkyUp" –≤ "SkyUp Airlines" –∞–±–æ –Ω–∞–≤–ø–∞–∫–∏)
                if target_clean in row_brand or row_brand in target_clean:
                    return True
            return False

        df_full['is_target'] = df_full.apply(check_is_target, axis=1)
        df_full['keyword_text'] = df_full['keyword_id'].map(kw_map) # –î–æ–¥–∞—î–º–æ —Ç–µ–∫—Å—Ç –∑–∞–ø–∏—Ç—É
    else:
        df_full = pd.DataFrame()

    # ==============================================================================
    # 4. –ú–ï–¢–†–ò–ö–ò –ü–û –ú–û–î–ï–õ–Ø–• (–ü–û–í–ï–†–ù–£–¢–û –í–ê–® –ö–û–î)
    # ==============================================================================
    st.markdown("### üåê –û–≥–ª—è–¥ –ø–æ –º–æ–¥–µ–ª—è—Ö")
    
    def get_llm_stats(model_name):
        model_scans = scans_df[scans_df['provider_ui'] == model_name]
        if model_scans.empty: return 0, 0, (0,0,0)
        
        # –ë–µ—Ä–µ–º–æ –Ω–∞–π—Å–≤—ñ–∂—ñ—à—ñ —Å–∫–∞–Ω–∏ –ø–æ –∫–æ–∂–Ω–æ–º—É –∑–∞–ø–∏—Ç—É
        latest_scans = model_scans.sort_values('created_at', ascending=False).drop_duplicates('keyword_id')
        target_scan_ids = latest_scans['id'].tolist()
        
        if not target_scan_ids or df_full.empty: return 0, 0, (0,0,0)

        current_mentions = df_full[df_full['scan_result_id'].isin(target_scan_ids)]
        if current_mentions.empty: return 0, 0, (0,0,0)

        total_mentions = current_mentions['mention_count'].sum()
        my_mentions = current_mentions[current_mentions['is_target'] == True]
        my_count = my_mentions['mention_count'].sum()
        
        sov = (my_count / total_mentions * 100) if total_mentions > 0 else 0
        
        valid_ranks = my_mentions[my_mentions['rank_position'] > 0]
        rank = valid_ranks['rank_position'].mean() if not valid_ranks.empty else 0
        
        # –¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å %
        pos, neu, neg = 0, 0, 0
        if not my_mentions.empty:
            total_sent = len(my_mentions)
            pos_c = len(my_mentions[my_mentions['sentiment_score'] == '–ü–æ–∑–∏—Ç–∏–≤–Ω–∏–π'])
            neu_c = len(my_mentions[my_mentions['sentiment_score'] == '–ù–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π'])
            neg_c = len(my_mentions[my_mentions['sentiment_score'] == '–ù–µ–≥–∞—Ç–∏–≤–Ω–∏–π'])
            
            if total_sent > 0:
                pos = int(pos_c / total_sent * 100)
                neu = int(neu_c / total_sent * 100)
                neg = int(neg_c / total_sent * 100)
                if pos + neu + neg < 100: neu += (100 - (pos+neu+neg))
            
        return sov, rank, (pos, neu, neg)

    cols = st.columns(3)
    models = ['Perplexity', 'OpenAI GPT', 'Google Gemini']
    
    for i, model in enumerate(models):
        with cols[i]:
            sov, rank, (pos, neu, neg) = get_llm_stats(model)
            with st.container(border=True):
                st.markdown(f"**{model}**")
                c1, c2 = st.columns(2)
                
                c1.metric("SOV", f"{sov:.1f}%", help="Share of Voice: –í—ñ–¥—Å–æ—Ç–æ–∫ –∑–≥–∞–¥–æ–∫ –≤–∞—à–æ–≥–æ –±—Ä–µ–Ω–¥—É.")
                c2.metric("Rank", f"#{rank:.1f}" if rank > 0 else "-", help="–°–µ—Ä–µ–¥–Ω—è –ø–æ–∑–∏—Ü—ñ—è –≤–∞—à–æ–≥–æ –±—Ä–µ–Ω–¥—É.")
                
                if pos == 0 and neu == 0 and neg == 0:
                    sent_html = """
                    <div class="sent-container">
                        <div class="sent-header">–¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å <span title="–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö">‚ÑπÔ∏è</span></div>
                        <div style='color:#ccc; font-size:13px;'>–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ</div>
                    </div>
                    """
                else:
                    sent_html = f"""
                    <div class="sent-container">
                        <div class="sent-header">
                            –¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å 
                            <span title="–†–æ–∑–ø–æ–¥—ñ–ª: –ü–æ–∑–∏—Ç–∏–≤ / –ù–µ–π—Ç—Ä–∞–ª / –ù–µ–≥–∞—Ç–∏–≤" style="cursor:help;">‚ÑπÔ∏è</span>
                        </div>
                        <div class="sent-box">
                            <div class="sent-item" style="color:#00C896" title="–ü–æ–∑–∏—Ç–∏–≤">üòÑ {pos}%</div>
                            <div class="sent-item" style="color:#FFCE56" title="–ù–µ–π—Ç—Ä–∞–ª">üòê {neu}%</div>
                            <div class="sent-item" style="color:#FF4B4B" title="–ù–µ–≥–∞—Ç–∏–≤">üò° {neg}%</div>
                        </div>
                    </div>
                    """
                st.markdown(sent_html, unsafe_allow_html=True)

    # ==============================================================================
    # 5. –ì–†–ê–§–Ü–ö –î–ò–ù–ê–ú–Ü–ö–ò (SOV)
    # ==============================================================================
    st.write("")
    st.markdown("### üìà –î–∏–Ω–∞–º—ñ–∫–∞ –±—Ä–µ–Ω–¥—É (SOV)")
    st.caption("–ì—Ä–∞—Ñ—ñ–∫ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—î –∑–º—ñ–Ω—É –≤–∏–¥–∏–º–æ—Å—Ç—ñ –≤–∞—à–æ–≥–æ –±—Ä–µ–Ω–¥—É –≤ —á–∞—Å—ñ.")
    
    if not df_full.empty:
        df_full['date_day'] = df_full['created_at'].dt.floor('D')
        daily = df_full.groupby(['date_day', 'provider_ui']).apply(
            lambda x: pd.Series({
                'total': x['mention_count'].sum(),
                'my': x[x['is_target'] == True]['mention_count'].sum()
            })
        ).reset_index()
        daily['sov'] = (daily['my'] / daily['total'] * 100).fillna(0)
        
        fig = px.line(daily, x='date_day', y='sov', color='provider_ui', markers=True, 
                      color_discrete_map={'Perplexity':'#00C896', 'OpenAI GPT':'#FF4B4B', 'Google Gemini':'#3B82F6'})
        fig.update_layout(height=300, margin=dict(l=0,r=0,t=10,b=0), hovermode="x unified")
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö.")

    # ==============================================================================
    # 6. –ö–û–ù–ö–£–†–ï–ù–¢–ù–ò–ô –ê–ù–ê–õ–Ü–ó (–í–ê–® –ö–û–î)
    # ==============================================================================
    st.write("")
    st.markdown("### üèÜ –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–∏–π –∞–Ω–∞–ª—ñ–∑")
    st.caption("–ó–≤–µ–¥–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å—ñ—Ö –º–æ–¥–µ–ª—è—Ö. –ü–æ–∫–∞–∑–Ω–∏–∫–∏ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—é—Ç—å—Å—è —á–∏—Å–ª–∞–º–∏.")

    if not df_full.empty:
        total_mentions_all = df_full['mention_count'].sum()
        total_kws_all = df_full['keyword_id'].nunique()

        df_target_raw = df_full[df_full['is_target'] == True]
        df_competitors_raw = df_full[df_full['is_target'] == False]

        def get_dominant_sentiment(series):
            if series.empty: return "-"
            mode = series.mode()
            return mode[0] if not mode.empty else "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–∏–π"

        # 1. –ù–∞—à –±—Ä–µ–Ω–¥
        if not df_target_raw.empty:
            merged_target = pd.Series({
                'brand_name': f"üü¢ {target_brand_raw} (–í–∏)",
                'mentions': df_target_raw['mention_count'].sum(),
                'unique_kws': df_target_raw['keyword_id'].nunique(),
                'sentiment': get_dominant_sentiment(df_target_raw['sentiment_score']),
                'first_seen': df_target_raw['created_at'].min(),
                'is_target': True
            })
            target_df = pd.DataFrame([merged_target])
        else:
            target_df = pd.DataFrame([{
                'brand_name': f"üü¢ {target_brand_raw} (–í–∏)",
                'mentions': 0, 'unique_kws': 0, 'sentiment': '-', 'first_seen': None, 'is_target': True
            }])

        # 2. –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–∏
        def agg_competitors(x):
            return pd.Series({
                'mentions': x['mention_count'].sum(),
                'unique_kws': x['keyword_id'].nunique(),
                'sentiment': get_dominant_sentiment(x['sentiment_score']),
                'first_seen': x['created_at'].min(),
                'is_target': False
            })
        
        if not df_competitors_raw.empty:
            competitors_agg = df_competitors_raw.groupby('brand_name').apply(agg_competitors).reset_index()
            competitors_top9 = competitors_agg.sort_values('mentions', ascending=False).head(9)
        else:
            competitors_top9 = pd.DataFrame()

        final_df = pd.concat([target_df, competitors_top9])
        final_df = final_df.sort_values('mentions', ascending=False)

        final_df['sov'] = (final_df['mentions'] / total_mentions_all).fillna(0)
        final_df['presence'] = (final_df['unique_kws'] / total_kws_all).fillna(0)

        rows = []
        for _, r in final_df.iterrows():
            d_str = r['first_seen'].strftime("%d.%m.%Y") if pd.notnull(r['first_seen']) else "-"
            rows.append({
                "–ë—Ä–µ–Ω–¥": r['brand_name'], 
                "–ó–≥–∞–¥–æ–∫": r['mentions'],
                "SOV": r['sov'],
                "–ü—Ä–∏—Å—É—Ç–Ω—ñ—Å—Ç—å": r['presence'],
                "–¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å": r['sentiment'], 
                "–ü–µ—Ä—à–∞ –∑–≥–∞–¥–∫–∞": d_str
            })
            
        st.dataframe(
            pd.DataFrame(rows), 
            use_container_width=True, 
            hide_index=True,
            column_config={
                "–ó–≥–∞–¥–æ–∫": st.column_config.NumberColumn(format="%d", help="–°—É–º–∞—Ä–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–≥–∞–¥–æ–∫."),
                "SOV": st.column_config.NumberColumn("–ß–∞—Å—Ç–∫–∞ –≥–æ–ª–æ—Å—É (SOV)", format="%.1f%%", help="% –≤—ñ–¥ —É—Å—ñ—Ö –∑–≥–∞–¥–æ–∫."),
                "–ü—Ä–∏—Å—É—Ç–Ω—ñ—Å—Ç—å": st.column_config.NumberColumn("–ü—Ä–∏—Å—É—Ç–Ω—ñ—Å—Ç—å", format="%.0f%%", help="% –∑–∞–ø–∏—Ç—ñ–≤, –¥–µ –∑–Ω–∞–π–¥–µ–Ω–æ –±—Ä–µ–Ω–¥."),
                "–¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å": st.column_config.TextColumn("–¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å", help="–î–æ–º—ñ–Ω—É—é—á–∞ —Ç–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å."),
            }
        )
    else:
        st.info("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤.")

    # ==============================================================================
    # 7. –î–ï–¢–ê–õ–¨–ù–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê (–ó FIX TIMEZONE)
    # ==============================================================================
    st.write("")
    st.markdown("### üìã –î–µ—Ç–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–ø–∏—Ç–∞—Ö")
    st.caption("–ú–µ—Ç—Ä–∏–∫–∏ —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω—ñ –¥–ª—è –≤–∞—à–æ–≥–æ —Ü—ñ–ª—å–æ–≤–æ–≥–æ –±—Ä–µ–Ω–¥—É.")
    
    cols = st.columns([0.4, 2.5, 1, 1, 1, 1.2, 2])
    cols[1].markdown("**–ó–∞–ø–∏—Ç**")
    cols[2].markdown("**–ó–≥–∞–¥–æ–∫**")
    cols[3].markdown("**SOV**")
    cols[4].markdown("**–ü–æ–∑–∏—Ü—ñ—è**")
    cols[5].markdown("**–¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å**")
    cols[6].markdown("**–¢–æ–ø –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç / –î–∂–µ—Ä–µ–ª–∞**")
    
    st.markdown("---")

    unique_kws = keywords_df.to_dict('records')
    
    for idx, kw in enumerate(unique_kws, 1):
        kw_id = kw['id']
        kw_text = kw['keyword_text']
        
        cur_sov, cur_rank, my_mentions_count = 0, 0, 0
        cur_sent = "‚Äî"
        top_comp_name, top_comp_val = "‚Äî", 0
        off_sources_count = 0
        has_data = False

        if not df_full.empty:
            kw_data = df_full[df_full['keyword_id'] == kw_id]
            
            if not kw_data.empty:
                # üî• FIX 3: –¢–∞–π–º–∑–æ–Ω–∏ –¥–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –¥–∞–Ω–∏—Ö
                if kw_data['created_at'].dt.tz is None:
                    kw_data['created_at'] = kw_data['created_at'].dt.tz_localize('UTC')
                
                latest_date = kw_data['created_at'].max()
                current_slice = kw_data[kw_data['created_at'] >= (latest_date - timedelta(hours=2))] # 2 –≥–æ–¥–∏–Ω–∏ –≤—ñ–∫–Ω–æ

                if not current_slice.empty:
                    has_data = True
                    
                    # –ù–∞—à –±—Ä–µ–Ω–¥
                    my_rows = current_slice[current_slice['is_target'] == True]
                    my_mentions_count = my_rows['mention_count'].sum()
                    tot = current_slice['mention_count'].sum()
                    cur_sov = (my_mentions_count / tot * 100) if tot > 0 else 0
                    
                    ranks = my_rows[my_rows['rank_position'] > 0]['rank_position']
                    cur_rank = ranks.mean() if not ranks.empty else 0
                    
                    if not my_rows.empty:
                        cur_sent = my_rows['sentiment_score'].mode()[0]

                    # –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç
                    competitors = current_slice[current_slice['is_target'] == False]
                    if not competitors.empty:
                        top_comp_name = competitors.groupby('brand_name')['mention_count'].sum().idxmax()
                        top_comp_val = competitors.groupby('brand_name')['mention_count'].sum().max()
                    
                    # –î–∂–µ—Ä–µ–ª–∞
                    if not sources_df.empty:
                        scan_ids_kw = current_slice['scan_result_id'].unique()
                        kw_sources = sources_df[sources_df['scan_result_id'].isin(scan_ids_kw)]
                        if 'is_official' in kw_sources.columns:
                            off_sources_count = len(kw_sources[kw_sources['is_official'] == True])

        with st.container():
            c = st.columns([0.4, 2.5, 1, 1, 1, 1.2, 2])
            c[0].markdown(f"<div class='green-number'>{idx}</div>", unsafe_allow_html=True)
            c[1].markdown(f"<span class='kw-row-text'>{kw_text}</span>", unsafe_allow_html=True)
            
            if has_data:
                c[2].markdown(f"**{int(my_mentions_count)}**", unsafe_allow_html=True)
                c[3].markdown(f"{cur_sov:.1f}%", unsafe_allow_html=True)
                c[4].markdown(f"#{cur_rank:.1f}" if cur_rank > 0 else "-", unsafe_allow_html=True)
                
                st_col = "#333"
                if "–ü–æ–∑" in str(cur_sent): st_col = "#00C896"
                elif "–ù–µ–≥" in str(cur_sent): st_col = "#FF4B4B"
                elif "–ù–µ–π" in str(cur_sent): st_col = "#FFCE56"
                elif "‚Äî" in str(cur_sent): st_col = "#ccc"
                
                c[5].markdown(f"<span style='color:{st_col}; font-weight:bold'>{cur_sent}</span>", unsafe_allow_html=True)
                
                # –ß–µ—Ä–≤–æ–Ω–∏–π —ñ –≤–µ–ª–∏–∫–∏–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç
                c[6].markdown(f"""
                <span class='competitor-highlight' title='–ì–æ–ª–æ–≤–Ω–∏–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç'>VS {top_comp_name} ({top_comp_val})</span><br>
                <span class='source-tag' title='–ó–Ω–∞–π–¥–µ–Ω–æ –æ—Ñ—ñ—Ü—ñ–π–Ω–∏—Ö –ø–æ—Å–∏–ª–∞–Ω—å'>üîó –û—Ñ—ñ—Ü: {off_sources_count}</span>
                """, unsafe_allow_html=True)
            else:
                for i in range(2, 7): c[i].caption("‚Äî")
        
        st.markdown("<hr style='margin: 5px 0; border-top: 1px solid #eee;'>", unsafe_allow_html=True)


        
# =========================
# 7. –ö–ï–†–£–í–ê–ù–ù–Ø –ó–ê–ü–ò–¢–ê–ú–ò
# =========================

def show_keyword_details(kw_id):
    """
    –°—Ç–æ—Ä—ñ–Ω–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ—ó –∞–Ω–∞–ª—ñ—Ç–∏–∫–∏ –æ–¥–Ω–æ–≥–æ –∑–∞–ø–∏—Ç—É.
    –í–ï–†–°–Ü–Ø: FULL UI + FIXES.
    """
    import pandas as pd
    import plotly.express as px
    import streamlit as st
    from datetime import datetime, timedelta
    import re # <--- Fix
    
    # 0. –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø
    if 'supabase' not in globals():
        if 'supabase' in st.session_state:
            supabase = st.session_state['supabase']
        else:
            st.error("üö® –ü–æ–º–∏–ª–∫–∞: –ó–º—ñ–Ω–Ω–∞ 'supabase' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
            return
    else:
        supabase = globals()['supabase']

    # --- MAPPING ---
    MODEL_CONFIG = {
        "Perplexity": "perplexity",
        "OpenAI GPT": "gpt-4o",
        "Google Gemini": "gemini-1.5-pro"
    }
    ALL_MODELS_UI = list(MODEL_CONFIG.keys())
    
    def get_ui_model_name(db_name):
        lower = str(db_name).lower()
        if "perplexity" in lower: return "Perplexity"
        if "gpt" in lower or "openai" in lower: return "OpenAI GPT"
        if "gemini" in lower or "google" in lower: return "Google Gemini"
        return db_name 

    def tooltip(text):
        return f'<span title="{text}" style="cursor:help; font-size:14px; color:#333; margin-left:4px;">‚ÑπÔ∏è</span>'

    def normalize_url(u):
        u = str(u).strip()
        u = re.split(r'[)\]]', u)[0] # –û—á–∏—Å—Ç–∫–∞ –≤—ñ–¥ Markdown
        if not u.startswith(('http://', 'https://')): return f"https://{u}"
        return u

    # üî• FIX: –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–ª—è –∫–∏—Ä–∏–ª–∏—Ü—ñ
    def normalize_brand_name(name):
        if not name: return ""
        s = str(name).lower()
        return "".join(c for c in s if c.isalnum())

    # 1. –û–¢–†–ò–ú–ê–ù–ù–Ø –î–ê–ù–ò–• –ó–ê–ü–ò–¢–£
    try:
        kw_resp = supabase.table("keywords").select("*").eq("id", kw_id).execute()
        if not kw_resp.data:
            st.error("–ó–∞–ø–∏—Ç –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
            st.session_state["focus_keyword_id"] = None
            st.rerun()
            return
        
        keyword_record = kw_resp.data[0]
        keyword_text = keyword_record["keyword_text"]
        project_id = keyword_record["project_id"]
        
        proj = st.session_state.get("current_project", {})
        target_brand_name = proj.get("brand_name", "").strip()
        
    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ë–î: {e}")
        return

    # HEADER
    col_back, col_title = st.columns([1, 15])
    with col_back:
        if st.button("‚¨Ö", key="back_from_details", help="–ù–∞–∑–∞–¥ –¥–æ —Å–ø–∏—Å–∫—É"):
            st.session_state["focus_keyword_id"] = None
            st.rerun()
    
    with col_title:
        st.markdown(f"<h3 style='margin-top: -5px;'>üîç {keyword_text}</h3>", unsafe_allow_html=True)

    # ‚öôÔ∏è –ë–õ–û–ö –ù–ê–õ–ê–®–¢–£–í–ê–ù–¨
    with st.expander("‚öôÔ∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Ç–∞ –ù–æ–≤–µ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è", expanded=False):
        c1, c2 = st.columns(2)
        
        # –õ–Ü–í–ê: –†–ï–î–ê–ì–£–í–ê–ù–ù–Ø
        with c1:
            edit_key = f"edit_mode_{kw_id}"
            if edit_key not in st.session_state: st.session_state[edit_key] = False
            
            new_text = st.text_input(
                "–¢–µ–∫—Å—Ç –∑–∞–ø–∏—Ç—É", 
                value=keyword_text, 
                key="edit_kw_input",
                disabled=not st.session_state[edit_key]
            )
            
            if not st.session_state[edit_key]:
                if st.button("‚úèÔ∏è –†–µ–¥–∞–≥—É–≤–∞—Ç–∏", key="enable_edit_btn"):
                    st.session_state[edit_key] = True
                    st.rerun()
            else:
                if st.button("üíæ –ó–±–µ—Ä–µ–≥—Ç–∏", key="save_kw_btn"):
                    if new_text and new_text != keyword_text:
                        supabase.table("keywords").update({"keyword_text": new_text}).eq("id", kw_id).execute()
                        st.success("–ó–±–µ—Ä–µ–∂–µ–Ω–æ!")
                    st.session_state[edit_key] = False
                    st.rerun()

        # –ü–†–ê–í–ê: –ó–ê–ü–£–°–ö
        with c2:
            selected_models_to_run = st.multiselect(
                "–û–±–µ—Ä—ñ—Ç—å –º–æ–¥–µ–ª—ñ –¥–ª—è —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è:", 
                options=ALL_MODELS_UI, 
                default=ALL_MODELS_UI, 
                key="rescan_models_select"
            )
            
            confirm_run_key = f"confirm_run_{kw_id}"
            if confirm_run_key not in st.session_state: st.session_state[confirm_run_key] = False

            if not st.session_state[confirm_run_key]:
                if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–∏ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è", key="pre_run_btn"):
                    st.session_state[confirm_run_key] = True
                    st.rerun()
            else:
                c_conf1, c_conf2 = st.columns(2)
                with c_conf1:
                    if st.button("‚úÖ –ü—ñ–¥—Ç–≤–µ—Ä–¥–∏—Ç–∏", type="primary", key="real_run_btn"):
                        proj = st.session_state.get("current_project", {})
                        if 'n8n_trigger_analysis' in globals():
                            n8n_trigger_analysis(
                                project_id, 
                                [new_text], 
                                proj.get("brand_name"), 
                                models=selected_models_to_run
                            )
                            st.success("–ó–∞–¥–∞—á—É –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ! –û–Ω–æ–≤–ª–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö...")
                            time.sleep(2)
                            st.session_state[confirm_run_key] = False
                            st.rerun()
                        else:
                            st.error("–§—É–Ω–∫—Ü—ñ—è –∑–∞–ø—É—Å–∫—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
                with c_conf2:
                    if st.button("‚ùå –°–∫–∞—Å—É–≤–∞—Ç–∏", key="cancel_run_btn"):
                        st.session_state[confirm_run_key] = False
                        st.rerun()

    # 2. –û–¢–†–ò–ú–ê–ù–ù–Ø –î–ê–ù–ò–•
    try:
        scans_resp = supabase.table("scan_results")\
            .select("id, created_at, provider, raw_response")\
            .eq("keyword_id", kw_id)\
            .order("created_at", desc=False)\
            .execute()
        
        scans_data = scans_resp.data if scans_resp.data else []
        df_scans = pd.DataFrame(scans_data)
        
        if not df_scans.empty:
            df_scans.rename(columns={'id': 'scan_id'}, inplace=True)
            
            # --- TIMEZONE FIX ---
            df_scans['created_at'] = pd.to_datetime(df_scans['created_at'])
            if df_scans['created_at'].dt.tz is None:
                df_scans['created_at'] = df_scans['created_at'].dt.tz_localize('UTC')
            
            try: df_scans['date_str'] = df_scans['created_at'].dt.tz_convert('Europe/Kiev').dt.strftime('%Y-%m-%d %H:%M')
            except: df_scans['date_str'] = df_scans['created_at'].dt.strftime('%Y-%m-%d %H:%M')
            
            df_scans['provider_ui'] = df_scans['provider'].apply(get_ui_model_name)
        else:
            df_scans = pd.DataFrame(columns=['scan_id', 'created_at', 'provider', 'raw_response', 'date_str', 'provider_ui'])

        # B. Mentions
        df_mentions = pd.DataFrame()
        if not df_scans.empty:
            scan_ids = df_scans['scan_id'].tolist()
            if scan_ids:
                mentions_resp = supabase.table("brand_mentions").select("*").in_("scan_result_id", scan_ids).execute()
                if mentions_resp.data: df_mentions = pd.DataFrame(mentions_resp.data)

        # üî• FIX: SMART MERGE (–î—É–±–ª—ñ–∫–∞—Ç–∏ & –ö–∏—Ä–∏–ª–∏—Ü—è)
        if not df_mentions.empty:
            target_clean = normalize_brand_name(target_brand_name)
            
            def check_is_real_target(row):
                if row.get('is_my_brand') is True: return True
                
                row_brand = normalize_brand_name(row.get('brand_name', ''))
                if target_clean and row_brand:
                    if target_clean in row_brand or row_brand in target_clean:
                        return True
                return False

            df_mentions['is_real_target'] = df_mentions.apply(check_is_real_target, axis=1)
            
            # Merge
            df_full = pd.merge(df_scans, df_mentions, left_on='scan_id', right_on='scan_result_id', how='left')
        else:
            df_full = df_scans.copy()
            df_full['mention_count'] = 0
            df_full['is_real_target'] = False
            df_full['scan_result_id'] = df_full['scan_id'] if not df_full.empty else None
            df_full['sentiment_score'] = None
            df_full['rank_position'] = None
            df_full['brand_name'] = None

    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö: {e}")
        return

    # 5. –î–ï–¢–ê–õ–Ü–ó–ê–¶–Ü–Ø (TABS)
    st.markdown("##### üìù –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π")
    
    tabs = st.tabs(ALL_MODELS_UI)
    
    for tab, ui_model_name in zip(tabs, ALL_MODELS_UI):
        with tab:
            if not df_scans.empty:
                model_scans = df_scans[df_scans['provider_ui'] == ui_model_name].sort_values('created_at', ascending=False)
            else:
                model_scans = pd.DataFrame()
            
            if model_scans.empty:
                st.write(f"üìâ –î–∞–Ω–∏—Ö –≤—ñ–¥ **{ui_model_name}** —â–µ –Ω–µ–º–∞—î.")
                continue

            with st.container(border=True):
                scan_options = {row['date_str']: row['scan_id'] for _, row in model_scans.iterrows()}
                
                c_sel, c_del = st.columns([3, 1])
                with c_sel:
                    selected_date = st.selectbox(
                        f"–û–±–µ—Ä—ñ—Ç—å –¥–∞—Ç—É –∞–Ω–∞–ª—ñ–∑—É ({ui_model_name}):", 
                        list(scan_options.keys()), 
                        key=f"sel_date_{ui_model_name}"
                    )
                
                selected_scan_id = scan_options[selected_date]
                
                with c_del:
                    st.write(""); st.write("")
                    confirm_key = f"del_scan_{selected_scan_id}"
                    if confirm_key not in st.session_state: st.session_state[confirm_key] = False

                    if not st.session_state[confirm_key]:
                        if st.button("üóëÔ∏è –í–∏–¥–∞–ª–∏—Ç–∏", key=f"btn_del_{selected_scan_id}"):
                            st.session_state[confirm_key] = True
                            st.rerun()
                    else:
                        c_y, c_n = st.columns(2)
                        if c_y.button("‚úÖ", key=f"yes_{selected_scan_id}"):
                            try:
                                supabase.table("scan_results").delete().eq("id", selected_scan_id).execute()
                                st.success("–í–∏–¥–∞–ª–µ–Ω–æ!")
                                st.session_state[confirm_key] = False
                                time.sleep(1)
                                st.rerun()
                            except Exception as e:
                                st.error(f"–ü–æ–º–∏–ª–∫–∞: {e}")
                        
                        if c_n.button("‚ùå", key=f"no_{selected_scan_id}"):
                            st.session_state[confirm_key] = False
                            st.rerun()

            current_scan_row = model_scans[model_scans['scan_id'] == selected_scan_id].iloc[0]
            
            # --- LOCAL METRICS ---
            loc_sov, loc_mentions = 0, 0
            loc_sent = "–ù–µ –∑–≥–∞–¥–∞–Ω–æ"
            loc_rank_str = "-"
            
            current_scan_mentions = pd.DataFrame()
            if not df_mentions.empty:
                current_scan_mentions = df_mentions[df_mentions['scan_result_id'] == selected_scan_id]
            
            if not current_scan_mentions.empty:
                total_in_scan = current_scan_mentions['mention_count'].sum()
                
                # üî• FIX: –§—ñ–ª—å—Ç—Ä—É—î–º–æ –í–°–Ü —Ä—è–¥–∫–∏, —â–æ –ø—ñ–¥—Ö–æ–¥—è—Ç—å –ø—ñ–¥ "–ú—ñ–π –ë—Ä–µ–Ω–¥"
                my_brand_rows = current_scan_mentions[current_scan_mentions['is_real_target'] == True]

                if not my_brand_rows.empty:
                    val_my_mentions = my_brand_rows['mention_count'].sum()
                    valid_ranks = my_brand_rows[my_brand_rows['rank_position'] > 0]['rank_position']
                    val_rank = valid_ranks.min() if not valid_ranks.empty else None
                    
                    if val_my_mentions > 0:
                        main_row = my_brand_rows.sort_values('mention_count', ascending=False).iloc[0]
                        loc_sent = main_row['sentiment_score']
                    
                    loc_mentions = int(val_my_mentions)
                    loc_sov = (val_my_mentions / total_in_scan * 100) if total_in_scan > 0 else 0
                    loc_rank_str = f"#{val_rank:.0f}" if pd.notna(val_rank) else "-"
            
            sent_color = "#333"
            if loc_sent == "–ü–æ–∑–∏—Ç–∏–≤–Ω–∏–π": sent_color = "#00C896"
            elif loc_sent == "–ù–µ–≥–∞—Ç–∏–≤–Ω–∏–π": sent_color = "#FF4B4B"
            elif loc_sent == "–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ": sent_color = "#999"

            st.markdown(f"""
            <div style="display: grid; grid-template-columns: repeat(4, 1fr); gap: 10px; margin-bottom: 20px;">
                <div style="background:#fff; border:1px solid #E0E0E0; border-top:4px solid #00C896; border-radius:8px; padding:15px; text-align:center;">
                    <div style="font-size:11px; color:#888; font-weight:600;">–ß–ê–°–¢–ö–ê –ì–û–õ–û–°–£ (SOV) {tooltip('–í—ñ–¥—Å–æ—Ç–æ–∫ –∑–≥–∞–¥–æ–∫ –≤–∞—à–æ–≥–æ –±—Ä–µ–Ω–¥—É –≤ —Ü—ñ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ–π –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ.')}</div>
                    <div style="font-size:24px; font-weight:700; color:#333;">{loc_sov:.1f}%</div>
                </div>
                <div style="background:#fff; border:1px solid #E0E0E0; border-top:4px solid #00C896; border-radius:8px; padding:15px; text-align:center;">
                    <div style="font-size:11px; color:#888; font-weight:600;">–ó–ì–ê–î–û–ö –ë–†–ï–ù–î–£ {tooltip('–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–∞–∑—ñ–≤, –∫–æ–ª–∏ –±—Ä–µ–Ω–¥ –±—É–≤ –∑–≥–∞–¥–∞–Ω–∏–π.')}</div>
                    <div style="font-size:24px; font-weight:700; color:#333;">{loc_mentions}</div>
                </div>
                <div style="background:#fff; border:1px solid #E0E0E0; border-top:4px solid #00C896; border-radius:8px; padding:15px; text-align:center;">
                    <div style="font-size:11px; color:#888; font-weight:600;">–¢–û–ù–ê–õ–¨–ù–Ü–°–¢–¨ {tooltip('–ï–º–æ—Ü—ñ–π–Ω–µ –∑–∞–±–∞—Ä–≤–ª–µ–Ω–Ω—è –∑–≥–∞–¥–∫–∏ –≤ —Ü—ñ–π –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ.')}</div>
                    <div style="font-size:18px; font-weight:600; color:{sent_color}; margin-top:5px;">{loc_sent}</div>
                </div>
                <div style="background:#fff; border:1px solid #E0E0E0; border-top:4px solid #00C896; border-radius:8px; padding:15px; text-align:center;">
                    <div style="font-size:11px; color:#888; font-weight:600;">–ü–û–ó–ò–¶–Ü–Ø –£ –°–ü–ò–°–ö–£ {tooltip('–ü–æ—Ä—è–¥–∫–æ–≤–∏–π –Ω–æ–º–µ—Ä –ø–µ—Ä—à–æ—ó –∑–≥–∞–¥–∫–∏ –±—Ä–µ–Ω–¥—É.')}</div>
                    <div style="font-size:24px; font-weight:700; color:#333;">{loc_rank_str}</div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            raw_text = current_scan_row.get('raw_response', '')
            st.markdown("##### –í—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ LLM")
            
            if raw_text:
                final_html = raw_text
                if target_brand_name:
                    highlight_span = f"<span style='background-color:#dcfce7; color:#166534; font-weight:bold; padding:0 4px; border-radius:4px;'>{target_brand_name}</span>"
                    try: final_html = re.sub(re.escape(target_brand_name), highlight_span, final_html, flags=re.IGNORECASE)
                    except: pass
                st.markdown(f"""<div style="background-color: #f9fffb; border: 1px solid #bbf7d0; border-radius: 8px; padding: 20px; font-size: 16px; line-height: 1.6; color: #374151;">{final_html}</div>""", unsafe_allow_html=True)
            else:
                st.info("–¢–µ–∫—Å—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–æ.")

            st.markdown("<br>", unsafe_allow_html=True)

            # --- –ë–†–ï–ù–î–ò ---
            st.markdown(f"**–ó–Ω–∞–π–¥–µ–Ω—ñ –±—Ä–µ–Ω–¥–∏:** {tooltip('–ë—Ä–µ–Ω–¥–∏, —è–∫—ñ AI –∑–≥–∞–¥–∞–≤ —É —Ü—ñ–π –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ.')}", unsafe_allow_html=True)
            
            if not current_scan_mentions.empty:
                scan_mentions_plot = current_scan_mentions[current_scan_mentions['mention_count'] > 0].copy()
                scan_mentions_plot = scan_mentions_plot.sort_values('mention_count', ascending=False)

                if not scan_mentions_plot.empty:
                    c_chart, c_table = st.columns([1.3, 2], vertical_alignment="center")
                    with c_chart:
                        fig_brands = px.pie(
                            scan_mentions_plot, values='mention_count', names='brand_name', hole=0.5,
                            color_discrete_sequence=px.colors.qualitative.Pastel,
                            labels={'brand_name': '–ë—Ä–µ–Ω–¥', 'mention_count': '–ó–≥–∞–¥–æ–∫'}
                        )
                        fig_brands.update_traces(textposition='inside', textinfo='percent+label', hovertemplate='<b>%{label}</b><br>–ó–≥–∞–¥–æ–∫: %{value}')
                        fig_brands.update_layout(showlegend=False, margin=dict(t=0, b=0, l=0, r=0), height=250)
                        st.plotly_chart(fig_brands, use_container_width=True, config={'displayModeBar': False})
                    with c_table:
                        st.dataframe(
                            scan_mentions_plot[['brand_name', 'mention_count', 'rank_position', 'sentiment_score']],
                            column_config={
                                "brand_name": "–ë—Ä–µ–Ω–¥",
                                "mention_count": st.column_config.NumberColumn("–ó–≥–∞–¥–æ–∫"),
                                "rank_position": st.column_config.NumberColumn("–ü–æ–∑–∏—Ü—ñ—è"),
                                "sentiment_score": st.column_config.TextColumn("–¢–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å")
                            },
                            use_container_width=True, hide_index=True
                        )
                else:
                     st.info("–ë—Ä–µ–Ω–¥—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
            else:
                st.info("–ë—Ä–µ–Ω–¥—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
            
            st.markdown("<br>", unsafe_allow_html=True)

            # --- –î–ñ–ï–†–ï–õ–ê ---
            st.markdown(f"#### üîó –¶–∏—Ç–æ–≤–∞–Ω—ñ –¥–∂–µ—Ä–µ–ª–∞ {tooltip('–ü–æ—Å–∏–ª–∞–Ω–Ω—è, —è–∫—ñ –Ω–∞–¥–∞–ª–∞ –º–æ–¥–µ–ª—å.')}", unsafe_allow_html=True)
            try:
                sources_resp = supabase.table("extracted_sources").select("*").eq("scan_result_id", selected_scan_id).execute()
                sources_data = sources_resp.data
                if sources_data:
                    df_src = pd.DataFrame(sources_data)
                    
                    if 'url' in df_src.columns:
                        if 'domain' not in df_src.columns:
                            from urllib.parse import urlparse
                            df_src['domain'] = df_src['url'].apply(lambda x: str(x).split('/')[2] if x and '//' in str(x) else 'unknown')
                        
                        df_src['url'] = df_src['url'].apply(normalize_url)
                        
                        if 'is_official' in df_src.columns:
                            df_src['status_text'] = df_src['is_official'].apply(lambda x: "‚úÖ –û—Ñ—ñ—Ü—ñ–π–Ω–µ" if x is True else "üîó –ó–æ–≤–Ω—ñ—à–Ω—î")
                        else:
                            df_src['status_text'] = "üîó –ó–æ–≤–Ω—ñ—à–Ω—î"

                        # –ì–†–£–ü–£–í–ê–ù–ù–Ø
                        df_grouped_src = df_src.groupby(['url', 'domain', 'status_text'], as_index=False).size()
                        df_grouped_src = df_grouped_src.rename(columns={'size': 'count'})
                        df_grouped_src = df_grouped_src.sort_values(by='count', ascending=False)

                        c_src_chart, c_src_table = st.columns([1.3, 2], vertical_alignment="center")
                        
                        with c_src_chart:
                            domain_counts = df_grouped_src.groupby('domain')['count'].sum().reset_index()
                            fig_src = px.pie(
                                domain_counts.head(10), values='count', names='domain', hole=0.5,
                                labels={'domain': '–î–æ–º–µ–Ω', 'count': '–ö—ñ–ª—å–∫—ñ—Å—Ç—å'}
                            )
                            fig_src.update_traces(textposition='inside', textinfo='percent', hovertemplate='<b>%{label}</b><br>–ö—ñ–ª—å–∫—ñ—Å—Ç—å: %{value}')
                            fig_src.update_layout(showlegend=False, margin=dict(t=0, b=0, l=0, r=0), height=200)
                            st.plotly_chart(fig_src, use_container_width=True, config={'displayModeBar': False})

                        with c_src_table:
                            st.dataframe(
                                df_grouped_src[['url', 'status_text', 'count']], 
                                use_container_width=True, 
                                hide_index=True,
                                column_config={
                                    "url": st.column_config.LinkColumn("–ü–æ—Å–∏–ª–∞–Ω–Ω—è", width="large", validate="^https?://"),
                                    "status_text": st.column_config.TextColumn("–¢–∏–ø", width="small"),
                                    "count": st.column_config.NumberColumn("–ö-—Å—Ç—å", width="small")
                                }
                            )
                    else:
                        st.info("URL –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
                else:
                    st.info("‚ÑπÔ∏è –î–∂–µ—Ä–µ–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
            except Exception as e:
                st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∂–µ—Ä–µ–ª: {e}")



def show_keywords_page():
    """
    –°—Ç–æ—Ä—ñ–Ω–∫–∞ —Å–ø–∏—Å–∫—É –∑–∞–ø–∏—Ç—ñ–≤.
    –í–ï–†–°–Ü–Ø: FIX DUPLICATE KEY ERROR.
    1. –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ DuplicateElementKey (–¥–æ–¥–∞–Ω–æ idx –¥–æ –∫–ª—é—á—ñ–≤ —á–µ–∫–±–æ–∫—Å—ñ–≤).
    2. –°–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—è –¥–æ–∑–≤–æ–ª—ñ–≤ –∞–≤—Ç–æ—Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è.
    """
    import pandas as pd
    import streamlit as st
    from datetime import datetime
    import time
    import io 
    import re 
    
    # CSS –°—Ç–∏–ª—ñ–∑–∞—Ü—ñ—è
    st.markdown("""
    <style>
        .green-number {
            background-color: #00C896;
            color: white;
            width: 28px;
            height: 28px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 14px;
            margin-top: 5px; 
        }
        div[data-testid="stColumn"]:nth-of-type(3) button[kind="secondary"] {
            border: none;
            background: transparent;
            text-align: left;
            padding-left: 0;
            font-weight: 600;
            color: #31333F;
            box-shadow: none;
        }
        div[data-testid="stColumn"]:nth-of-type(3) button[kind="secondary"]:hover {
            color: #00C896;
            background: transparent;
            border: none;
            box-shadow: none;
        }
        div[data-testid="stColumn"]:nth-of-type(3) button[kind="secondary"]:active {
            color: #00C896;
            background: transparent;
            box-shadow: none;
        }
    </style>
    """, unsafe_allow_html=True)

    try:
        import pytz
        kyiv_tz = pytz.timezone('Europe/Kiev')
    except ImportError:
        kyiv_tz = None

    MODEL_MAPPING = {
        "Perplexity": "perplexity",
        "OpenAI GPT": "gpt-4o",
        "Google Gemini": "gemini-1.5-pro"
    }

    if 'supabase' not in globals():
        if 'supabase' in st.session_state:
            supabase = st.session_state['supabase']
        else:
            st.error("üö® –ü–æ–º–∏–ª–∫–∞: –ó–º—ñ–Ω–Ω–∞ 'supabase' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
            return
    else:
        supabase = globals()['supabase']

    if "kw_input_count" not in st.session_state:
        st.session_state["kw_input_count"] = 1

    # --- –°–ò–ù–•–†–û–ù–Ü–ó–ê–¶–Ü–Ø –ó –ë–î ---
    if "current_project" in st.session_state and st.session_state["current_project"]:
        try:
            curr_id = st.session_state["current_project"]["id"]
            refresh_resp = supabase.table("projects").select("*").eq("id", curr_id).execute()
            if refresh_resp.data:
                st.session_state["current_project"] = refresh_resp.data[0]
        except Exception:
            pass 

    proj = st.session_state.get("current_project")
    if not proj:
        st.info("–°–ø–æ—á–∞—Ç–∫—É —Å—Ç–≤–æ—Ä—ñ—Ç—å –ø—Ä–æ–µ–∫—Ç –≤ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥—É.")
        return

    if st.session_state.get("focus_keyword_id"):
        if 'show_keyword_details' in globals():
            show_keyword_details(st.session_state["focus_keyword_id"])
            return

    st.markdown("<h3 style='padding-top:0;'>üìã –ü–µ—Ä–µ–ª—ñ–∫ –∑–∞–ø–∏—Ç—ñ–≤</h3>", unsafe_allow_html=True)

    def format_kyiv_time(iso_str):
        if not iso_str or iso_str == "1970-01-01T00:00:00+00:00":
            return "‚Äî"
        try:
            dt_utc = datetime.fromisoformat(iso_str.replace('Z', '+00:00'))
            if kyiv_tz:
                dt_kyiv = dt_utc.astimezone(kyiv_tz)
                return dt_kyiv.strftime("%d.%m %H:%M")
            else:
                return dt_utc.strftime("%d.%m %H:%M UTC")
        except:
            return iso_str

    def update_kw_field(kw_id, field, value):
        try:
            supabase.table("keywords").update({field: value}).eq("id", kw_id).execute()
        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è: {e}")

    # ========================================================
    # 2. –ë–õ–û–ö –†–ï–î–ê–ì–£–í–ê–ù–ù–Ø
    # ========================================================
    with st.expander("‚úèÔ∏è –†–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—ñ–≤", expanded=False): 
        
        tab_manual, tab_import, tab_export = st.tabs(["‚úçÔ∏è –í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É", "üì• –Ü–º–ø–æ—Ä—Ç (Excel / URL)", "üì§ –ï–∫—Å–ø–æ—Ä—Ç (Excel)"])

        # --- TAB 1: –í–†–£–ß–ù–£ ---
        with tab_manual:
            with st.container(border=True):
                st.markdown("##### üìù –í–≤–µ–¥—ñ—Ç—å –Ω–æ–≤—ñ –∑–∞–ø–∏—Ç–∏")
                for i in range(st.session_state["kw_input_count"]):
                    st.text_input(f"–ó–∞–ø–∏—Ç #{i+1}", key=f"new_kw_input_{i}", placeholder="–ù–∞–ø—Ä–∏–∫–ª–∞–¥: –ö—É–ø–∏—Ç–∏ –∫–≤–∏—Ç–∫–∏...")

                col_plus, col_minus, _ = st.columns([1, 1, 5])
                with col_plus:
                    if st.button("‚ûï –©–µ —Ä—è–¥–æ–∫"):
                        st.session_state["kw_input_count"] += 1
                        st.rerun()
                with col_minus:
                    if st.session_state["kw_input_count"] > 1:
                        if st.button("‚ûñ –ü—Ä–∏–±—Ä–∞—Ç–∏"):
                            st.session_state["kw_input_count"] -= 1
                            st.rerun()

                st.divider()
                c_models, c_submit = st.columns([3, 1])
                with c_models:
                    selected_models_manual = st.multiselect("LLM –¥–ª—è –ø–µ—Ä—à–æ–≥–æ —Å–∫–∞–Ω—É:", list(MODEL_MAPPING.keys()), default=["Perplexity"], key="manual_multiselect")
                
                with c_submit:
                    st.write("")
                    st.write("")
                    if st.button("üöÄ –î–æ–¥–∞—Ç–∏", use_container_width=True, type="primary", key="btn_add_manual"):
                        new_keywords_list = []
                        for i in range(st.session_state["kw_input_count"]):
                            val = st.session_state.get(f"new_kw_input_{i}", "").strip()
                            if val: new_keywords_list.append(val)
                        
                        if new_keywords_list:
                            try:
                                insert_data = [{
                                    "project_id": proj["id"], "keyword_text": kw, "is_active": True, 
                                    "is_auto_scan": False, "frequency": "daily"
                                } for kw in new_keywords_list]
                                
                                res = supabase.table("keywords").insert(insert_data).execute()
                                if res.data:
                                    with st.spinner(f"–ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç–∞ –∑–∞–ø—É—Å–∫–∞—î–º–æ –∞–Ω–∞–ª—ñ–∑..."):
                                        if 'n8n_trigger_analysis' in globals():
                                            for new_kw in new_keywords_list:
                                                n8n_trigger_analysis(proj["id"], [new_kw], proj.get("brand_name"), models=selected_models_manual)
                                                time.sleep(0.5) 
                                    st.success(f"–î–æ–¥–∞–Ω–æ {len(new_keywords_list)} –∑–∞–ø–∏—Ç—ñ–≤!")
                                    st.session_state["kw_input_count"] = 1
                                    for key in list(st.session_state.keys()):
                                        if key.startswith("new_kw_input_"): del st.session_state[key]
                                    time.sleep(1)
                                    st.rerun()
                            except Exception as e:
                                st.error(f"–ü–æ–º–∏–ª–∫–∞: {e}")
                        else:
                            st.warning("–í–≤–µ–¥—ñ—Ç—å —Ö–æ—á–∞ –± –æ–¥–∏–Ω –∑–∞–ø–∏—Ç.")

        # --- TAB 2: –Ü–ú–ü–û–†–¢ EXCEL / URL ---
        with tab_import:
            st.info("üí° –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª .xlsx –∞–±–æ –≤—Å—Ç–∞–≤—Ç–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ Google Sheet. **–í–∞–∂–ª–∏–≤–æ:** –î–ª—è Google Sheet –º–∞—î –±—É—Ç–∏ –≤—ñ–¥–∫—Ä–∏—Ç–æ –¥–æ—Å—Ç—É–ø (Anyone with the link). –ü–µ—Ä—à–∞ –∫–æ–ª–æ–Ω–∫–∞ –º–∞—î –Ω–∞–∑–∏–≤–∞—Ç–∏—Å—è **Keyword**.")
            
            import_source = st.radio("–î–∂–µ—Ä–µ–ª–æ:", ["–§–∞–π–ª (.xlsx)", "–ü–æ—Å–∏–ª–∞–Ω–Ω—è (URL)"], horizontal=True)
            df_upload = None
            
            if import_source == "–§–∞–π–ª (.xlsx)":
                uploaded_file = st.file_uploader("–û–±–µ—Ä—ñ—Ç—å —Ñ–∞–π–ª Excel", type=["xlsx"])
                if uploaded_file:
                    try:
                        df_upload = pd.read_excel(uploaded_file)
                    except ImportError:
                        st.error("üö® –í—ñ–¥—Å—É—Ç–Ω—è –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ `openpyxl`. –ë—É–¥—å –ª–∞—Å–∫–∞, –¥–æ–¥–∞–π—Ç–µ `openpyxl` —É requirements.txt –≤–∞—à–æ–≥–æ –ø—Ä–æ–µ–∫—Ç—É.")
                    except Exception as e:
                        st.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ —Ñ–∞–π–ª: {e}")
            else: # URL
                import_url = st.text_input("–í—Å—Ç–∞–≤—Ç–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è (Google Sheets –∞–±–æ CSV):")
                if import_url:
                    try:
                        if "docs.google.com" in import_url:
                            match = re.search(r'/d/([a-zA-Z0-9-_]+)', import_url)
                            if match:
                                sheet_id = match.group(1)
                                csv_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv"
                                df_upload = pd.read_csv(csv_url)
                            else:
                                st.error("–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ ID Google —Ç–∞–±–ª–∏—Ü—ñ. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è.")
                        elif import_url.endswith(".csv"):
                            df_upload = pd.read_csv(import_url)
                        elif import_url.endswith(".xlsx"):
                            df_upload = pd.read_excel(import_url)
                        else:
                            st.warning("–°–ø—Ä–æ–±—É—î–º–æ –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ —è–∫ CSV...")
                            df_upload = pd.read_csv(import_url)
                    except Exception as e:
                        if "400" in str(e) or "403" in str(e):
                            st.error("üîí –ü–æ–º–∏–ª–∫–∞ –¥–æ—Å—Ç—É–ø—É (HTTP 400/403).")
                        else:
                            st.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏: {e}")

            if df_upload is not None:
                target_col = None
                cols_lower = [str(c).lower().strip() for c in df_upload.columns]
                
                if "keyword" in cols_lower:
                    target_col = df_upload.columns[cols_lower.index("keyword")]
                elif "–∑–∞–ø–∏—Ç" in cols_lower:
                    target_col = df_upload.columns[cols_lower.index("–∑–∞–ø–∏—Ç")]
                else:
                    target_col = df_upload.columns[0] 
                
                preview_kws = df_upload[target_col].dropna().astype(str).tolist()
                st.write(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ **{len(preview_kws)}** –∑–∞–ø–∏—Ç—ñ–≤. –ü—Ä–∏–∫–ª–∞–¥: {preview_kws[:3]}")
                
                st.write("---")
                st.write("–û–±–µ—Ä—ñ—Ç—å –¥—ñ—é:")
                
                c_imp_models, c_imp_btn1, c_imp_btn2 = st.columns([2, 1.5, 1.5])
                
                with c_imp_models:
                    selected_models_import = st.multiselect("LLM (—Ç—ñ–ª—å–∫–∏ –¥–ª—è –∫–Ω–æ–ø–∫–∏ –∞–Ω–∞–ª—ñ–∑—É):", list(MODEL_MAPPING.keys()), default=["Perplexity"], key="import_multiselect")
                
                with c_imp_btn1:
                    st.write("")
                    st.write("")
                    if st.button("üì• –¢—ñ–ª—å–∫–∏ –∑–±–µ—Ä–µ–≥—Ç–∏", use_container_width=True):
                        if preview_kws:
                            try:
                                insert_data = [{
                                    "project_id": proj["id"], "keyword_text": kw, "is_active": True, 
                                    "is_auto_scan": False, "frequency": "daily"
                                } for kw in preview_kws]
                                
                                supabase.table("keywords").insert(insert_data).execute()
                                st.success(f"–£—Å–ø—ñ—à–Ω–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ {len(preview_kws)} –∑–∞–ø–∏—Ç—ñ–≤!")
                                time.sleep(1.5)
                                st.rerun()
                            except Exception as e:
                                st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è: {e}")

                with c_imp_btn2:
                    st.write("")
                    st.write("")
                    if st.button("üöÄ –ó–±–µ—Ä–µ–≥—Ç–∏ —Ç–∞ –ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏", type="primary", use_container_width=True):
                        if preview_kws:
                            try:
                                insert_data = [{
                                    "project_id": proj["id"], "keyword_text": kw, "is_active": True, 
                                    "is_auto_scan": False, "frequency": "daily"
                                } for kw in preview_kws]
                                
                                res = supabase.table("keywords").insert(insert_data).execute()
                                if res.data:
                                    with st.spinner(f"–û–±—Ä–æ–±–∫–∞ {len(preview_kws)} –∑–∞–ø–∏—Ç—ñ–≤..."):
                                        if 'n8n_trigger_analysis' in globals():
                                            my_bar = st.progress(0, text="–ó–∞–ø—É—Å–∫...")
                                            total = len(preview_kws)
                                            for i, kw in enumerate(preview_kws):
                                                n8n_trigger_analysis(proj["id"], [kw], proj.get("brand_name"), models=selected_models_import)
                                                my_bar.progress((i + 1) / total)
                                                time.sleep(0.3)
                                    st.success("–£—Å–ø—ñ—à–Ω–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —Ç–∞ –∑–∞–ø—É—â–µ–Ω–æ!")
                                    time.sleep(2)
                                    st.rerun()
                            except Exception as e:
                                st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–æ—Ü–µ—Å—É: {e}")

        # --- TAB 3: –ï–ö–°–ü–û–†–¢ EXCEL ---
        with tab_export:
            st.write("–ù–∞—Ç–∏—Å–Ω—ñ—Ç—å –∫–Ω–æ–ø–∫—É –Ω–∏–∂—á–µ, —â–æ–± –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –≤—Å—ñ –∑–∞–ø–∏—Ç–∏ —Ü—å–æ–≥–æ –ø—Ä–æ–µ–∫—Ç—É –≤ Excel.")
            try:
                kws_resp = supabase.table("keywords").select("id, keyword_text, created_at").eq("project_id", proj["id"]).execute()
                if kws_resp.data:
                    df_export = pd.DataFrame(kws_resp.data)
                    scan_resp = supabase.table("scan_results").select("keyword_id, created_at").eq("project_id", proj["id"]).order("created_at", desc=True).execute()
                    
                    last_scan_map = {}
                    if scan_resp.data:
                        for s in scan_resp.data:
                            if s['keyword_id'] not in last_scan_map:
                                last_scan_map[s['keyword_id']] = s['created_at']
                    
                    df_export['last_scan_date'] = df_export['id'].map(lambda x: last_scan_map.get(x, "-"))
                    df_export['created_at'] = pd.to_datetime(df_export['created_at']).dt.strftime('%Y-%m-%d %H:%M')
                    df_export['last_scan_date'] = df_export['last_scan_date'].apply(lambda x: pd.to_datetime(x).strftime('%Y-%m-%d %H:%M') if x != "-" else "-")
                    
                    df_final = df_export[["keyword_text", "created_at", "last_scan_date"]].rename(columns={"keyword_text": "Keyword", "created_at": "Date Added", "last_scan_date": "Last Scan Date"})
                    
                    buffer = io.BytesIO()
                    try:
                        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                            df_final.to_excel(writer, index=False, sheet_name='Keywords')
                    except:
                         try:
                             with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                 df_final.to_excel(writer, index=False, sheet_name='Keywords')
                         except ImportError:
                             st.error("–î–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É –ø–æ—Ç—Ä—ñ–±–Ω–∞ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ `xlsxwriter` –∞–±–æ `openpyxl`.")
                             buffer = None

                    if buffer:
                        st.download_button(label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ Excel", data=buffer.getvalue(), file_name=f"keywords_{proj.get('brand_name')}.xlsx", mime="application/vnd.ms-excel", type="primary")
                else:
                    st.warning("–£ –ø—Ä–æ–µ–∫—Ç—ñ —â–µ –Ω–µ–º–∞—î –∑–∞–ø–∏—Ç—ñ–≤ –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É.")
            except Exception as e:
                st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∏ –µ–∫—Å–ø–æ—Ä—Ç—É: {e}")

    st.divider()
    
    # ========================================================
    # 3. –û–¢–†–ò–ú–ê–ù–ù–Ø –î–ê–ù–ò–• (–î–õ–Ø –¢–ê–ë–õ–ò–¶–Ü –ù–ò–ñ–ß–ï)
    # ========================================================
    try:
        keywords = supabase.table("keywords").select("*").eq("project_id", proj["id"]).order("created_at", desc=True).execute().data
        last_scans_resp = supabase.table("scan_results").select("keyword_id, created_at").eq("project_id", proj["id"]).order("created_at", desc=True).execute()
        
        last_scan_map = {}
        if last_scans_resp.data:
            for s in last_scans_resp.data:
                if s['keyword_id'] not in last_scan_map:
                    last_scan_map[s['keyword_id']] = s['created_at']
        
        for k in keywords:
            k['last_scan_date'] = last_scan_map.get(k['id'], "1970-01-01T00:00:00+00:00")

    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
        keywords = []

    if not keywords:
        st.info("–°–ø–∏—Å–æ–∫ –ø–æ—Ä–æ–∂–Ω—ñ–π.")
        return

    # ========================================================
    # 4. –ü–ê–ù–ï–õ–¨ –£–ü–†–ê–í–õ–Ü–ù–ù–Ø (–°–û–†–¢–£–í–ê–ù–ù–Ø)
    # ========================================================
    c_sort, _ = st.columns([2, 4])
    with c_sort:
        sort_option = st.selectbox("–°–æ—Ä—Ç—É–≤–∞—Ç–∏ –∑–∞:", ["–ù–∞–π–Ω–æ–≤—ñ—à—ñ (–î–æ–¥–∞–Ω—ñ)", "–ù–∞–π—Å—Ç–∞—Ä—ñ—à—ñ (–î–æ–¥–∞–Ω—ñ)", "–ù–µ—â–æ–¥–∞–≤–Ω–æ –ø—Ä–æ—Å–∫–∞–Ω–æ–≤–∞–Ω—ñ", "–î–∞–≤–Ω–æ –Ω–µ —Å–∫–∞–Ω–æ–≤–∞–Ω—ñ"], label_visibility="collapsed")

    if sort_option == "–ù–∞–π–Ω–æ–≤—ñ—à—ñ (–î–æ–¥–∞–Ω—ñ)": keywords.sort(key=lambda x: x['created_at'], reverse=True)
    elif sort_option == "–ù–∞–π—Å—Ç–∞—Ä—ñ—à—ñ (–î–æ–¥–∞–Ω—ñ)": keywords.sort(key=lambda x: x['created_at'], reverse=False)
    elif sort_option == "–ù–µ—â–æ–¥–∞–≤–Ω–æ –ø—Ä–æ—Å–∫–∞–Ω–æ–≤–∞–Ω—ñ": keywords.sort(key=lambda x: x['last_scan_date'], reverse=True)
    elif sort_option == "–î–∞–≤–Ω–æ –Ω–µ —Å–∫–∞–Ω–æ–≤–∞–Ω—ñ": keywords.sort(key=lambda x: x['last_scan_date'], reverse=False)

    with st.container(border=True):
        c_check, c_models, c_btn = st.columns([0.5, 3, 1.5])
        with c_check:
            st.write("") 
            select_all = st.checkbox("–í—Å—ñ", key="select_all_kws")
        with c_models:
            bulk_models = st.multiselect("–õ–õ–ú –¥–ª—è –∑–∞–ø—É—Å–∫—É:", list(MODEL_MAPPING.keys()), default=["Perplexity"], label_visibility="collapsed", key="bulk_models_main")
        with c_btn:
            if st.button("üöÄ –ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –æ–±—Ä–∞–Ω—ñ", use_container_width=True, type="primary"):
                selected_kws_text = []
                if select_all:
                    selected_kws_text = [k['keyword_text'] for k in keywords]
                else:
                    # üî• FIX: –ó–±—ñ—Ä –æ–±—Ä–∞–Ω–∏—Ö –∑ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º –∫–ª—é—á–µ–º
                    for idx, k in enumerate(keywords, start=1):
                        if st.session_state.get(f"chk_{k['id']}_{idx}", False):
                            selected_kws_text.append(k['keyword_text'])
                
                if selected_kws_text:
                    my_bar = st.progress(0, text="–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è...")
                    total_kws = len(selected_kws_text)
                    try:
                        if 'n8n_trigger_analysis' in globals():
                            for i, single_kw in enumerate(selected_kws_text):
                                my_bar.progress((i / total_kws), text=f"–í—ñ–¥–ø—Ä–∞–≤–∫–∞: {single_kw}...")
                                n8n_trigger_analysis(proj["id"], [single_kw], proj.get("brand_name"), models=bulk_models)
                                time.sleep(0.3)
                            my_bar.progress(1.0, text="–ì–æ—Ç–æ–≤–æ!")
                            st.success(f"–£—Å–ø—ñ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω–æ {total_kws} –∑–∞–≤–¥–∞–Ω—å! –û–Ω–æ–≤—ñ—Ç—å —Å—Ç–æ—Ä—ñ–Ω–∫—É –∑–∞ —Ö–≤–∏–ª–∏–Ω—É.")
                            time.sleep(2)
                            st.rerun()
                        else:
                            st.error("–§—É–Ω–∫—Ü—ñ—è –∑–∞–ø—É—Å–∫—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
                    except Exception as e:
                        st.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫—É: {e}")
                else:
                    st.warning("–û–±–µ—Ä—ñ—Ç—å —Ö–æ—á–∞ –± –æ–¥–∏–Ω –∑–∞–ø–∏—Ç.")

    # ========================================================
    # 5. –°–ü–ò–°–û–ö –ó–ê–ü–ò–¢–Ü–í (–¢–ê–ë–õ–ò–¶–Ø)
    # ========================================================
    
    h_chk, h_num, h_txt, h_cron, h_date, h_act = st.columns([0.4, 0.5, 3.2, 2, 1.2, 1.3])
    h_txt.markdown("**–ó–∞–ø–∏—Ç**")
    h_cron.markdown("**–ê–≤—Ç–æ–∑–∞–ø—É—Å–∫**")
    h_date.markdown("**–û—Å—Ç–∞–Ω–Ω—ñ–π –∞–Ω–∞–ª—ñ–∑**")
    h_act.markdown("**–í–∏–¥–∞–ª–∏—Ç–∏**")

    # üî• –û–¢–†–ò–ú–£–Ñ–ú–û –î–û–ó–í–Ü–õ –í–Ü–î –ê–î–ú–Ü–ù–ê
    allow_cron_global = proj.get('allow_cron', False)

    for idx, k in enumerate(keywords, start=1):
        with st.container(border=True):
            c1, c2, c3, c4, c5, c6 = st.columns([0.4, 0.5, 3.2, 2, 1.2, 1.3])
            
            with c1:
                st.write("") 
                is_checked = select_all
                # üî• FIX: –£–Ω—ñ–∫–∞–ª—å–Ω–∏–π –∫–ª—é—á –∑ idx
                st.checkbox("", key=f"chk_{k['id']}_{idx}", value=is_checked)
            
            with c2:
                st.markdown(f"<div class='green-number'>{idx}</div>", unsafe_allow_html=True)
            
            with c3:
                if st.button(k['keyword_text'], key=f"link_btn_{k['id']}_{idx}", help="–ù–∞—Ç–∏—Å–Ω—ñ—Ç—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É"):
                    st.session_state["focus_keyword_id"] = k["id"]
                    st.rerun()
            
            with c4:
                cron_c1, cron_c2 = st.columns([0.8, 1.2])
                is_auto = k.get('is_auto_scan', False) 
                
                # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–≤—ñ—Ä–∫–æ—é
                new_auto = is_auto 

                with cron_c1:
                    # –í—ñ–¥–æ–±—Ä–∞–∂–∞—î–º–æ —Ç–æ–≥–ª —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –¥–æ–∑–≤–æ–ª–µ–Ω–æ –≥–ª–æ–±–∞–ª—å–Ω–æ
                    if allow_cron_global:
                        new_auto = st.toggle("–ê–≤—Ç–æ", value=is_auto, key=f"auto_{k['id']}_{idx}", label_visibility="collapsed")
                        if new_auto != is_auto:
                            update_kw_field(k['id'], "is_auto_scan", new_auto)
                            st.rerun()
                    else:
                        st.toggle("–ê–≤—Ç–æ", value=False, key=f"auto_{k['id']}_{idx}", label_visibility="collapsed", disabled=True)
                        st.caption("üîí Admin")

                with cron_c2:
                    if new_auto and allow_cron_global:
                        current_freq = k.get('frequency', 'daily')
                        freq_options = ["daily", "weekly", "monthly"]
                        try: idx_f = freq_options.index(current_freq)
                        except: idx_f = 0
                        new_freq = st.selectbox("Freq", freq_options, index=idx_f, key=f"freq_{k['id']}_{idx}", label_visibility="collapsed")
                        if new_freq != current_freq:
                            update_kw_field(k['id'], "frequency", new_freq)
                    else:
                        st.write("")
            
            with c5:
                st.write("")
                date_iso = k.get('last_scan_date')
                formatted_date = format_kyiv_time(date_iso)
                st.caption(f"{formatted_date}")
            
            with c6:
                st.write("")
                del_key = f"confirm_del_kw_{k['id']}_{idx}"
                if del_key not in st.session_state: st.session_state[del_key] = False

                if not st.session_state[del_key]:
                    if st.button("üóëÔ∏è –í–∏–¥–∞–ª–∏—Ç–∏", key=f"pre_del_{k['id']}_{idx}"):
                        st.session_state[del_key] = True
                        st.rerun()
                else:
                    dc1, dc2 = st.columns(2)
                    if dc1.button("‚úÖ", key=f"yes_del_{k['id']}_{idx}", type="primary"):
                        try:
                            supabase.table("scan_results").delete().eq("keyword_id", k["id"]).execute()
                            supabase.table("keywords").delete().eq("id", k["id"]).execute()
                            st.success("!")
                            st.session_state[del_key] = False
                            time.sleep(0.5)
                            st.rerun()
                        except Exception as e:
                            st.error("–ü–æ–º–∏–ª–∫–∞")
                    
                    if dc2.button("‚ùå", key=f"no_del_{k['id']}_{idx}"):
                        st.session_state[del_key] = False
                        st.rerun()




# =========================
# 9. SIDEBAR
# =========================

def show_sources_page():
    """
    –°—Ç–æ—Ä—ñ–Ω–∫–∞ –¥–∂–µ—Ä–µ–ª.
    –í–ï–†–°–Ü–Ø: FIXED & REDESIGNED.
    1. –ß–∏—Ç–∞—î –∑ —Ç–∞–±–ª–∏—Ü—ñ official_assets (—Ç–µ–ø–µ—Ä –¥–æ–º–µ–Ω –∑ —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó –±—É–¥–µ –≤–∏–¥–Ω–æ).
    2. –î–∏–∑–∞–π–Ω —Ç–∞–±–ª–∏—Ü—ñ Whitelist –ø—Ä–∏–≤–µ–¥–µ–Ω–æ –¥–æ —Å—Ç–∏–ª—é —ñ–Ω—à–∏—Ö —Ç–∞–±–ª–∏—Ü—å.
    3. –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ –ª–æ–≥—ñ–∫—É –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø—Ä–∏ —Ä–µ–¥–∞–≥—É–≤–∞–Ω–Ω—ñ.
    """
    import pandas as pd
    import plotly.express as px
    import streamlit as st
    import time
    from urllib.parse import urlparse
    
    # –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è
    if 'supabase' not in globals():
        if 'supabase' in st.session_state:
            supabase = st.session_state['supabase']
        else:
            st.error("üö® –ü–æ–º–∏–ª–∫–∞: –ó–º—ñ–Ω–Ω–∞ 'supabase' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
            return
    else:
        supabase = globals()['supabase']

    proj = st.session_state.get("current_project")
    if not proj:
        st.info("–°–ø–æ—á–∞—Ç–∫—É –æ–±–µ—Ä—ñ—Ç—å –ø—Ä–æ–µ–∫—Ç.")
        return

    st.title("üîó –î–∂–µ—Ä–µ–ª–∞")

    # ==============================================================================
    # 1. –û–¢–†–ò–ú–ê–ù–ù–Ø –î–ê–ù–ò–• (–°–∫–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏)
    # ==============================================================================
    try:
        # Keywords
        kw_resp = supabase.table("keywords").select("id, keyword_text").eq("project_id", proj["id"]).execute()
        kw_map = {k['id']: k['keyword_text'] for k in kw_resp.data} if kw_resp.data else {}

        # Scan Results
        scan_resp = supabase.table("scan_results")\
            .select("id, provider, created_at, keyword_id")\
            .eq("project_id", proj["id"])\
            .execute()
        
        scan_meta = {} 
        scan_ids = []
        
        PROVIDER_MAP = {
            "perplexity": "Perplexity",
            "gpt-4o": "OpenAI GPT", "gpt-4": "OpenAI GPT",
            "gemini-1.5-pro": "Google Gemini", "gemini": "Google Gemini"
        }

        if scan_resp.data:
            for s in scan_resp.data:
                scan_ids.append(s['id'])
                raw_p = s.get('provider', '').lower()
                clean_p = "–Ü–Ω—à–µ"
                for k, v in PROVIDER_MAP.items():
                    if k in raw_p:
                        clean_p = v
                        break
                
                scan_meta[s['id']] = {
                    'provider': clean_p,
                    'date': s['created_at'],
                    'keyword_text': kw_map.get(s['keyword_id'], "–ù–µ–≤—ñ–¥–æ–º–∏–π –∑–∞–ø–∏—Ç")
                }
        
        # Extracted Sources
        df_master = pd.DataFrame()
        if scan_ids:
            sources_resp = supabase.table("extracted_sources").select("*").in_("scan_result_id", scan_ids).execute()
            if sources_resp.data:
                df_master = pd.DataFrame(sources_resp.data)
                df_master['provider'] = df_master['scan_result_id'].map(lambda x: scan_meta.get(x, {}).get('provider', '–Ü–Ω—à–µ'))
                df_master['keyword_text'] = df_master['scan_result_id'].map(lambda x: scan_meta.get(x, {}).get('keyword_text', ''))
                df_master['scan_date'] = df_master['scan_result_id'].map(lambda x: scan_meta.get(x, {}).get('date'))
                
                if 'domain' not in df_master.columns:
                    df_master['domain'] = df_master['url'].apply(lambda x: urlparse(x).netloc if x else "unknown")

    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö: {e}")
        df_master = pd.DataFrame()

    # ==============================================================================
    # 2. WHITELIST LOGIC (–ü–†–ê–í–ò–õ–¨–ù–ï –ß–ò–¢–ê–ù–ù–Ø)
    # ==============================================================================
    try:
        # üî• FIX: –ß–∏—Ç–∞—î–º–æ –∑ —Ç–∞–±–ª–∏—Ü—ñ official_assets
        oa_resp = supabase.table("official_assets").select("domain_or_url, type").eq("project_id", proj["id"]).execute()
        raw_assets = oa_resp.data if oa_resp.data else []
    except Exception as e:
        raw_assets = []

    # –§–æ—Ä–º—É—î–º–æ —Å–ø–∏—Å–æ–∫ –¥–ª—è –ª–æ–≥—ñ–∫–∏
    assets_list_dicts = []
    for item in raw_assets:
        assets_list_dicts.append({
            "–î–æ–º–µ–Ω": item.get("domain_or_url", ""), 
            "–ú—ñ—Ç–∫–∞": item.get("type", "–í–µ–±-—Å–∞–π—Ç")
        })
    
    OFFICIAL_DOMAINS = [d["–î–æ–º–µ–Ω"].lower().strip() for d in assets_list_dicts if d["–î–æ–º–µ–Ω"]]

    # –§—É–Ω–∫—Ü—ñ—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
    def check_is_official(url):
        if not url: return False
        u_str = str(url).lower()
        for od in OFFICIAL_DOMAINS:
            if od in u_str: return True
        return False

    if not df_master.empty:
        df_master['is_official_dynamic'] = df_master['url'].apply(check_is_official)

    # ==============================================================================
    # 3. –í–ö–õ–ê–î–ö–ò
    # ==============================================================================
    tab1, tab2, tab3 = st.tabs(["üìä –û—Ñ—ñ—Ü—ñ–π–Ω—ñ —Ä–µ—Å—É—Ä—Å–∏ –±—Ä–µ–Ω–¥—É", "üåê –†–µ–Ω–∫—ñ–Ω–≥ –¥–æ–º–µ–Ω—ñ–≤", "üîó –ü–æ—Å–∏–ª–∞–Ω–Ω—è"])

    # --- TAB 1: –ê–ù–ê–õ–Ü–ó –û–•–û–ü–õ–ï–ù–ù–Ø ---
    with tab1:
        st.markdown("#### üìä –ê–Ω–∞–ª—ñ–∑ –æ—Ö–æ–ø–ª–µ–Ω–Ω—è –æ—Ñ—ñ—Ü—ñ–π–Ω–∏—Ö —Ä–µ—Å—É—Ä—Å—ñ–≤")
        
        if not df_master.empty:
            total_rows = len(df_master)
            off_rows = df_master[df_master['is_official_dynamic'] == True]
            ext_rows = df_master[df_master['is_official_dynamic'] == False]
            
            def get_counts(df_sub):
                cnt = len(df_sub)
                if cnt == 0: return 0, 0, 0, 0
                p_c = len(df_sub[df_sub['provider'] == 'Perplexity'])
                g_c = len(df_sub[df_sub['provider'] == 'OpenAI GPT'])
                gem_c = len(df_sub[df_sub['provider'] == 'Google Gemini'])
                return cnt, p_c, g_c, gem_c

            tot_all, tot_p, tot_g, tot_gem = get_counts(df_master)
            off_all, off_p, off_g, off_gem = get_counts(off_rows)
            
            c_chart, c_stats = st.columns([2.5, 1.5], vertical_alignment="center")
            
            with c_chart:
                if total_rows > 0:
                    fig = px.pie(
                        names=["–û—Ñ—ñ—Ü—ñ–π–Ω—ñ", "–ó–æ–≤–Ω—ñ—à–Ω—ñ"], 
                        values=[off_all, len(ext_rows)],
                        hole=0.55, 
                        color_discrete_sequence=["#00C896", "#E0E0E0"]
                    )
                    fig.update_layout(margin=dict(t=10, b=10, l=10, r=10), height=350, showlegend=True)
                    fig.update_traces(textposition='inside', textinfo='percent+label')
                    st.plotly_chart(fig, use_container_width=True, key="unique_chart_key_sources_1")
                else:
                    st.info("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö.")

            with c_stats:
                st.markdown(f"""
                <div style="margin-bottom: 20px; padding:20px; border:1px solid #eee; border-radius:12px; background:white; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
                    <div style="color:#888; font-size:13px; font-weight:700; text-transform:uppercase; margin-bottom:5px;">–í—Å—å–æ–≥–æ –ø–æ—Å–∏–ª–∞–Ω—å</div>
                    <div style="font-size:32px; font-weight:800; color:#333; line-height:1;">{tot_all}</div>
                    <div style="margin-top:10px; font-size:12px; color:#555; display:flex; flex-direction:column; gap:3px;">
                        <div>üîπ Perplexity: <b>{tot_p}</b></div>
                        <div>üî∏ OpenAI GPT: <b>{tot_g}</b></div>
                        <div>‚ú® Google Gemini: <b>{tot_gem}</b></div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                st.markdown(f"""
                <div style="padding:20px; border:1px solid #00C896; border-radius:12px; background:#f0fdf9; box-shadow: 0 2px 5px rgba(0,200,150,0.1);">
                    <div style="color:#007a5c; font-size:13px; font-weight:700; text-transform:uppercase; margin-bottom:5px;">–ó –Ω–∏—Ö –æ—Ñ—ñ—Ü—ñ–π–Ω—ñ</div>
                    <div style="font-size:32px; font-weight:800; color:#00C896; line-height:1;">{off_all}</div>
                    <div style="margin-top:10px; font-size:12px; color:#005c45; display:flex; flex-direction:column; gap:3px;">
                        <div>üîπ Perplexity: <b>{off_p}</b></div>
                        <div>üî∏ OpenAI GPT: <b>{off_g}</b></div>
                        <div>‚ú® Google Gemini: <b>{off_gem}</b></div>
                    </div>
                </div>
                """, unsafe_allow_html=True)

        else:
            st.info("–î–∞–Ω—ñ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è –≤—ñ–¥—Å—É—Ç–Ω—ñ.")

        st.divider()

        # --- –†–ï–î–ê–ö–¢–û–† WHITELIST (–ó –û–ù–û–í–õ–ï–ù–ò–ú –î–ò–ó–ê–ô–ù–û–ú) ---
        st.subheader("‚öôÔ∏è –ö–µ—Ä—É–≤–∞–Ω–Ω—è —Å–ø–∏—Å–∫–æ–º (Whitelist)")
        
        if "edit_whitelist_mode" not in st.session_state:
            st.session_state["edit_whitelist_mode"] = False

        # –ì–æ—Ç—É—î–º–æ DataFrame
        if assets_list_dicts:
            df_assets = pd.DataFrame(assets_list_dicts)
        else:
            df_assets = pd.DataFrame(columns=["–î–æ–º–µ–Ω", "–ú—ñ—Ç–∫–∞"])

        # –†–∞—Ö—É—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (—Å–∫—ñ–ª—å–∫–∏ —Ä–∞–∑—ñ–≤ —Ü–µ–π –¥–æ–º–µ–Ω –∑—É—Å—Ç—Ä—ñ—á–∞–≤—Å—è –≤ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—ñ)
        if not df_master.empty:
            def get_stat_whitelist(dom):
                matches = df_master[df_master['url'].astype(str).str.contains(dom.lower(), case=False, na=False)]
                return len(matches)
            
            df_assets['–ó–≥–∞–¥–æ–∫'] = df_assets['–î–æ–º–µ–Ω'].apply(get_stat_whitelist)
        else:
            df_assets['–ó–≥–∞–¥–æ–∫'] = 0

        # --- –í–Ü–î–û–ë–†–ê–ñ–ï–ù–ù–Ø –¢–ê–ë–õ–ò–¶–Ü (View Mode) ---
        if not st.session_state["edit_whitelist_mode"]:
            st.dataframe(
                df_assets,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "–î–æ–º–µ–Ω": st.column_config.TextColumn("–î–æ–º–µ–Ω / URL", width="medium"),
                    "–ú—ñ—Ç–∫–∞": st.column_config.TextColumn("–¢–∏–ø —Ä–µ—Å—É—Ä—Å—É", width="small"),
                    "–ó–≥–∞–¥–æ–∫": st.column_config.NumberColumn("–ó–Ω–∞–π–¥–µ–Ω–æ —Ä–∞–∑—ñ–≤", format="%d")
                }
            )
            
            if st.button("‚úèÔ∏è –†–µ–¥–∞–≥—É–≤–∞—Ç–∏ —Å–ø–∏—Å–æ–∫"):
                st.session_state["edit_whitelist_mode"] = True
                st.rerun()
        
        # --- –†–ï–ñ–ò–ú –†–ï–î–ê–ì–£–í–ê–ù–ù–Ø (Edit Mode) ---
        else:
            st.info("–î–æ–¥–∞–π—Ç–µ –∞–±–æ –≤–∏–¥–∞–ª—ñ—Ç—å –¥–æ–º–µ–Ω–∏. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å '–ó–±–µ—Ä–µ–≥—Ç–∏' –¥–ª—è –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –∑–º—ñ–Ω.")
            
            # –Ø–∫—â–æ —Ç–∞–±–ª–∏—Ü—è –ø—É—Å—Ç–∞, –¥–æ–¥–∞—î–º–æ —Ä—è–¥–æ–∫
            if df_assets.empty: 
                edit_df_input = pd.DataFrame([{"–î–æ–º–µ–Ω": "", "–ú—ñ—Ç–∫–∞": "–í–µ–±-—Å–∞–π—Ç"}])
            else:
                edit_df_input = df_assets[["–î–æ–º–µ–Ω", "–ú—ñ—Ç–∫–∞"]]
            
            edited_df = st.data_editor(
                edit_df_input,
                num_rows="dynamic",
                use_container_width=True,
                hide_index=True, # –ß–∏—Å—Ç–æ, —è–∫ –ø—Ä–æ—Å–∏–ª–∏
                column_config={
                    "–î–æ–º–µ–Ω": st.column_config.TextColumn("–î–æ–º–µ–Ω / URL", required=True),
                    "–ú—ñ—Ç–∫–∞": st.column_config.SelectboxColumn(
                        "–¢–∏–ø —Ä–µ—Å—É—Ä—Å—É",
                        options=["–í–µ–±-—Å–∞–π—Ç", "–°–æ—Ü—ñ–∞–ª—å–Ω—ñ –º–µ—Ä–µ–∂—ñ", "–°—Ç–∞—Ç—Ç—è", "–Ü–Ω—à–µ"],
                        required=True
                    )
                }
            )
            
            c1, c2 = st.columns([1, 4])
            with c1:
                if st.button("üíæ –ó–±–µ—Ä–µ–≥—Ç–∏", type="primary"):
                    try:
                        # 1. –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ –∑–∞–ø–∏—Å–∏ –¥–ª—è —Ü—å–æ–≥–æ –ø—Ä–æ–µ–∫—Ç—É
                        supabase.table("official_assets").delete().eq("project_id", proj["id"]).execute()
                        
                        # 2. –§–æ—Ä–º—É—î–º–æ –Ω–æ–≤—ñ
                        insert_data = []
                        for _, row in edited_df.iterrows():
                            d_val = str(row["–î–æ–º–µ–Ω"]).strip()
                            if d_val:
                                insert_data.append({
                                    "project_id": proj["id"],
                                    "domain_or_url": d_val,
                                    "type": row["–ú—ñ—Ç–∫–∞"]
                                })
                        
                        # 3. –í—Å—Ç–∞–≤–ª—è—î–º–æ
                        if insert_data:
                            supabase.table("official_assets").insert(insert_data).execute()
                            
                        st.success("–°–ø–∏—Å–æ–∫ –æ–Ω–æ–≤–ª–µ–Ω–æ!")
                        st.session_state["edit_whitelist_mode"] = False
                        time.sleep(1)
                        st.rerun()
                    except Exception as e:
                        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è: {e}")
            with c2:
                if st.button("‚ùå –°–∫–∞—Å—É–≤–∞—Ç–∏"):
                    st.session_state["edit_whitelist_mode"] = False
                    st.rerun()

    # --- TAB 2: –†–ï–ù–ö–Ü–ù–ì ---
    with tab2:
        st.markdown("#### üèÜ –†–µ–Ω–∫—ñ–Ω–≥ –¥–æ–º–µ–Ω—ñ–≤")
        if not df_master.empty:
            all_kws = sorted(df_master['keyword_text'].unique())
            sel_kws_rank = st.multiselect("üîç –§—ñ–ª—å—Ç—Ä –ø–æ –∑–∞–ø–∏—Ç–∞—Ö:", all_kws, key="rank_kw_filter")
            
            df_rank_view = df_master.copy()
            if sel_kws_rank:
                df_rank_view = df_rank_view[df_rank_view['keyword_text'].isin(sel_kws_rank)]
            
            if not df_rank_view.empty:
                pivot_df = df_rank_view.pivot_table(
                    index='domain', columns='provider', values='mention_count', aggfunc='sum', fill_value=0
                ).reset_index()
                
                pivot_df['–í—Å—å–æ–≥–æ'] = pivot_df.sum(axis=1, numeric_only=True)
                for col in ["Perplexity", "OpenAI GPT", "Google Gemini"]:
                    if col not in pivot_df.columns: pivot_df[col] = 0
                
                def get_meta(dom):
                    is_off = "–ó–æ–≤–Ω—ñ—à–Ω—ñ–π"
                    for od in OFFICIAL_DOMAINS:
                        if od in dom.lower():
                            is_off = "–û—Ñ—ñ—Ü—ñ–π–Ω–∏–π"
                            break
                    dates = df_rank_view[df_rank_view['domain'] == dom]['scan_date']
                    first = dates.min() if not dates.empty else None
                    first_str = pd.to_datetime(first).strftime("%Y-%m-%d") if first else "-"
                    return is_off, first_str

                pivot_df[['–¢–∏–ø', '–í–ø–µ—Ä—à–µ –∑–Ω–∞–π–¥–µ–Ω–æ']] = pivot_df['domain'].apply(lambda x: pd.Series(get_meta(x)))
                pivot_df = pivot_df.sort_values("–í—Å—å–æ–≥–æ", ascending=False).reset_index(drop=True)
                
                cols_order = ["domain", "–¢–∏–ø", "–í—Å—å–æ–≥–æ", "Perplexity", "OpenAI GPT", "Google Gemini", "–í–ø–µ—Ä—à–µ –∑–Ω–∞–π–¥–µ–Ω–æ"]
                final_cols = [c for c in cols_order if c in pivot_df.columns]
                
                st.dataframe(
                    pivot_df[final_cols],
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "domain": "–î–æ–º–µ–Ω",
                        "–í—Å—å–æ–≥–æ": st.column_config.NumberColumn(format="%d"),
                        "Perplexity": st.column_config.NumberColumn(format="%d"),
                        "OpenAI GPT": st.column_config.NumberColumn(format="%d"),
                        "Google Gemini": st.column_config.NumberColumn(format="%d"),
                    }
                )
            else:
                st.warning("–î–∞–Ω–∏—Ö –Ω–µ–º–∞—î.")
        else:
            st.info("–î–∞–Ω—ñ –≤—ñ–¥—Å—É—Ç–Ω—ñ.")

    # --- TAB 3: –ü–û–°–ò–õ–ê–ù–ù–Ø ---
    with tab3:
        st.markdown("#### üîó –î–µ—Ç–∞–ª—å–Ω–∏–π —Å–ø–∏—Å–æ–∫ –ø–æ—Å–∏–ª–∞–Ω—å")
        if not df_master.empty:
            c_f1, c_f2 = st.columns([1, 1])
            with c_f1: sel_kws_links = st.multiselect("üîç –§—ñ–ª—å—Ç—Ä –ø–æ –∑–∞–ø–∏—Ç–∞—Ö:", all_kws, key="links_kw_filter")
            with c_f2: search_url = st.text_input("üîé –ü–æ—à—É–∫ URL:", key="links_search")
            
            c_f3, c_f4 = st.columns(2)
            with c_f3: type_filter = st.selectbox("–¢–∏–ø —Ä–µ—Å—É—Ä—Å—É:", ["–í—Å—ñ", "–û—Ñ—ñ—Ü—ñ–π–Ω—ñ", "–ó–æ–≤–Ω—ñ—à–Ω—ñ"], key="links_type_filter")
            
            df_links_view = df_master.copy()
            if sel_kws_links: df_links_view = df_links_view[df_links_view['keyword_text'].isin(sel_kws_links)]
            if search_url: df_links_view = df_links_view[df_links_view['url'].astype(str).str.contains(search_url, case=False)]
            if type_filter == "–û—Ñ—ñ—Ü—ñ–π–Ω—ñ": df_links_view = df_links_view[df_links_view['is_official_dynamic'] == True]
            elif type_filter == "–ó–æ–≤–Ω—ñ—à–Ω—ñ": df_links_view = df_links_view[df_links_view['is_official_dynamic'] == False]

            if not df_links_view.empty:
                pivot_links = df_links_view.pivot_table(
                    index=['url', 'domain', 'is_official_dynamic'],
                    columns='provider', values='mention_count', aggfunc='sum', fill_value=0
                ).reset_index()
                
                pivot_links['–í—Å—å–æ–≥–æ'] = pivot_links.sum(axis=1, numeric_only=True)
                for col in ["Perplexity", "OpenAI GPT", "Google Gemini"]:
                    if col not in pivot_links.columns: pivot_links[col] = 0
                
                pivot_links['–¢–∏–ø'] = pivot_links['is_official_dynamic'].apply(lambda x: "–û—Ñ—ñ—Ü—ñ–π–Ω—ñ" if x else "–ó–æ–≤–Ω—ñ—à–Ω—ñ")
                pivot_links = pivot_links.sort_values("–í—Å—å–æ–≥–æ", ascending=False).reset_index(drop=True)
                
                cols_order = ["url", "domain", "–¢–∏–ø", "–í—Å—å–æ–≥–æ", "Perplexity", "OpenAI GPT", "Google Gemini"]
                final_cols = [c for c in cols_order if c in pivot_links.columns]
                
                st.dataframe(
                    pivot_links[final_cols],
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "url": st.column_config.LinkColumn("–ü–æ—Å–∏–ª–∞–Ω–Ω—è", width="large"),
                        "–í—Å—å–æ–≥–æ": st.column_config.NumberColumn(format="%d"),
                        "Perplexity": st.column_config.NumberColumn(format="%d"),
                        "OpenAI GPT": st.column_config.NumberColumn(format="%d"),
                        "Google Gemini": st.column_config.NumberColumn(format="%d"),
                    }
                )
            else:
                st.warning("–ù—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        else:
            st.info("–î–∞–Ω—ñ –≤—ñ–¥—Å—É—Ç–Ω—ñ.")


def show_history_page():
    """
    –°—Ç–æ—Ä—ñ–Ω–∫–∞ —ñ—Å—Ç–æ—Ä—ñ—ó —Å–∫–∞–Ω—É–≤–∞–Ω—å.
    –í–ï–†–°–Ü–Ø: PRETTY LLM NAMES.
    1. –ü–µ—Ä–µ–π–º–µ–Ω–æ–≤—É—î gpt-4o -> OpenAI, gemini -> Gemini —Ç–æ—â–æ.
    2. –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ –≤—Å—ñ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ –ø–æ–º–∏–ª–∫–∏ (Timezone, Merge).
    """
    import pandas as pd
    import streamlit as st
    from datetime import datetime, timedelta, timezone 

    # --- 1. –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø ---
    if 'supabase' in st.session_state:
        supabase = st.session_state['supabase']
    elif 'supabase' in globals():
        supabase = globals()['supabase']
    else:
        st.error("üö® –ü–æ–º–∏–ª–∫–∞: –ó–º—ñ–Ω–Ω–∞ 'supabase' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
        return

    proj = st.session_state.get("current_project")
    if not proj:
        st.info("–°–ø–æ—á–∞—Ç–∫—É –æ–±–µ—Ä—ñ—Ç—å –ø—Ä–æ–µ–∫—Ç.")
        return

    st.title("üìú –Ü—Å—Ç–æ—Ä—ñ—è —Å–∫–∞–Ω—É–≤–∞–Ω—å")

    # --- 2. –û–¢–†–ò–ú–ê–ù–ù–Ø –î–ê–ù–ò–• ---
    with st.spinner("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó..."):
        try:
            # 1. Keywords
            kw_resp = supabase.table("keywords").select("id, keyword_text").eq("project_id", proj["id"]).execute()
            kw_map = {k['id']: k['keyword_text'] for k in kw_resp.data} if kw_resp.data else {}

            # 2. Scans
            scans_resp = supabase.table("scan_results")\
                .select("id, created_at, provider, keyword_id")\
                .eq("project_id", proj["id"])\
                .order("created_at", desc=True)\
                .limit(500)\
                .execute()
            
            scans_data = scans_resp.data if scans_resp.data else []
            
            if not scans_data:
                st.info("–Ü—Å—Ç–æ—Ä—ñ—è —Å–∫–∞–Ω—É–≤–∞–Ω—å –ø–æ—Ä–æ–∂–Ω—è.")
                return

            scan_ids = [s['id'] for s in scans_data]

            # 3. Mentions
            m_resp = supabase.table("brand_mentions")\
                .select("scan_result_id, is_my_brand, mention_count")\
                .in_("scan_result_id", scan_ids)\
                .execute()
            mentions_df = pd.DataFrame(m_resp.data) if m_resp.data else pd.DataFrame()

            # 4. Sources
            s_resp = supabase.table("extracted_sources")\
                .select("scan_result_id, is_official")\
                .in_("scan_result_id", scan_ids)\
                .execute()
            sources_df = pd.DataFrame(s_resp.data) if s_resp.data else pd.DataFrame()

        except Exception as e:
            st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö: {e}")
            return

    # --- 3. –û–ë–†–û–ë–ö–ê –î–ê–ù–ò–• ---
    df_scans = pd.DataFrame(scans_data)

    # üî• –ú–ê–ü–Ü–ù–ì –ù–ê–ó–í (–†–æ–±–∏–º–æ —Ü–µ –Ω–∞ –ø–æ—á–∞—Ç–∫—É)
    PROVIDER_MAP = {
        "gpt-4o": "OpenAI",
        "gpt-4-turbo": "OpenAI",
        "gemini-1.5-pro": "Gemini",
        "perplexity": "Perplexity"
    }
    # –ó–∞–º—ñ–Ω—é—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ provider. –Ø–∫—â–æ –∑–Ω–∞—á–µ–Ω–Ω—è –Ω–µ–º–∞—î –≤ —Å–ª–æ–≤–Ω–∏–∫—É, –≤–æ–Ω–æ –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è —è–∫ –±—É–ª–æ.
    df_scans['provider'] = df_scans['provider'].replace(PROVIDER_MAP)
    
    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞
    df_scans['keyword'] = df_scans['keyword_id'].map(kw_map).fillna("–í–∏–¥–∞–ª–µ–Ω–∏–π –∑–∞–ø–∏—Ç")
    df_scans['created_at_dt'] = pd.to_datetime(df_scans['created_at'])
    
    # –ê–≥—Ä–µ–≥–∞—Ü—ñ—è Mentions
    if not mentions_df.empty:
        brands_count = mentions_df.groupby('scan_result_id').size().reset_index(name='total_brands')
        my_mentions = mentions_df[mentions_df['is_my_brand'] == True].groupby('scan_result_id')['mention_count'].sum().reset_index(name='my_mentions_count')
        
        df_scans = pd.merge(df_scans, brands_count, left_on='id', right_on='scan_result_id', how='left').fillna(0)
        if 'scan_result_id' in df_scans.columns: df_scans = df_scans.drop(columns=['scan_result_id'])
            
        df_scans = pd.merge(df_scans, my_mentions, left_on='id', right_on='scan_result_id', how='left').fillna(0)
        if 'scan_result_id' in df_scans.columns: df_scans = df_scans.drop(columns=['scan_result_id'])
    else:
        df_scans['total_brands'] = 0
        df_scans['my_mentions_count'] = 0

    # –ê–≥—Ä–µ–≥–∞—Ü—ñ—è Sources
    if not sources_df.empty:
        links_count = sources_df.groupby('scan_result_id').size().reset_index(name='total_links')
        official_count = sources_df[sources_df['is_official'] == True].groupby('scan_result_id').size().reset_index(name='official_links')
        
        df_scans = pd.merge(df_scans, links_count, left_on='id', right_on='scan_result_id', how='left').fillna(0)
        if 'scan_result_id' in df_scans.columns: df_scans = df_scans.drop(columns=['scan_result_id'])
            
        df_scans = pd.merge(
            df_scans, 
            official_count, 
            left_on='id', 
            right_on='scan_result_id', 
            how='left',
            suffixes=('', '_dup')
        ).fillna(0)
        
        if 'scan_result_id' in df_scans.columns: df_scans = df_scans.drop(columns=['scan_result_id'])
    else:
        df_scans['total_links'] = 0
        df_scans['official_links'] = 0

    # --- 4. –§–Ü–õ–¨–¢–†–ò –¢–ê –°–û–†–¢–£–í–ê–ù–ù–Ø ---
    st.markdown("### üîç –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è")
    
    c1, c2, c3 = st.columns([1, 1, 1.5])
    
    with c1:
        # –¢–µ–ø–µ—Ä —Ç—É—Ç –±—É–¥—É—Ç—å –∫—Ä–∞—Å–∏–≤—ñ –Ω–∞–∑–≤–∏ (OpenAI, Gemini...)
        all_providers = df_scans['provider'].unique().tolist()
        sel_providers = st.multiselect("–ú–æ–¥–µ–ª—å (LLM)", all_providers, default=all_providers)
    
    with c2:
        date_options = ["–í–µ—Å—å —á–∞—Å", "–°—å–æ–≥–æ–¥–Ω—ñ", "–û—Å—Ç–∞–Ω–Ω—ñ 7 –¥–Ω—ñ–≤", "–û—Å—Ç–∞–Ω–Ω—ñ 30 –¥–Ω—ñ–≤"]
        sel_date = st.selectbox("–ü–µ—Ä—ñ–æ–¥", date_options)
        
    with c3:
        sort_opts = [
            "–ù–∞–π–Ω–æ–≤—ñ—à—ñ —Å–ø–æ—á–∞—Ç–∫—É", 
            "–ù–∞–π—Å—Ç–∞—Ä—ñ—à—ñ —Å–ø–æ—á–∞—Ç–∫—É", 
            "–ù–∞–π–±—ñ–ª—å—à–µ –∑–≥–∞–¥–æ–∫ –±—Ä–µ–Ω–¥—É", 
            "–ù–∞–π–º–µ–Ω—à–µ –∑–≥–∞–¥–æ–∫ –±—Ä–µ–Ω–¥—É",
            "–ù–∞–π–±—ñ–ª—å—à–µ –æ—Ñ—ñ—Ü—ñ–π–Ω–∏—Ö –¥–∂–µ—Ä–µ–ª",
            "–ù–∞–π–±—ñ–ª—å—à–µ –∑–Ω–∞–π–¥–µ–Ω–∏—Ö –±—Ä–µ–Ω–¥—ñ–≤"
        ]
        sel_sort = st.selectbox("–°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è", sort_opts)

    # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è
    mask = df_scans['provider'].isin(sel_providers)
    
    now = datetime.now(timezone.utc)
    
    if sel_date == "–°—å–æ–≥–æ–¥–Ω—ñ":
        mask &= (df_scans['created_at_dt'].dt.date == now.date())
    elif sel_date == "–û—Å—Ç–∞–Ω–Ω—ñ 7 –¥–Ω—ñ–≤":
        mask &= (df_scans['created_at_dt'] >= (now - timedelta(days=7)))
    elif sel_date == "–û—Å—Ç–∞–Ω–Ω—ñ 30 –¥–Ω—ñ–≤":
        mask &= (df_scans['created_at_dt'] >= (now - timedelta(days=30)))
        
    df_final = df_scans[mask].copy()

    # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è
    if sel_sort == "–ù–∞–π–Ω–æ–≤—ñ—à—ñ —Å–ø–æ—á–∞—Ç–∫—É":
        df_final = df_final.sort_values('created_at_dt', ascending=False)
    elif sel_sort == "–ù–∞–π—Å—Ç–∞—Ä—ñ—à—ñ —Å–ø–æ—á–∞—Ç–∫—É":
        df_final = df_final.sort_values('created_at_dt', ascending=True)
    elif sel_sort == "–ù–∞–π–±—ñ–ª—å—à–µ –∑–≥–∞–¥–æ–∫ –±—Ä–µ–Ω–¥—É":
        df_final = df_final.sort_values('my_mentions_count', ascending=False)
    elif sel_sort == "–ù–∞–π–º–µ–Ω—à–µ –∑–≥–∞–¥–æ–∫ –±—Ä–µ–Ω–¥—É":
        df_final = df_final.sort_values('my_mentions_count', ascending=True)
    elif sel_sort == "–ù–∞–π–±—ñ–ª—å—à–µ –æ—Ñ—ñ—Ü—ñ–π–Ω–∏—Ö –¥–∂–µ—Ä–µ–ª":
        df_final = df_final.sort_values('official_links', ascending=False)
    elif sel_sort == "–ù–∞–π–±—ñ–ª—å—à–µ –∑–Ω–∞–π–¥–µ–Ω–∏—Ö –±—Ä–µ–Ω–¥—ñ–≤":
        df_final = df_final.sort_values('total_brands', ascending=False)

    # --- 5. –í–Ü–î–û–ë–†–ê–ñ–ï–ù–ù–Ø ---
    st.divider()
    st.markdown(f"**–ó–Ω–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å—ñ–≤:** {len(df_final)}")
    
    cols_to_show = [
        'created_at_dt', 'keyword', 'provider', 
        'total_brands', 'total_links', 'my_mentions_count', 'official_links'
    ]
    # –ó–∞—Ö–∏—Å—Ç, —è–∫—â–æ —è–∫–∏—Ö–æ—Å—å –∫–æ–ª–æ–Ω–æ–∫ –Ω–µ–º–∞—î
    cols_to_show = [c for c in cols_to_show if c in df_final.columns]
    
    df_display = df_final[cols_to_show].copy()
    
    if 'created_at_dt' in df_display.columns:
        df_display['created_at_dt'] = df_display['created_at_dt'].dt.strftime('%d.%m.%Y %H:%M')

    st.dataframe(
        df_display,
        use_container_width=True,
        hide_index=True,
        column_config={
            "created_at_dt": "–î–∞—Ç–∞ —Ç–∞ –ß–∞—Å",
            "keyword": st.column_config.TextColumn("–ó–∞–ø–∏—Ç", width="medium"),
            "provider": "LLM",
            "total_brands": st.column_config.NumberColumn("–í—Å—å–æ–≥–æ –±—Ä–µ–Ω–¥—ñ–≤", help="–£–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –±—Ä–µ–Ω–¥—ñ–≤"),
            "total_links": st.column_config.NumberColumn("–í—Å—å–æ–≥–æ –ø–æ—Å–∏–ª–∞–Ω—å", help="–í—Å—å–æ–≥–æ –∑–Ω–∞–π–¥–µ–Ω–æ"),
            "my_mentions_count": st.column_config.NumberColumn("–ó–≥–∞–¥–æ–∫ –Ω–∞—Å", help="–ù–∞—à –±—Ä–µ–Ω–¥"),
            "official_links": st.column_config.NumberColumn("–û—Ñ—ñ—Ü. –¥–∂–µ—Ä–µ–ª–∞", help="Whitelist")
        }
    )


def sidebar_menu():
    """
    –ë–æ–∫–æ–≤–µ –º–µ–Ω—é –Ω–∞–≤—ñ–≥–∞—Ü—ñ—ó.
    –í–ï–†–°–Ü–Ø: FIXED & FULL (Menu, User Profile, Support, Navigation).
    """
    from streamlit_option_menu import option_menu
    import streamlit as st
    
    # –û—Ç—Ä–∏–º—É—î–º–æ –¥–∞–Ω—ñ –∑ —Å–µ—Å—ñ—ó
    proj = st.session_state.get("current_project")
    user = st.session_state.get("user")
    
    # –î–∞–Ω—ñ –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
    user_email = user.email if user else "–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á"
    proj_name = proj.get("brand_name", "No Project") if proj else "–û–±–µ—Ä—ñ—Ç—å –ø—Ä–æ–µ–∫—Ç"
    proj_id = proj.get("id", "") if proj else ""

    with st.sidebar:
        # 1. –õ–æ–≥–æ—Ç–∏–ø
        st.image("https://raw.githubusercontent.com/virshi-ai/image/refs/heads/main/logo-removebg-preview.png", width=160)
        
        st.divider()

        # 2. –ü—Ä–æ—Ñ—ñ–ª—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (–í—ñ–¥–Ω–æ–≤–ª–µ–Ω–æ)
        with st.container():
            c1, c2 = st.columns([0.2, 0.8])
            with c1:
                st.markdown("üë§") # –ê–±–æ —ñ–∫–æ–Ω–∫–∞ –∞–≤–∞—Ç–∞—Ä–∞
            with c2:
                st.caption("–í–∏ —É–≤—ñ–π—à–ª–∏ —è–∫:")
                st.markdown(f"**{user_email}**")
        
        st.write("") # –í—ñ–¥—Å—Ç—É–ø

        # 3. –í–∏–±—ñ—Ä –ø—Ä–æ–µ–∫—Ç—É
        with st.expander(f"üìÅ {proj_name}", expanded=False):
            st.caption(f"ID: {proj_id}")
            if st.button("üîÑ –ó–º—ñ–Ω–∏—Ç–∏ –ø—Ä–æ–µ–∫—Ç"):
                st.session_state["current_project"] = None
                st.rerun()

        st.write("") 

        # 4. –ù–∞–≤—ñ–≥–∞—Ü—ñ–π–Ω–µ –º–µ–Ω—é
        options = [
            "–î–∞—à–±–æ—Ä–¥", 
            "–ü–µ—Ä–µ–ª—ñ–∫ –∑–∞–ø–∏—Ç—ñ–≤", 
            "–î–∂–µ—Ä–µ–ª–∞", 
            "–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–∏", 
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó", 
            "–Ü—Å—Ç–æ—Ä—ñ—è —Å–∫–∞–Ω—É–≤–∞–Ω—å", 
            "–ó–≤—ñ—Ç–∏",             
            "FAQ",               
            "GPT-Visibility"
        ]
        
        icons = [
            "speedometer2", 
            "list-task", 
            "router", 
            "people", 
            "lightbulb", 
            "clock-history", 
            "file-earmark-text", 
            "question-circle",   
            "robot"
        ]

        # –î–æ–¥–∞—î–º–æ –ê–¥–º—ñ–Ω–∫—É —Ç—ñ–ª—å–∫–∏ –¥–ª—è –∞–¥–º—ñ–Ω—ñ–≤
        if st.session_state.get("role") in ["admin", "super_admin"]:
            options.append("–ê–¥–º—ñ–Ω")
            icons.append("shield-lock")

        selected = option_menu(
            "–ú–µ–Ω—é",
            options,
            icons=icons,
            menu_icon="cast",
            default_index=0,
            styles={
                "container": {"padding": "0!important", "background-color": "transparent"},
                "icon": {"color": "grey", "font-size": "16px"}, 
                "nav-link": {"font-size": "14px", "text-align": "left", "margin":"0px", "--hover-color": "#eee"},
                "nav-link-selected": {"background-color": "#00C896"},
            }
        )
        
        st.divider()

        # 5. –°–∞–ø–æ—Ä—Ç (–í—ñ–¥–Ω–æ–≤–ª–µ–Ω–æ)
        st.caption("–ü–æ—Ç—Ä—ñ–±–Ω–∞ –¥–æ–ø–æ–º–æ–≥–∞?")
        st.markdown("üìß **hi@virshi.ai**")

        # 6. –°—Ç–∞—Ç—É—Å —Ç–∞ –í–∏—Ö—ñ–¥
        if proj:
            st.write("")
            status = proj.get("status", "trial").upper()
            color = "orange" if status == "TRIAL" else "green" if status == "ACTIVE" else "red"
            st.markdown(f"–°—Ç–∞—Ç—É—Å: **:{color}[{status}]**")
            
            if st.session_state.get("is_impersonating"):
                st.info("üïµÔ∏è Admin Mode")

        st.write("")
        if st.button("üö™ –í–∏–π—Ç–∏ –∑ –∞–∫–∞—É–Ω—Ç—É", use_container_width=True):
            # –¢—É—Ç –≤–∏–∫–ª–∏–∫–∞—î–º–æ –≤–∞—à—É —Ñ—É–Ω–∫—Ü—ñ—é logout
            if 'logout' in globals():
                logout()
            else:
                # Fallback, —è–∫—â–æ —Ñ—É–Ω–∫—Ü—ñ—è logout –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞
                st.session_state.clear()
                st.rerun()

    return selected



def show_auth_page():
    """
    Renders the centered authentication card (Login / Register) with Virshi styling.
    """
    # Apply custom CSS for the auth page
    st.markdown("""
    <style>
        /* General Page Background */
        .stApp {
            background-color: #F4F7F6;
        }
        
        /* Center the form container */
        [data-testid="stForm"] {
            background-color: #ffffff;
            padding: 40px;
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.08);
            border: 1px solid #EAEAEA;
        }

        /* Input fields styling */
        .stTextInput > div > div > input {
            border-radius: 8px;
            border: 1px solid #e0e0e0;
            padding: 10px;
        }

        /* Primary Button (Virshi Green) */
        .stButton > button {
            width: 100%;
            background-color: #00C896 !important;
            color: white !important;
            border: none;
            border-radius: 8px;
            padding: 12px;
            font-weight: 600;
            margin-top: 10px;
        }
        .stButton > button:hover {
            background-color: #00a87e !important;
        }
        
        /* Tabs Styling */
        .stTabs [data-baseweb="tab-list"] {
            gap: 20px;
            justify-content: center;
        }
        .stTabs [data-baseweb="tab"] {
            height: 50px;
            white-space: pre-wrap;
            border-radius: 4px 4px 0 0;
            gap: 1px;
            padding-top: 10px;
            padding-bottom: 10px;
        }
    </style>
    """, unsafe_allow_html=True)

    # Centering Layout using Columns
    # [Empty Left] [Center Card] [Empty Right]
    col_l, col_center, col_r = st.columns([1, 1.5, 1])

    with col_center:
        # Logo Section
        st.markdown(
            '<div style="text-align: center; margin-bottom: 20px;">'
            '<img src="https://raw.githubusercontent.com/virshi-ai/image/refs/heads/main/logo-removebg-preview.png" width="180">'
            '</div>',
            unsafe_allow_html=True,
        )
        
        st.markdown("<h3 style='text-align: center; color: #333; margin-bottom: 5px;'>Welcome to Virshi</h3>", unsafe_allow_html=True)
        st.markdown("<p style='text-align: center; color: #666; margin-bottom: 30px;'>Sign in to manage your AI visibility</p>", unsafe_allow_html=True)

        # Tabs for Login / Register
        tab_login, tab_register = st.tabs(["üîë Sign In", "üìù Sign Up"])

        # --- LOGIN TAB ---
        with tab_login:
            with st.form("login_form"):
                email = st.text_input("Email", placeholder="name@company.com")
                password = st.text_input("Password", type="password", placeholder="‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢")
                
                st.write("") # Spacer
                
                submit = st.form_submit_button("Sign In", use_container_width=True)
                
                if submit:
                    if not email or not password:
                        st.warning("Please fill in all fields.")
                    else:
                        login_user(email, password)

        # --- REGISTER TAB ---
        with tab_register:
            with st.form("register_form"):
                c1, c2 = st.columns(2)
                with c1:
                    first_name = st.text_input("First Name", placeholder="Ivan")
                with c2:
                    last_name = st.text_input("Last Name", placeholder="Petrenko")
                
                new_email = st.text_input("Email", placeholder="name@company.com")
                new_password = st.text_input("Password", type="password", placeholder="‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢", help="Min 6 chars")
                
                st.write("") # Spacer
                
                submit_reg = st.form_submit_button("Create Account", use_container_width=True)
                
                if submit_reg:
                    if not new_email or not new_password or not first_name:
                        st.warning("Please fill in required fields.")
                    elif len(new_password) < 6:
                        st.warning("Password must be at least 6 characters.")
                    else:
                        register_user(new_email, new_password, first_name, last_name)



def show_admin_page():
    """
    –ê–¥–º—ñ–Ω-–ø–∞–Ω–µ–ª—å (CRM).
    –í–ï–†–°–Ü–Ø: FINAL FIXES (RESET FIELDS, IMPORT URL, STATUS ERROR HANDLING).
    1. Tab 2: –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ –æ—á–∏—â–µ–Ω–Ω—è –ø–æ–ª—ñ–≤ —á–µ—Ä–µ–∑ –¥–∏–Ω–∞–º—ñ—á–Ω—ñ –∫–ª—é—á—ñ (fix 'cannot be modified').
    2. Tab 2: –î–æ–¥–∞–Ω–æ —ñ–º–ø–æ—Ä—Ç –∑–∞–ø–∏—Ç—ñ–≤ —á–µ—Ä–µ–∑ URL.
    3. Tab 1: –û–±—Ä–æ–±–∫–∞ –ø–æ–º–∏–ª–∫–∏ ENUM –¥–ª—è —Å—Ç–∞—Ç—É—Å—É 'blocked'.
    4. Tab 3: –ü—Ä–æ–µ–∫—Ç–∏ –∑ –Ω–æ–≤–æ–≥–æ —Ä—è–¥–∫–∞.
    """
    import pandas as pd
    import streamlit as st
    import numpy as np
    import requests
    import json
    import time
    import plotly.express as px
    import io
    import re

    # --- –ö–û–ù–°–¢–ê–ù–¢–ò ---
    N8N_GEN_URL = "https://virshi.app.n8n.cloud/webhook/webhook/generate-prompts"

    # --- 0. –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø ---
    if 'supabase' not in globals():
        if 'supabase' in st.session_state:
            supabase = st.session_state['supabase']
        else:
            st.error("üö® –ü–æ–º–∏–ª–∫–∞: –ó–º—ñ–Ω–Ω–∞ 'supabase' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
            return
    else:
        supabase = globals()['supabase']

    # --- CSS ---
    st.markdown("""
    <style>
        .green-number { 
            background-color: #00C896; 
            color: white; 
            width: 24px; 
            height: 24px; 
            border-radius: 50%; 
            display: flex; 
            align-items: center; 
            justify-content: center; 
            font-weight: bold; 
            font-size: 12px; 
        }
        .del-kw-btn { color: #FF4B4B; cursor: pointer; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

    # --- STATE –î–õ–Ø –û–ß–ò–©–ï–ù–ù–Ø –§–û–†–ú–ò ---
    if "admin_reset_id" not in st.session_state:
        st.session_state["admin_reset_id"] = 0

    # --- –•–ï–õ–ü–ï–†–ò ---
    def clean_data_for_json(data):
        if isinstance(data, dict): return {k: clean_data_for_json(v) for k, v in data.items()}
        elif isinstance(data, list): return [clean_data_for_json(v) for v in data]
        elif isinstance(data, (np.int64, np.int32, np.integer)): return int(data)
        elif isinstance(data, (np.float64, np.float32, np.floating)): return float(data)
        elif isinstance(data, (np.bool_, bool)): return bool(data)
        elif pd.isna(data): return None
        return data

    def update_project_field(proj_id, field, value):
        try:
            val = clean_data_for_json(value)
            supabase.table("projects").update({field: val}).eq("id", proj_id).execute()
            
            # –û—á–∏—Å—Ç–∫–∞ –∫–µ—à—É
            if "my_projects" in st.session_state: del st.session_state["my_projects"]
            if "all_projects_admin" in st.session_state: del st.session_state["all_projects_admin"]
            
            # –û–Ω–æ–≤–ª–µ–Ω–Ω—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ
            if "current_project" in st.session_state and st.session_state["current_project"]:
                if st.session_state["current_project"]["id"] == proj_id:
                    st.session_state["current_project"][field] = val
                
            st.toast(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ: {field} -> {value}")
            time.sleep(0.5)
        except Exception as e:
            err_msg = str(e)
            if "invalid input value for enum" in err_msg:
                st.error(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ë–î: –°—Ç–∞—Ç—É—Å '{value}' –Ω–µ –¥–æ–¥–∞–Ω–æ –≤ ENUM (—Ç–∏–ø –¥–∞–Ω–∏—Ö) —É Supabase. –ó–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ —Ä–æ–∑—Ä–æ–±–Ω–∏–∫–∞ –ë–î.")
            else:
                st.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è: {err_msg}")

    # --- –í–ï–ë–•–£–ö ---
    def trigger_keyword_generation(brand, domain, industry, products):
        payload = { "brand": brand, "domain": domain, "industry": industry, "products": products }
        headers = {"virshi-auth": "hi@virshi.ai2025"}
        try:
            response = requests.post(N8N_GEN_URL, json=payload, headers=headers, timeout=60)
            if response.status_code == 200:
                try:
                    data = response.json()
                    if isinstance(data, dict):
                        if "prompts" in data: return data["prompts"]
                        if "keywords" in data: return data["keywords"]
                        return list(data.values()) if data else []
                    elif isinstance(data, list):
                        return data
                    return []
                except ValueError:
                    return []
            else:
                st.error(f"Error: {response.status_code}")
                return []
        except Exception as e:
            st.error(f"Connection error: {e}")
            return []

    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–ø–∏—Å–∫—É
    if "new_proj_keywords" not in st.session_state:
        st.session_state["new_proj_keywords"] = [] 

    st.title("üõ°Ô∏è Admin Panel (CRM)")

    # --- 1. –û–¢–†–ò–ú–ê–ù–ù–Ø –î–ê–ù–ò–• ---
    try:
        projects_resp = supabase.table("projects").select("*").execute()
        projects_data = projects_resp.data if projects_resp.data else []

        kws_resp = supabase.table("keywords").select("project_id").execute()
        kws_df = pd.DataFrame(kws_resp.data) if kws_resp.data else pd.DataFrame()
        kw_counts = kws_df['project_id'].value_counts().to_dict() if not kws_df.empty else {}

        users_resp = supabase.table("profiles").select("*").execute()
        users_data = users_resp.data if users_resp.data else []
        
        user_map = {}
        for u in users_data:
            f_name = u.get('first_name', '') or ''
            l_name = u.get('last_name', '') or ''
            full_name = f"{f_name} {l_name}".strip() or u.get('email', 'Unknown')
            user_map[u['id']] = {
                "full_name": full_name,
                "role": u.get('role', 'user'),
                "email": u.get('email', '-'),
                "created_at": u.get('created_at', '')
            }

    except Exception as e:
        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö: {e}")
        return

    # --- 2. KPI ---
    if projects_data:
        df_stats = pd.DataFrame(projects_data)
        total = len(df_stats)
        active = len(df_stats[df_stats['status'] == 'active'])
        blocked = len(df_stats[df_stats['status'] == 'blocked'])
        trial = len(df_stats[df_stats['status'] == 'trial'])
        
        k1, k2, k3, k4 = st.columns(4)
        k1.metric("–í—Å—å–æ–≥–æ –ø—Ä–æ–µ–∫—Ç—ñ–≤", total)
        k2.metric("Active", active)
        k3.metric("Trial", trial)
        k4.metric("Blocked", blocked)

    st.write("")

    # --- 3. –í–ö–õ–ê–î–ö–ò ---
    tab_list, tab_create, tab_users = st.tabs(["üìÇ –°–ø–∏—Å–æ–∫ –ø—Ä–æ–µ–∫—Ç—ñ–≤", "‚ûï –°—Ç–≤–æ—Ä–∏—Ç–∏ –ø—Ä–æ–µ–∫—Ç", "üë• –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ & –ü—Ä–∞–≤–∞"])

    # ========================================================
    # TAB 1: –°–ü–ò–°–û–ö –ü–†–û–ï–ö–¢–Ü–í
    # ========================================================
    with tab_list:
        st.markdown("##### üîç –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —Ç–∞ –ü–æ—à—É–∫")
        
        fc1, fc2, fc3 = st.columns([2, 1.5, 1])
        with fc1:
            search_query = st.text_input("–ü–æ—à—É–∫", placeholder="–ù–∞–∑–≤–∞, ID, –¥–æ–º–µ–Ω, email –≤–ª–∞—Å–Ω–∏–∫–∞", key="adm_search")
        with fc2:
            status_filter = st.multiselect("–°—Ç–∞—Ç—É—Å", ["active", "trial", "blocked"], default=[], key="adm_status_filter", placeholder="–í—Å—ñ —Å—Ç–∞—Ç—É—Å–∏")
        with fc3:
            sort_order = st.selectbox("–°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è", ["–ù–∞–π–Ω–æ–≤—ñ—à—ñ", "–ù–∞–π—Å—Ç–∞—Ä—ñ—à—ñ"], key="adm_sort")

        st.divider()
        
        filtered_projects = []
        if projects_data:
            for p in projects_data:
                u_id = p.get('user_id')
                owner = user_map.get(u_id, {"full_name": "", "email": ""})
                
                p_name = p.get('brand_name') or p.get('project_name') or ""
                p_domain = p.get('domain') or ""
                p_id_str = str(p.get('id', ''))
                
                search_text = f"{p_name} {p_domain} {p_id_str} {owner['full_name']} {owner['email']}".lower()
                
                if search_query and search_query.lower() not in search_text: continue
                if status_filter and p.get('status', 'trial') not in status_filter: continue
                
                filtered_projects.append(p)

            reverse_sort = True if sort_order == "–ù–∞–π–Ω–æ–≤—ñ—à—ñ" else False
            filtered_projects.sort(key=lambda x: x.get('created_at', ''), reverse=reverse_sort)

        # Header
        h0, h1, h_dash, h2, h3, h_cnt, h4, h5 = st.columns([0.3, 2.2, 0.5, 1.5, 1.2, 0.8, 1, 0.5])
        h0.markdown("**#**")
        h1.markdown("**–ü—Ä–æ–µ–∫—Ç / –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á**")
        h_dash.markdown("") 
        h2.markdown("**–°—Ç–∞—Ç—É—Å**")
        h3.markdown("**–ê–≤—Ç–æ—Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è**")
        h_cnt.markdown("**–ó–∞–ø–∏—Ç—ñ–≤**")
        h4.markdown("**–î–∞—Ç–∞**")
        h5.markdown("**–î—ñ—ó**")
        st.markdown("<hr style='margin: 5px 0'>", unsafe_allow_html=True)

        if not filtered_projects: st.info("–ü—Ä–æ–µ–∫—Ç—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")

        for idx, p in enumerate(filtered_projects, 1):
            p_id = p['id']
            u_id = p.get('user_id')
            owner_info = user_map.get(u_id, {"full_name": "–ù–µ–≤—ñ–¥–æ–º–∏–π", "role": "user", "email": "-"})
            
            raw_name = p.get('brand_name') or p.get('project_name')
            domain = p.get('domain', '')
            if raw_name:
                clean_name = str(raw_name).replace('*', '').strip()
            else:
                clean_name = domain.replace('https://', '').replace('www.', '').split('/')[0] if domain else "–ë–µ–∑ –Ω–∞–∑–≤–∏"

            k_count = kw_counts.get(p_id, 0)

            with st.container():
                c0, c1, c_dash, c2, c3, c_cnt, c4, c5 = st.columns([0.3, 2.2, 0.5, 1.5, 1.2, 0.8, 1, 0.5])

                with c0: st.caption(f"{idx}")

                with c1:
                    st.markdown(f"**{clean_name}**")
                    st.caption(f"ID: `{p_id}`")
                    if domain: st.caption(f"üåê {domain}")
                    st.caption(f"üë§ {owner_info['full_name']} | {owner_info['email']}")

                with c_dash:
                    if st.button("‚ÜóÔ∏è", key=f"goto_{p_id}", help="–í—ñ–¥–∫—Ä–∏—Ç–∏ –¥–∞—à–±–æ—Ä–¥"):
                        st.session_state["current_project"] = p
                        st.session_state["selected_page"] = "–î–∞—à–±–æ—Ä–¥"
                        st.session_state["focus_keyword_id"] = None
                        st.rerun()

                with c2:
                    curr_status = p.get('status', 'trial')
                    opts = ["trial", "active", "blocked"]
                    try: idx_s = opts.index(curr_status)
                    except: idx_s = 0
                    
                    new_status = st.selectbox("St", opts, index=idx_s, key=f"st_{p_id}", label_visibility="collapsed")
                    if new_status != curr_status:
                        update_project_field(p_id, "status", new_status)

                with c3:
                    allow_cron = p.get('allow_cron', False)
                    new_cron = st.checkbox("–î–æ–∑–≤–æ–ª–∏—Ç–∏", value=allow_cron, key=f"cr_{p_id}")
                    if new_cron != allow_cron:
                        update_project_field(p_id, "allow_cron", new_cron)

                with c_cnt:
                    st.markdown(f"**{k_count}**")

                with c4:
                    raw_date = p.get('created_at', '')
                    if raw_date: st.caption(raw_date[:10])

                with c5:
                    confirm_key = f"confirm_del_{p_id}"
                    if not st.session_state.get(confirm_key, False):
                        if st.button("üóë", key=f"del_btn_{p_id}"):
                            st.session_state[confirm_key] = True
                            st.rerun()
                    else:
                        if st.button("‚úÖ", key=f"yes_{p_id}"):
                            try:
                                supabase.table("projects").delete().eq("id", p_id).execute()
                                st.success("–í–∏–¥–∞–ª–µ–Ω–æ!")
                                time.sleep(0.5)
                                st.rerun()
                            except Exception as e:
                                st.error(str(e))
                        if st.button("‚ùå", key=f"no_{p_id}"):
                            st.session_state[confirm_key] = False
                            st.rerun()
                
                st.markdown("<hr style='margin: 5px 0; border-top: 1px solid #eee;'>", unsafe_allow_html=True)

    # ========================================================
    # TAB 2: –°–¢–í–û–†–ò–¢–ò –ü–†–û–ï–ö–¢
    # ========================================================
    with tab_create:
        st.markdown("##### –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç—É")
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –¥–∏–Ω–∞–º—ñ—á–Ω–∏–π –∫–ª—é—á –¥–ª—è —Å–∫–∏–¥–∞–Ω–Ω—è –ø–æ–ª—ñ–≤
        rk = st.session_state["admin_reset_id"]
        
        c1, c2 = st.columns(2)
        new_name_val = c1.text_input("–ù–∞–∑–≤–∞ –ø—Ä–æ–µ–∫—Ç—É (–ë—Ä–µ–Ω–¥)", key=f"new_proj_name_{rk}", placeholder="–ù–∞–ø—Ä–∏–∫–ª–∞–¥: SkyUp")
        new_domain_val = c2.text_input("–î–æ–º–µ–Ω", key=f"new_proj_domain_{rk}", placeholder="skyup.aero")
        
        c3, c4 = st.columns(2)
        new_industry_val = c3.text_input("–ì–∞–ª—É–∑—å (–û–±–æ–≤'—è–∑–∫–æ–≤–æ)", key=f"new_proj_ind_{rk}", placeholder="–Ω–∞–ø—Ä. –∞–≤—ñ–∞–ø–µ—Ä–µ–≤–µ–∑–µ–Ω–Ω—è")
        
        region_options = ["Ukraine", "USA", "Europe", "Global"]
        new_region_val = c4.selectbox("–†–µ–≥—ñ–æ–Ω", region_options, key=f"new_proj_region_{rk}")

        new_desc_val = st.text_area("–ü—Ä–æ–¥—É–∫—Ç–∏/–ü–æ—Å–ª—É–≥–∏", placeholder="–Ω–∞–ø—Ä. –ª–æ—É–∫–æ—Å—Ç–µ—Ä, –∫–≤–∏—Ç–∫–∏", height=68, key=f"new_proj_desc_{rk}")
        
        if st.button("‚ú® –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ 10 –∑–∞–ø–∏—Ç—ñ–≤ (AI)", key=f"btn_gen_{rk}"):
            if new_domain_val and new_industry_val and new_desc_val: 
                brand_for_ai = new_name_val if new_name_val else new_domain_val.split('.')[0]
                
                with st.spinner("–ó–≤–µ—Ä—Ç–∞—î–º–æ—Å—å –¥–æ n8n –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó..."):
                    generated_kws = trigger_keyword_generation(
                        brand=brand_for_ai,
                        domain=new_domain_val,
                        industry=new_industry_val,
                        products=new_desc_val
                    )
                
                if generated_kws:
                    current_kws = st.session_state["new_proj_keywords"]
                    for kw in generated_kws:
                        current_kws.append({"keyword": kw})
                    st.session_state["new_proj_keywords"] = current_kws
                    st.success(f"–î–æ–¥–∞–Ω–æ {len(generated_kws)} –∑–∞–ø–∏—Ç—ñ–≤!")
                else:
                    st.warning("–í–µ–±—Ö—É–∫ –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–≤ –¥–∞–Ω–∏—Ö.")
            else:
                st.warning("‚ö†Ô∏è –ó–∞–ø–æ–≤–Ω—ñ—Ç—å: –î–æ–º–µ–Ω, –ì–∞–ª—É–∑—å —Ç–∞ –ü—Ä–æ–¥—É–∫—Ç–∏.")

        st.divider()
        st.markdown("###### üìù –†–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—ñ–≤ –ø–µ—Ä–µ–¥ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è–º")
        
        # --- –Ü–ú–ü–û–†–¢ (FILE & URL) ---
        with st.expander("üì• –Ü–º–ø–æ—Ä—Ç (Excel / URL)", expanded=False):
            st.info("üí° –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª .xlsx –∞–±–æ –≤—Å—Ç–∞–≤—Ç–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ Google Sheet. –ü–µ—Ä—à–∞ –∫–æ–ª–æ–Ω–∫–∞ –º–∞—î –Ω–∞–∑–∏–≤–∞—Ç–∏—Å—è **Keyword**.")
            
            import_source = st.radio("–î–∂–µ—Ä–µ–ª–æ:", ["–§–∞–π–ª (.xlsx)", "–ü–æ—Å–∏–ª–∞–Ω–Ω—è (URL)"], horizontal=True, key=f"admin_imp_src_{rk}")
            df_upload = None
            
            if import_source == "–§–∞–π–ª (.xlsx)":
                uploaded_file = st.file_uploader("–û–±–µ—Ä—ñ—Ç—å —Ñ–∞–π–ª Excel", type=["xlsx"], key=f"admin_kw_import_file_{rk}")
                if uploaded_file:
                    try:
                        df_upload = pd.read_excel(uploaded_file)
                    except Exception as e:
                        st.error(f"–ü–æ–º–∏–ª–∫–∞ —Ñ–∞–π–ª—É: {e}")
            else:
                import_url = st.text_input("–í—Å—Ç–∞–≤—Ç–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è (Google Sheets –∞–±–æ CSV):", key=f"admin_kw_import_url_{rk}")
                if import_url:
                    try:
                        if "docs.google.com" in import_url:
                            match = re.search(r'/d/([a-zA-Z0-9-_]+)', import_url)
                            if match:
                                sheet_id = match.group(1)
                                csv_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv"
                                df_upload = pd.read_csv(csv_url)
                            else:
                                st.error("–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ ID Google Sheet.")
                        elif import_url.endswith(".csv"):
                            df_upload = pd.read_csv(import_url)
                        elif import_url.endswith(".xlsx"):
                            df_upload = pd.read_excel(import_url)
                        else:
                            st.warning("–ü—Ä–æ–±—É—î–º–æ —è–∫ CSV...")
                            df_upload = pd.read_csv(import_url)
                    except Exception as e:
                        if "400" in str(e): st.error("–ü–æ–º–∏–ª–∫–∞ 400. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –¥–æ—Å—Ç—É–ø (Anyone with the link).")
                        else: st.error(f"–ü–æ–º–∏–ª–∫–∞ URL: {e}")

            if df_upload is not None:
                target_col = None
                cols_lower = [str(c).lower().strip() for c in df_upload.columns]
                if "keyword" in cols_lower: target_col = df_upload.columns[cols_lower.index("keyword")]
                elif "–∑–∞–ø–∏—Ç" in cols_lower: target_col = df_upload.columns[cols_lower.index("–∑–∞–ø–∏—Ç")]
                else: target_col = df_upload.columns[0]
                
                imp_kws = df_upload[target_col].dropna().astype(str).tolist()
                
                if st.button(f"–î–æ–¥–∞—Ç–∏ {len(imp_kws)} –∑–∞–ø–∏—Ç—ñ–≤", key=f"btn_add_imp_{rk}"):
                    current_kws = st.session_state["new_proj_keywords"]
                    for kw in imp_kws:
                        current_kws.append({"keyword": kw})
                    st.session_state["new_proj_keywords"] = current_kws
                    st.success("–Ü–º–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ!")
                    st.rerun()

        # --- –¢–ê–ë–õ–ò–¶–Ø –ó–ê–ü–ò–¢–Ü–í ---
        keywords_list = st.session_state["new_proj_keywords"]
        
        if not keywords_list:
            st.info("–°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Ç—ñ–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π. –î–æ–¥–∞–π—Ç–µ –≤—Ä—É—á–Ω—É –∞–±–æ –∑–≥–µ–Ω–µ—Ä—É–π—Ç–µ.")
        else:
            for i, item in enumerate(keywords_list):
                with st.container(border=True):
                    c_num, c_txt, c_act = st.columns([0.5, 8, 1])
                    with c_num:
                        st.markdown(f"<div class='green-number'>{i+1}</div>", unsafe_allow_html=True)
                    with c_txt:
                        new_val = st.text_input("kw", value=item['keyword'], key=f"edit_kw_adm_{i}_{rk}", label_visibility="collapsed")
                        if new_val != item['keyword']:
                            st.session_state["new_proj_keywords"][i]['keyword'] = new_val
                    with c_act:
                        if st.button("üóëÔ∏è", key=f"del_kw_adm_{i}_{rk}"):
                            st.session_state["new_proj_keywords"].pop(i)
                            st.rerun()

        if st.button("‚ûï –î–æ–¥–∞—Ç–∏ —Ä—è–¥–æ–∫", key=f"btn_plus_{rk}"):
            st.session_state["new_proj_keywords"].append({"keyword": ""})
            st.rerun()

        st.divider()
        c_st, c_cr = st.columns(2)
        new_status = c_st.selectbox("–ü–æ—á–∞—Ç–∫–æ–≤–∏–π —Å—Ç–∞—Ç—É—Å", ["trial", "active", "blocked"], key=f"new_proj_status_{rk}")
        new_cron = c_cr.checkbox("–î–æ–∑–≤–æ–ª–∏—Ç–∏ –∞–≤—Ç–æ—Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è –æ–¥—Ä–∞–∑—É?", value=False, key=f"new_proj_cron_{rk}")

        if st.button("üöÄ –°—Ç–≤–æ—Ä–∏—Ç–∏ –ø—Ä–æ–µ–∫—Ç —Ç–∞ –∑–±–µ—Ä–µ–≥—Ç–∏ –∑–∞–ø–∏—Ç–∏", type="primary", key=f"btn_create_{rk}"):
            final_name = new_name_val if new_name_val else new_domain_val.split('.')[0].capitalize()
            
            if new_domain_val:
                try:
                    current_user_id = st.session_state["user"].id
                    
                    new_proj_data = {
                        "user_id": current_user_id,
                        "brand_name": final_name, 
                        "domain": new_domain_val,
                        "status": new_status,
                        "allow_cron": new_cron,
                        "region": new_region_val
                    }
                    res_proj = supabase.table("projects").insert(new_proj_data).execute()
                    
                    if res_proj.data:
                        new_proj_id = res_proj.data[0]['id']
                        
                        # Whitelist Clean
                        try:
                            clean_d = new_domain_val.replace("https://", "").replace("http://", "").replace("www.", "").strip().rstrip("/")
                            supabase.table("official_assets").insert({
                                "project_id": new_proj_id, 
                                "domain_or_url": clean_d, 
                                "type": "website"
                            }).execute()
                        except: pass

                        final_kws_clean = [k['keyword'].strip() for k in keywords_list if k['keyword'].strip()]
                        
                        if final_kws_clean:
                            kws_data = [
                                {
                                    "project_id": new_proj_id, 
                                    "keyword_text": kw,
                                    "is_active": True
                                } for kw in final_kws_clean
                            ]
                            supabase.table("keywords").insert(kws_data).execute()
                        
                        # --- SUCCESS & RESET ---
                        st.session_state["new_proj_keywords"] = [] 
                        if "my_projects" in st.session_state: del st.session_state["my_projects"]
                        
                        # –ó–º—ñ–Ω—é—î–º–æ –∫–ª—é—á, —â–æ–± –æ—á–∏—Å—Ç–∏—Ç–∏ —ñ–Ω–ø—É—Ç–∏
                        st.session_state["admin_reset_id"] += 1
                        
                        st.success(f"‚úÖ –ü—Ä–æ–µ–∫—Ç '{final_name}' —É—Å–ø—ñ—à–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–æ!")
                        time.sleep(2)
                        st.rerun()
                except Exception as e:
                    st.error(f"–ü–æ–º–∏–ª–∫–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è: {e}")
            else:
                st.warning("–î–æ–º–µ–Ω –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–π.")

    # ========================================================
    # TAB 3: –ö–û–†–ò–°–¢–£–í–ê–ß–Ü –¢–ê –ü–†–ê–í–ê (NEW LINE PROJECTS)
    # ========================================================
    with tab_users:
        st.markdown("##### üë• –ë–∞–∑–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤")

        uf1, uf2 = st.columns(2)
        with uf1:
            u_search = st.text_input("üîç –ü–æ—à—É–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞", placeholder="–Ü–º'—è –∞–±–æ email")
        with uf2:
            role_filter = st.multiselect("–†–æ–ª—å", ["user", "admin", "super_admin"], default=[])

        if users_data:
            proj_df = pd.DataFrame(projects_data)
            
            user_table_data = []
            for u in users_data:
                full_name = f"{u.get('first_name', '')} {u.get('last_name', '')}".strip()
                email = u.get('email', '')
                
                search_target = f"{full_name} {email}".lower()
                if u_search and u_search.lower() not in search_target: continue
                if role_filter and u.get('role', 'user') not in role_filter: continue

                user_projs = []
                if not proj_df.empty and 'user_id' in proj_df.columns:
                    my_projs = proj_df[proj_df['user_id'] == u['id']]
                    for _, p_row in my_projs.iterrows():
                        p_nm = p_row.get('brand_name') or p_row.get('project_name') or 'NoName'
                        p_dt = p_row.get('created_at', '')[:10]
                        user_projs.append(f"{p_nm} ({p_dt})")
                
                # üî• FIX: –ù–æ–≤–∏–π —Ä—è–¥–æ–∫
                projs_str = "\n".join(user_projs) if user_projs else "-"

                user_table_data.append({
                    "id": u['id'],
                    "–Ü–º'—è": full_name,
                    "Email": email,
                    "–†–æ–ª—å": u.get('role', 'user'),
                    "–ü—Ä–æ–µ–∫—Ç–∏": projs_str, 
                    "–ó–∞—Ä–µ—î—Å—Ç—Ä–æ–≤–∞–Ω–∏–π": u.get('created_at', '')[:10]
                })
            
            df_users_view = pd.DataFrame(user_table_data)
            
            if not df_users_view.empty:
                df_users_view.index = np.arange(1, len(df_users_view) + 1)
                
                edited_users = st.data_editor(
                    df_users_view,
                    column_config={
                        "id": st.column_config.TextColumn("User ID", disabled=True, width="small"),
                        "Email": st.column_config.TextColumn("Email", disabled=True),
                        "–Ü–º'—è": st.column_config.TextColumn("–Ü–º'—è", disabled=True),
                        "–ü—Ä–æ–µ–∫—Ç–∏": st.column_config.TextColumn("–ü—Ä–æ–µ–∫—Ç–∏ (–î–∞—Ç–∞)", disabled=True, width="large"),
                        "–ó–∞—Ä–µ—î—Å—Ç—Ä–æ–≤–∞–Ω–∏–π": st.column_config.TextColumn("–î–∞—Ç–∞ —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ—ó", disabled=True),
                        "–†–æ–ª—å": st.column_config.SelectboxColumn("–†–æ–ª—å", options=["user", "admin", "super_admin"], required=True)
                    },
                    use_container_width=True,
                    key="admin_users_final_v4"
                )

                if st.button("üíæ –ó–±–µ—Ä–µ–≥—Ç–∏ –∑–º—ñ–Ω–∏ –ø—Ä–∞–≤"):
                    try:
                        changes_count = 0
                        updated_rows = edited_users.to_dict('index') 
                        
                        for idx, row in updated_rows.items():
                            uid = row['id']
                            new_role = row['–†–æ–ª—å']
                            
                            old_user = next((u for u in users_data if u['id'] == uid), None)
                            if old_user and old_user.get('role') != new_role:
                                supabase.table("profiles").update({"role": new_role}).eq("id", uid).execute()
                                changes_count += 1
                        
                        if changes_count > 0:
                            st.success(f"–£—Å–ø—ñ—à–Ω–æ –æ–Ω–æ–≤–ª–µ–Ω–æ {changes_count} –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤!")
                            time.sleep(1)
                            st.rerun()
                        else:
                            st.info("–ó–º—ñ–Ω –Ω–µ –≤–∏—è–≤–ª–µ–Ω–æ.")
                            
                    except Exception as e:
                        st.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è: {e}")

                st.divider()
                st.markdown("##### üìà –î–∏–Ω–∞–º—ñ–∫–∞ —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ–π")
                
                df_chart = pd.DataFrame(users_data)
                if 'created_at' in df_chart.columns:
                    df_chart['date'] = pd.to_datetime(df_chart['created_at']).dt.date
                    from datetime import timedelta
                    time_filter = st.selectbox("–ü–µ—Ä—ñ–æ–¥", ["–û—Å—Ç–∞–Ω–Ω—ñ 7 –¥–Ω—ñ–≤", "–û—Å—Ç–∞–Ω–Ω—ñ 30 –¥–Ω—ñ–≤", "–û—Å—Ç–∞–Ω–Ω—ñ 90 –¥–Ω—ñ–≤", "–í–µ—Å—å —á–∞—Å"], index=1)
                    
                    today = pd.to_datetime("today").date()
                    if "7" in time_filter: start_date = today - timedelta(days=7)
                    elif "30" in time_filter: start_date = today - timedelta(days=30)
                    elif "90" in time_filter: start_date = today - timedelta(days=90)
                    else: start_date = df_chart['date'].min()
                    
                    df_chart_filtered = df_chart[df_chart['date'] >= start_date]
                    reg_counts = df_chart_filtered.groupby('date').size().reset_index(name='count')
                    
                    if not reg_counts.empty:
                        fig = px.bar(reg_counts, x='date', y='count', labels={'date': '–î–∞—Ç–∞', 'count': '–ù–æ–≤–∏—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤'})
                        fig.update_layout(height=300)
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("–ù–µ–º–∞—î —Ä–µ—î—Å—Ç—Ä–∞—Ü—ñ–π –∑–∞ —Ü–µ–π –ø–µ—Ä—ñ–æ–¥.")
            else:
                st.warning("–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        else:
            st.warning("–ë–∞–∑–∞ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –ø—É—Å—Ç–∞.")


def show_chat_page():
    """
    –°—Ç–æ—Ä—ñ–Ω–∫–∞ AI-–∞—Å–∏—Å—Ç–µ–Ω—Ç–∞ (GPT-Visibility).
    –í–ï–†–°–Ü–Ø: ADDED CONTEXT (SOURCES, BRAND, USER NAME).
    1. –ü–µ—Ä–µ–¥–∞—î official_sources (—Å–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω—ñ–≤ –∑ –±–∞–∑–∏).
    2. –ü–µ—Ä–µ–¥–∞—î user_name (–∑ –º–µ—Ç–∞–¥–∞–Ω–∏—Ö –∞–±–æ email).
    3. –ü–µ—Ä–µ–¥–∞—î target_brand.
    """
    import requests
    import streamlit as st

    # --- –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø ---
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ URL
    if 'N8N_CHAT_WEBHOOK' not in globals():
        target_url = st.secrets.get("N8N_CHAT_WEBHOOK", "")
        if not target_url:
            st.error("üö® –ù–µ –∑–∞–¥–∞–Ω–æ –ø–æ—Å–∏–ª–∞–Ω–Ω—è N8N_CHAT_WEBHOOK.")
            return
    else:
        target_url = N8N_CHAT_WEBHOOK

    # –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –±–∞–∑–∏ (–¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∂–µ—Ä–µ–ª)
    if 'supabase' in st.session_state:
        supabase = st.session_state['supabase']
    elif 'supabase' in globals():
        supabase = globals()['supabase']
    else:
        st.error("üö® –ó–º—ñ–Ω–Ω–∞ 'supabase' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
        return

    headers = {
        "virshi-auth": "hi@virshi.ai2025" 
    }

    st.title("ü§ñ GPT-Visibility Assistant")
    
    # 1. –û—Ç—Ä–∏–º—É—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —Ç–∞ –ø—Ä–æ–µ–∫—Ç—É
    user = st.session_state.get("user")
    role = st.session_state.get("role", "user") 
    proj = st.session_state.get("current_project", {})
    
    if not proj:
        st.warning("‚ö†Ô∏è –ë—É–¥—å –ª–∞—Å–∫–∞, –æ–±–µ—Ä—ñ—Ç—å –ø—Ä–æ–µ–∫—Ç —É –º–µ–Ω—é –∑–ª—ñ–≤–∞.")
        return

    # 2. –õ–æ–≥—ñ–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–º–µ–Ω—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    user_name = "–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á"
    if user:
        # –°–ø—Ä–æ–±–∞ –¥—ñ—Å—Ç–∞—Ç–∏ —ñ–º'—è –∑ –º–µ—Ç–∞–¥–∞–Ω–∏—Ö Supabase, —ñ–Ω–∞–∫—à–µ email
        meta = getattr(user, "user_metadata", {})
        user_name = meta.get("full_name") or meta.get("name") or user.email.split("@")[0]

    # 3. –õ–æ–≥—ñ–∫–∞ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –æ—Ñ—ñ—Ü—ñ–π–Ω–∏—Ö –¥–∂–µ—Ä–µ–ª (Whitelist)
    official_sources_list = []
    try:
        # –†–æ–±–∏–º–æ –∑–∞–ø–∏—Ç –¥–æ –±–∞–∑–∏, —â–æ–± –∞–≥–µ–Ω—Ç –∑–Ω–∞–≤ "–±—ñ–ª–∏–π —Å–ø–∏—Å–æ–∫"
        assets_resp = supabase.table("official_assets")\
            .select("domain_or_url")\
            .eq("project_id", proj.get("id"))\
            .execute()
        
        if assets_resp.data:
            official_sources_list = [item["domain_or_url"] for item in assets_resp.data]
    except Exception:
        official_sources_list = [] # –Ø–∫—â–æ –ø–æ–º–∏–ª–∫–∞, –ø—Ä–æ—Å—Ç–æ –ø—É—Å—Ç–∏–π —Å–ø–∏—Å–æ–∫

    # 4. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è —ñ—Å—Ç–æ—Ä—ñ—ó
    if "messages" not in st.session_state:
        brand_name = proj.get('brand_name', '–≤–∞—à–æ–≥–æ –±—Ä–µ–Ω–¥—É')
        welcome_text = f"–ü—Ä–∏–≤—ñ—Ç, {user_name}! –Ø –∞–Ω–∞–ª—ñ—Ç–∏–∫ –ø—Ä–æ–µ–∫—Ç—É **{brand_name}**. –ì–æ—Ç–æ–≤–∏–π –¥–æ–ø–æ–º–æ–≥—Ç–∏ –∑ –∞–Ω–∞–ª—ñ–∑–æ–º –≤–∏–¥–∏–º–æ—Å—Ç—ñ —Ç–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤."
        st.session_state["messages"] = [
            {"role": "assistant", "content": welcome_text}
        ]

    # 5. –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —ñ—Å—Ç–æ—Ä—ñ—ó
    for msg in st.session_state["messages"]:
        avatar_icon = "üë§" if msg["role"] == "user" else "ü§ñ"
        with st.chat_message(msg["role"], avatar=avatar_icon):
            st.markdown(msg["content"])

    # 6. –û–±—Ä–æ–±–∫–∞ –≤–≤–æ–¥—É
    if prompt := st.chat_input("–ù–∞–ø–∏—à—ñ—Ç—å –≤–∞—à–µ –∑–∞–ø–∏—Ç–∞–Ω–Ω—è..."):
        
        # A. –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á
        st.session_state["messages"].append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üë§"):
            st.markdown(prompt)

        # B. –í—ñ–¥–ø—Ä–∞–≤–∫–∞ –Ω–∞ n8n
        with st.chat_message("assistant", avatar="ü§ñ"):
            message_placeholder = st.empty()
            
            with st.spinner("–ê–Ω–∞–ª—ñ–∑—É—é –¥–∞–Ω—ñ..."):
                try:
                    # --- üî• –†–û–ó–®–ò–†–ï–ù–ò–ô PAYLOAD ---
                    payload = {
                        "query": prompt,
                        
                        # –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á
                        "user_id": user.id if user else "guest",
                        "user_email": user.email if user else None,
                        "user_name": user_name,  # <--- –Ü–º'—è
                        "role": role,
                        
                        # –ü—Ä–æ–µ–∫—Ç
                        "project_id": proj.get("id"),
                        "project_name": proj.get("brand_name"),
                        "target_brand": proj.get("brand_name"), # <--- –¶—ñ–ª—å–æ–≤–∏–π –±—Ä–µ–Ω–¥
                        "domain": proj.get("domain"),
                        "status": proj.get("status"),
                        
                        # –ö–æ–Ω—Ç–µ–∫—Å—Ç
                        "official_sources": official_sources_list # <--- –°–ø–∏—Å–æ–∫ –¥–∂–µ—Ä–µ–ª
                    }

                    response = requests.post(
                        target_url, 
                        json=payload, 
                        headers=headers, 
                        timeout=60
                    )

                    if response.status_code == 200:
                        data = response.json()
                        bot_reply = data.get("output") or data.get("answer") or data.get("text")
                        
                        if isinstance(bot_reply, dict):
                            bot_reply = str(bot_reply)
                        
                        if not bot_reply:
                            bot_reply = "‚ö†Ô∏è –û—Ç—Ä–∏–º–∞–Ω–∞ –ø—É—Å—Ç–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ AI."
                            
                    elif response.status_code == 403:
                        bot_reply = "‚õî –ü–æ–º–∏–ª–∫–∞ 403: –î–æ—Å—Ç—É–ø –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–æ. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ Header Name 'virshi-auth' –≤ n8n."
                    elif response.status_code == 404:
                        bot_reply = f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ 404 (Not Found).\n\n1. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –º–µ—Ç–æ–¥ **POST** –≤ n8n.\n2. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —â–æ Workflow **Active**."
                    else:
                        bot_reply = f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {response.status_code} - {response.text}"

                except Exception as e:
                    bot_reply = f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑'—î–¥–Ω–∞–Ω–Ω—è: {e}"

                # C. –í–∏–≤—ñ–¥
                message_placeholder.markdown(bot_reply)
        
        # D. –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        st.session_state["messages"].append({"role": "assistant", "content": bot_reply})
        
            
def main():
    # 1. Session Check
    if 'check_session' in globals():
        check_session()

    # 2. If not logged in -> Show Auth Page
    if not st.session_state.get("user"):
        # –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—è, —â–æ show_auth_page –≤–∏–∑–Ω–∞—á–µ–Ω–∞
        if 'show_auth_page' in globals():
            show_auth_page()
        else:
            st.error("–§—É–Ω–∫—Ü—ñ—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—ó –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
        return

    # 3. –û–¢–†–ò–ú–ê–ù–ù–Ø –î–ê–ù–ò–• –ü–†–û–ï–ö–¢–£
    if not st.session_state.get("current_project"):
        try:
            user_id = st.session_state["user"].id
            resp = supabase.table("projects").select("*").eq("user_id", user_id).execute()
            if resp.data:
                # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π –∑–Ω–∞–π–¥–µ–Ω–∏–π –ø—Ä–æ–µ–∫—Ç
                st.session_state["current_project"] = resp.data[0]
                st.rerun()
        except Exception:
            pass

    # 4. –õ–û–ì–Ü–ö–ê ONBOARDING
    # –Ø–∫—â–æ –ø—Ä–æ–µ–∫—Ç—É –Ω–µ–º–∞—î —ñ —Ü–µ –Ω–µ –∞–¥–º—ñ–Ω
    user_role = st.session_state.get("role", "user")
    
    if st.session_state.get("current_project") is None and user_role not in ["admin", "super_admin"]:
        with st.sidebar:
            # –õ–æ–≥–æ—Ç–∏–ø
            st.image("https://raw.githubusercontent.com/virshi-ai/image/refs/heads/main/logo-removebg-preview.png", width=150)
            if st.button("–í–∏–π—Ç–∏"):
                logout()
        
        # –ó–∞–ø—É—Å–∫ –º–∞–π—Å—Ç—Ä–∞
        if 'onboarding_wizard' in globals():
            onboarding_wizard()
        else:
            st.error("Onboarding Wizard not found.")
    
    # 5. –û–°–ù–û–í–ù–ò–ô –î–û–î–ê–¢–û–ö
    else:
        # –í–∏–∫–ª–∏–∫ –º–µ–Ω—é
        page = sidebar_menu()

        # –†–æ—É—Ç–∏–Ω–≥ —Å—Ç–æ—Ä—ñ–Ω–æ–∫
        if page == "–î–∞—à–±–æ—Ä–¥":
            show_dashboard()
        elif page == "–ü–µ—Ä–µ–ª—ñ–∫ –∑–∞–ø–∏—Ç—ñ–≤":
            show_keywords_page()
        elif page == "–î–∂–µ—Ä–µ–ª–∞":
            show_sources_page()
        elif page == "–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–∏":
            # –Ø–∫—â–æ –æ–∫—Ä–µ–º–æ—ó —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –Ω–µ–º–∞—î, –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ —á–∞—Å—Ç–∏–Ω—É –¥–∞—à–±–æ—Ä–¥—É –∞–±–æ –∑–∞–≥–ª—É—à–∫—É
            if 'show_competitors_page' in globals():
                show_competitors_page()
            else:
                st.info("–†–æ–∑–¥—ñ–ª —É —Ä–æ–∑—Ä–æ–±—Ü—ñ (–¥–∏–≤. –î–∞—à–±–æ—Ä–¥).")
        elif page == "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó":
            show_recommendations_page()
            
        # --- –ù–û–í–Ü –°–¢–û–†–Ü–ù–ö–ò ---
        elif page == "–Ü—Å—Ç–æ—Ä—ñ—è —Å–∫–∞–Ω—É–≤–∞–Ω—å":
            if 'show_history_page' in globals(): show_history_page()
            else: st.warning("–§—É–Ω–∫—Ü—ñ—è show_history_page –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
            
        elif page == "–ó–≤—ñ—Ç–∏":
            if 'show_reports_page' in globals(): show_reports_page()
            else: st.warning("–§—É–Ω–∫—Ü—ñ—è show_reports_page –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
            
        elif page == "FAQ":
            if 'show_faq_page' in globals(): show_faq_page()
            else: st.warning("–§—É–Ω–∫—Ü—ñ—è show_faq_page –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞.")
        # ---------------------

        elif page == "GPT-Visibility":
            show_chat_page()
            
        elif page == "–ê–¥–º—ñ–Ω":
            if user_role in ["admin", "super_admin"]:
                show_admin_page()
            else:
                st.error("–î–æ—Å—Ç—É–ø –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–æ.")

if __name__ == "__main__":
    main()
